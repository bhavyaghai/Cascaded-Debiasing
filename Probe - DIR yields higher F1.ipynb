{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfb4fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from aif360.algorithms.inprocessing import GerryFairClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "import copy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31ddd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(CM, priv=None):\n",
    "            numer = CM.num_true_positives(privileged=priv)\n",
    "            denom = CM.num_true_positives(privileged=priv) + 0.5*float(CM.num_false_positives(privileged=priv) + CM.num_false_negatives(privileged=priv))\n",
    "            return float(numer/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa18b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_options(dataset_name):\n",
    "    optim_options = None\n",
    "    if dataset_name==\"adult\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_adult,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'sex'\n",
    "        return (AdultDataset(), pro_attr, [{'sex': 1}], [{'sex': 0}], optim_options)\n",
    "    elif dataset_name==\"compas\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_compas,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'race'\n",
    "        return (CompasDataset(), pro_attr, [{'race': 1}], [{'race': 0}], optim_options)\n",
    "    elif dataset_name==\"bank\":\n",
    "        pro_attr = 'age'\n",
    "        return (BankDataset(protected_attribute_names=['age'],\n",
    "            privileged_classes=[lambda x: x >= 25], \n",
    "            features_to_drop=['day_of_week']), pro_attr, [{'age': 1}], [{'age': 0}], None)\n",
    "    elif dataset_name==\"german\":\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_german,\n",
    "            \"epsilon\": 0.1,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }   \n",
    "        pro_attr = 'age'\n",
    "        label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "        #g = load_preproc_data_german(['age'])\n",
    "        g = GermanDataset(metadata={'label_maps': [label_map]})\n",
    "        g.labels = (2.0 - g.labels).astype('float64')\n",
    "        g.favorable_label = 1.0\n",
    "        g.unfavorable_label = 0.0\n",
    "        #g.metadata['label_maps'] = [label_map]\n",
    "\n",
    "        # load_preproc_data_german(['age'])\n",
    "        return (g, pro_attr, [{'age': 1}], [{'age': 0}], optim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be95ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DIR(DIR=True, bal=False, dataset_name = \"adult\"):\n",
    "    dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "    preprocessing_algo = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\n",
    "\n",
    "    scale_orig = StandardScaler()\n",
    "    dataset.features = scale_orig.fit_transform(dataset.features)\n",
    "\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=0)\n",
    "\n",
    "    model = None\n",
    "    \n",
    "    if bal is True:\n",
    "        model = sklearn.linear_model.LogisticRegression(class_weight='balanced') # solver='liblinear', class_weight='balanced', \n",
    "    else:\n",
    "        model = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "    \n",
    "    if DIR is True:\n",
    "        dataset_train_pred = preprocessing_algo.fit_transform(dataset_train_pred)\n",
    "        dataset_test_pred = preprocessing_algo.fit_transform(dataset_test_pred)\n",
    "\n",
    "    model.fit(dataset_train_pred.features, dataset_train_pred.labels)   # .ravel()\n",
    "    fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "    dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "    dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1) \n",
    "    dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "    dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)  \n",
    "\n",
    "    dataset_test_pred.features = dataset_test.features \n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                                  dataset_test_pred,\n",
    "                                  unprivileged_groups=unprivileged_groups,\n",
    "                                  privileged_groups=privileged_groups)\n",
    "    return round(CM.accuracy(), 4), round(f1_score(CM), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "856e3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  adult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n",
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8505, 0.6639) (0.848, 0.6882)\n",
      "Dataset:  compas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n",
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6921, 0.7366) (0.6942, 0.7418)\n",
      "Dataset:  bank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8959, 0.5113) (0.894, 0.4932)\n",
      "Dataset:  german\n",
      "(0.7533, 0.8377) (0.7633, 0.8419)\n"
     ]
    }
   ],
   "source": [
    "# original, debiased\n",
    "for dataset_name in [\"adult\", \"compas\", \"bank\", \"german\"]:\n",
    "    print(\"Dataset: \", dataset_name)\n",
    "    print(run_DIR(DIR=False, dataset_name = dataset_name),  run_DIR(DIR=True, dataset_name = dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0338d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  adult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n",
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8103, 0.6863) (0.8005, 0.6754)\n",
      "Dataset:  compas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n",
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6759, 0.7056) (0.6823, 0.7132)\n",
      "Dataset:  bank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8474, 0.5958) (0.8361, 0.5833)\n",
      "Dataset:  german\n",
      "(0.7133, 0.7839) (0.7133, 0.785)\n"
     ]
    }
   ],
   "source": [
    "# Class balanced classifier\n",
    "# original, debiased\n",
    "\n",
    "for dataset_name in [\"adult\", \"compas\", \"bank\", \"german\"]:\n",
    "    print(\"Dataset: \", dataset_name)\n",
    "    print(run_DIR(DIR=False, bal=True, dataset_name = dataset_name),  run_DIR(DIR=True, bal=True, dataset_name = dataset_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9281b",
   "metadata": {},
   "source": [
    "<b>Finding: </b>This notebook replicates the fact that DIR can yield higher Accuracy/F1 score than the baseline. This is an interesting finding that needs further investigation for its causes. If we train the classifier that accounts for imbalanced output class distribution, this trend might still persist as seen in the case of COMPAS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae440eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
