{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Privileged and unprivileged groups specified will not be used. The protected attributes are directly specified in the data preprocessing function. The current implementation automatically adjusts for discrimination across all groups. This can be changed by changing the optimization code.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Intervention</th>\n",
       "      <th>Reweighing</th>\n",
       "      <th>Disparate Impact Remover</th>\n",
       "      <th>Learning Fair Representations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.7067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.7020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>-0.0481</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                No Intervention  Reweighing  \\\n",
       "accuracy                                 0.7700      0.7700   \n",
       "theil index                              0.1111      0.1173   \n",
       "consistency                              0.7020      0.7020   \n",
       "false positive rate difference          -0.0534     -0.0915   \n",
       "false negative rate difference           0.0084      0.0351   \n",
       "\n",
       "                                Disparate Impact Remover  \\\n",
       "accuracy                                          0.7533   \n",
       "theil index                                       0.1455   \n",
       "consistency                                       0.7020   \n",
       "false positive rate difference                   -0.0481   \n",
       "false negative rate difference                    0.0287   \n",
       "\n",
       "                                Learning Fair Representations  \n",
       "accuracy                                               0.7067  \n",
       "theil index                                            0.0572  \n",
       "consistency                                            0.7020  \n",
       "false positive rate difference                         0.0000  \n",
       "false negative rate difference                         0.0000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=1100)\n",
    "\n",
    "RW = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "DIR = preprocessing.DisparateImpactRemover()\n",
    "\n",
    "OP = preprocessing.OptimPreproc(SGD, {\"lr\":0.1}, unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "\n",
    "LFR = preprocessing.LFR(unprivileged_groups, privileged_groups)\n",
    "\n",
    "metrics = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, RF)\n",
    "df = pd.DataFrame(metrics, columns=[\"No Intervention\"])\n",
    "df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "            \"false negative rate difference\"]\n",
    "df[\"Reweighing\"] = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, RF, RW)\n",
    "df[\"Disparate Impact Remover\"] = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, RF, DIR)\n",
    "#df[\"Optimized Preprocessing\"] = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, RF, OP)\n",
    "df[\"Learning Fair Representations\"] = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, RF, LFR)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fairness_metrics(CM:ClassificationMetric):\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.consistency()[0], 4),\n",
    "        round(CM.false_positive_rate_difference(), 4),\n",
    "        round(CM.false_negative_rate_difference(), 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, classifier, \n",
    "                 preprocessing_algo=None):\n",
    "    if preprocessing_algo is not None:\n",
    "        dataset_train = preprocessing_algo.fit_transform(dataset_train)\n",
    "    \n",
    "    classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = classifier.predict(dataset_test.features)\n",
    "    \n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    return run_fairness_metrics(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disregard everything underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fairness_metrics(CM:ClassificationMetric):\n",
    "    print(f\"accuracy = {round(CM.accuracy(), 4)}\")\n",
    "    print(f\"theil index (goal:0) = {round(CM.theil_index(), 4)}\")\n",
    "    print(f\"binary confusion matrix = {CM.binary_confusion_matrix()}\")\n",
    "    print(f\"consistency (goal:1) = {round(CM.consistency()[0], 4)}\")\n",
    "    print(f\"false positive rate difference (negative:privileged bias) = {round(CM.false_positive_rate_difference(), 4)}\")\n",
    "    print(f\"false negative rate difference (negative:privileged bias) = {round(CM.false_negative_rate_difference(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fairness_metrics(CM1:ClassificationMetric, CM2:ClassificationMetric, side_by_side:bool=False):\n",
    "    if not side_by_side:\n",
    "        print_fairness_metrics(CM1)\n",
    "        print(\"After Fairness Algos are applied\")\n",
    "        print(\"_\"*10)\n",
    "        print_fairness_metrics(CM2)\n",
    "    else:\n",
    "        print(f\"accuracy = {round(CM1.accuracy(), 4)} => {round(CM2.accuracy(), 4)}\")\n",
    "        print(f\"theil index (goal:0) = {round(CM1.theil_index(), 4)} => {round(CM2.theil_index(), 4)}\")\n",
    "        print(f\"binary confusion matrix = {CM1.binary_confusion_matrix()} => {CM2.binary_confusion_matrix()}\")\n",
    "        print(f\"consistency (goal:1) = {round(CM1.consistency()[0], 4)} => {round(CM2.consistency()[0], 4)}\")\n",
    "        print(f\"false positive rate difference (negative:privileged bias) = \", end=\"\")\n",
    "        print(f\"{round(CM1.false_positive_rate_difference(), 4)} => {round(CM2.false_positive_rate_difference(), 4)}\")\n",
    "        print(f\"false negative rate difference (negative:privileged bias) = \", end=\"\")\n",
    "        print(f\"{round(CM1.false_negative_rate_difference(), 4)} => {round(CM2.false_negative_rate_difference(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fairness_metrics_as_df(df:pd.DataFrame, CM1:ClassificationMetric, CM2:ClassificationMetric,\n",
    "                                   intervention:str) -> pd.DataFrame:\n",
    "    metrics = np.array([[round(CM1.accuracy(), 4), round(CM2.accuracy(), 4)],\n",
    "        [round(CM1.theil_index(), 4), round(CM2.theil_index(), 4)],\n",
    "        [round(CM1.consistency()[0], 4), round(CM2.consistency()[0], 4)],\n",
    "        [round(CM1.false_positive_rate_difference(), 4), round(CM2.false_positive_rate_difference(), 4)],\n",
    "        [round(CM1.false_negative_rate_difference(), 4), round(CM2.false_negative_rate_difference(), 4)]]\n",
    "    )\n",
    "    df = pd.DataFrame(metrics, columns=[\"no intervention\", intervention])\n",
    "    df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "                \"false negative rate difference\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_debiasing_algos(dataset, privileged_groups, unprivileged_groups, classifier, \n",
    "                             preprocessing_algo:preprocessing = None, inprocessing_algo:inprocessing = None, \n",
    "                             postprocessing_algo:postprocessing = None):\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "    classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = classifier.predict(dataset_test.features)\n",
    "    \n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM1 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "\n",
    "    if preprocessing_algo is not None:\n",
    "        dataset_train = preprocessing_algo.fit_transform(dataset_train)\n",
    "    fair_classifier = clone(classifier)\n",
    "    fair_classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    \n",
    "    results = fair_classifier.predict(dataset_test.features)\n",
    "    \n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "    \n",
    "    CM2 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    return compare_fairness_metrics_as_df(CM1, CM2, \"preprocessing\")\n",
    "        \n",
    "    '''_________________________\n",
    "    RW = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                                 privileged_groups=privileged_groups)\n",
    "\n",
    "    fair_dataset_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "    fair_RF = RandomForestClassifier(n_estimators=1100)\n",
    "    fair_RF.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "\n",
    "    results = fair_RF.predict(dataset_test.features)\n",
    "\n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM2 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    compare_fairness_metrics(CM1, CM2, side_by_side=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=1100)\n",
    "RF.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "\n",
    "results = RF.predict(dataset_test.features)\n",
    "\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "CM1 = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "\n",
    "RW = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "fair_dataset_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "fair_RF = RandomForestClassifier(n_estimators=1100)\n",
    "fair_RF.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "\n",
    "results = fair_RF.predict(dataset_test.features)\n",
    "\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "CM2 = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Dataset metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no intervention</th>\n",
       "      <th>reweighing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.2635</td>\n",
       "      <td>-0.2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.1166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                no intervention  reweighing\n",
       "accuracy                                 0.7900      0.7800\n",
       "theil index                              0.0863      0.0909\n",
       "consistency                              0.6940      0.6940\n",
       "false positive rate difference          -0.2635     -0.2184\n",
       "false negative rate difference           0.1222      0.1166"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"German Dataset metrics\")\n",
    "compare_fairness_metrics_as_df(CM1, CM2, \"reweighing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
