{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "import art\n",
    "import fairlearn\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.consistency()[0], 4),\n",
    "        round(CM.false_positive_rate_difference(), 4),\n",
    "        round(CM.false_negative_rate_difference(), 4),\n",
    "        round(CM.error_rate_difference(), 4),\n",
    "        round(CM.false_discovery_rate_difference(), 4),\n",
    "        round(CM.false_omission_rate_difference(), 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    return np.array([\n",
    "        round(BLDM.statistical_parity_difference(), 4), # negative means privileged bias\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, classifier=None, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None):\n",
    "    if inprocessing_algo is not None:\n",
    "        inprocessing_algo.fit(dataset_train)\n",
    "        results = inprocessing_algo.predict(dataset_test)\n",
    "        #print(\"inprocessing algo\")\n",
    "        #print(results)\n",
    "        dataset_test_pred = dataset_test.copy()\n",
    "        dataset_test_pred.labels = results.labels\n",
    "        #dataset_test_pred = results\n",
    "    else:\n",
    "        classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "        results = classifier.predict(dataset_test.features)\n",
    "        #print(results)\n",
    "        if isinstance(classifier, sklearn.linear_model.LinearRegression):\n",
    "            results = np.rint(results)\n",
    "        dataset_test_pred = dataset_test.copy()\n",
    "        dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    #print(CM.binary_confusion_matrix())\n",
    "    return np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    if isinstance(model, sklearn.ensemble.RandomForestClassifier):\n",
    "        return \"Random Forest\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"Prejudice Remover\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"Adversarial Debiasing\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ART Classifier\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"Exp Grad Reduction\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GerryFair Classifier\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GridSearch Reduction\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MetaFair Classifier\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"Calibrated EOP\"\n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"EOP\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"Reject Option Class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_postproc_algo(dataset, unprivileged_groups, privileged_groups, model=None, postprocessing_algo=None, df=None):\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "    model.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = model.predict(dataset_test.features)\n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "    CM = ClassificationMetric(dataset_test, dataset_test_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "    \n",
    "    metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(metrics, columns=[get_model_name(model)])\n",
    "        df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "                \"false negative rate difference\", \"error rate difference\",\n",
    "                \"false discovery rate difference\", \"false omission rate difference\",\n",
    "                \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "    CM = ClassificationMetric(dataset_test, postprocessing_algo.fit_predict(dataset_test, dataset_test_pred), unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "    df[get_model_name(postprocessing_algo)] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inprocessing Algos Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>EOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.8423</td>\n",
       "      <td>0.8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.8394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.0821</td>\n",
       "      <td>-0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>-0.1120</td>\n",
       "      <td>-0.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.2936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>-0.1012</td>\n",
       "      <td>-0.1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Random Forest     EOP\n",
       "accuracy                                0.8423  0.8160\n",
       "theil index                             0.1215  0.1354\n",
       "consistency                             0.8394  0.8394\n",
       "false positive rate difference         -0.0821 -0.0003\n",
       "false negative rate difference          0.0716  0.0042\n",
       "error rate difference                  -0.1120 -0.0568\n",
       "false discovery rate difference         0.0273  0.2936\n",
       "false omission rate difference         -0.1012 -0.1138\n",
       "stat parity difference                 -0.1989 -0.1989\n",
       "priv base rate                          0.3125  0.3125\n",
       "unpriv base rate                        0.1136  0.1136"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"a72d93e1-1959-49bc-85a5-46629646a20e\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"a72d93e1-1959-49bc-85a5-46629646a20e\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "dataset = AdultDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "'''df = run_postproc_algo(dataset, unprivileged_groups, privileged_groups, model=model)\n",
    "display(df)'''\n",
    "display(run_postproc_algo(dataset, unprivileged_groups, privileged_groups, model=model,\n",
    "                          postprocessing_algo=postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                                              privileged_groups=privileged_groups)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disregard everything underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights features                                    \\\n",
      "                                                       protected attribute   \n",
      "                                     age education-num                race   \n",
      "instance names                                                               \n",
      "33468                       1.0     58.0           9.0                 0.0   \n",
      "31832                       1.0     43.0          14.0                 1.0   \n",
      "25415                       1.0     38.0           9.0                 1.0   \n",
      "14933                       1.0     17.0           7.0                 1.0   \n",
      "10741                       1.0     38.0           5.0                 1.0   \n",
      "...                         ...      ...           ...                 ...   \n",
      "16434                       1.0     21.0           9.0                 1.0   \n",
      "11288                       1.0     33.0          12.0                 1.0   \n",
      "10724                       1.0     17.0           6.0                 1.0   \n",
      "17276                       1.0     56.0           9.0                 1.0   \n",
      "21361                       1.0     30.0          10.0                 0.0   \n",
      "\n",
      "                                                              \\\n",
      "                                                               \n",
      "                sex capital-gain capital-loss hours-per-week   \n",
      "instance names                                                 \n",
      "33468           0.0          0.0          0.0           40.0   \n",
      "31832           1.0          0.0          0.0           50.0   \n",
      "25415           1.0          0.0          0.0           50.0   \n",
      "14933           0.0          0.0          0.0           10.0   \n",
      "10741           1.0          0.0          0.0           60.0   \n",
      "...             ...          ...          ...            ...   \n",
      "16434           1.0          0.0          0.0           35.0   \n",
      "11288           0.0          0.0          0.0           55.0   \n",
      "10724           0.0          0.0          0.0           16.0   \n",
      "17276           1.0          0.0          0.0           55.0   \n",
      "21361           0.0          0.0          0.0           16.0   \n",
      "\n",
      "                                                          ...  \\\n",
      "                                                          ...   \n",
      "               workclass=Federal-gov workclass=Local-gov  ...   \n",
      "instance names                                            ...   \n",
      "33468                            1.0                 0.0  ...   \n",
      "31832                            0.0                 0.0  ...   \n",
      "25415                            0.0                 1.0  ...   \n",
      "14933                            0.0                 0.0  ...   \n",
      "10741                            0.0                 0.0  ...   \n",
      "...                              ...                 ...  ...   \n",
      "16434                            0.0                 0.0  ...   \n",
      "11288                            0.0                 0.0  ...   \n",
      "10724                            0.0                 0.0  ...   \n",
      "17276                            0.0                 0.0  ...   \n",
      "21361                            0.0                 0.0  ...   \n",
      "\n",
      "                                                                   \\\n",
      "                                                                    \n",
      "               native-country=Puerto-Rico native-country=Scotland   \n",
      "instance names                                                      \n",
      "33468                                 0.0                     0.0   \n",
      "31832                                 0.0                     0.0   \n",
      "25415                                 0.0                     0.0   \n",
      "14933                                 0.0                     0.0   \n",
      "10741                                 0.0                     0.0   \n",
      "...                                   ...                     ...   \n",
      "16434                                 0.0                     0.0   \n",
      "11288                                 0.0                     0.0   \n",
      "10724                                 0.0                     0.0   \n",
      "17276                                 0.0                     0.0   \n",
      "21361                                 0.0                     0.0   \n",
      "\n",
      "                                                           \\\n",
      "                                                            \n",
      "               native-country=South native-country=Taiwan   \n",
      "instance names                                              \n",
      "33468                           0.0                   0.0   \n",
      "31832                           0.0                   0.0   \n",
      "25415                           0.0                   0.0   \n",
      "14933                           0.0                   0.0   \n",
      "10741                           0.0                   0.0   \n",
      "...                             ...                   ...   \n",
      "16434                           0.0                   0.0   \n",
      "11288                           0.0                   0.0   \n",
      "10724                           0.0                   0.0   \n",
      "17276                           0.0                   0.0   \n",
      "21361                           0.0                   0.0   \n",
      "\n",
      "                                                                       \\\n",
      "                                                                        \n",
      "               native-country=Thailand native-country=Trinadad&Tobago   \n",
      "instance names                                                          \n",
      "33468                              0.0                            0.0   \n",
      "31832                              0.0                            0.0   \n",
      "25415                              0.0                            0.0   \n",
      "14933                              0.0                            0.0   \n",
      "10741                              0.0                            0.0   \n",
      "...                                ...                            ...   \n",
      "16434                              0.0                            0.0   \n",
      "11288                              0.0                            0.0   \n",
      "10724                              0.0                            0.0   \n",
      "17276                              0.0                            0.0   \n",
      "21361                              0.0                            0.0   \n",
      "\n",
      "                                                                    \\\n",
      "                                                                     \n",
      "               native-country=United-States native-country=Vietnam   \n",
      "instance names                                                       \n",
      "33468                                   1.0                    0.0   \n",
      "31832                                   1.0                    0.0   \n",
      "25415                                   1.0                    0.0   \n",
      "14933                                   1.0                    0.0   \n",
      "10741                                   0.0                    0.0   \n",
      "...                                     ...                    ...   \n",
      "16434                                   1.0                    0.0   \n",
      "11288                                   1.0                    0.0   \n",
      "10724                                   1.0                    0.0   \n",
      "17276                                   1.0                    0.0   \n",
      "21361                                   1.0                    0.0   \n",
      "\n",
      "                                         labels  \n",
      "                                                 \n",
      "               native-country=Yugoslavia         \n",
      "instance names                                   \n",
      "33468                                0.0    0.0  \n",
      "31832                                0.0    1.0  \n",
      "25415                                0.0    1.0  \n",
      "14933                                0.0    0.0  \n",
      "10741                                0.0    0.0  \n",
      "...                                  ...    ...  \n",
      "16434                                0.0    0.0  \n",
      "11288                                0.0    1.0  \n",
      "10724                                0.0    0.0  \n",
      "17276                                0.0    1.0  \n",
      "21361                                0.0    0.0  \n",
      "\n",
      "[13567 rows x 100 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Cal EOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.8146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.8441</td>\n",
       "      <td>0.8441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.0861</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.0986</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>-0.1139</td>\n",
       "      <td>-0.0649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>-0.1002</td>\n",
       "      <td>-0.1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Random Forest  Cal EOP\n",
       "accuracy                                0.8437   0.8146\n",
       "theil index                             0.1213   0.1401\n",
       "consistency                             0.8441   0.8441\n",
       "false positive rate difference         -0.0861  -0.0008\n",
       "false negative rate difference          0.0986  -0.0008\n",
       "error rate difference                  -0.1139  -0.0649\n",
       "false discovery rate difference         0.0180   0.2976\n",
       "false omission rate difference         -0.1002  -0.1213\n",
       "stat parity difference                 -0.1989  -0.1989\n",
       "priv base rate                          0.3125   0.3125\n",
       "unpriv base rate                        0.1136   0.1136"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"d901b72b-1afa-46b8-a266-8997517e3a88\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"d901b72b-1afa-46b8-a266-8997517e3a88\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "'''dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]'''\n",
    "\n",
    "dataset = AdultDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "'''dataset = CompasDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]'''\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "RF = sklearn.ensemble.RandomForestClassifier()\n",
    "RF.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "results = RF.predict(dataset_test.features)\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "BLDM = BinaryLabelDatasetMetric(dataset, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "CM = ClassificationMetric(dataset_test, dataset_test_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "CEOP = postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "EOP = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "#print(dataset_test, dataset_test_pred)\n",
    "#print(CEOP.fit_predict(dataset_test, dataset_test_pred))\n",
    "\n",
    "#metrics = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, RF)\n",
    "metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "df = pd.DataFrame(metrics, columns=[get_model_name(RF)])\n",
    "df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "            \"false negative rate difference\", \"error rate difference\",\n",
    "            \"false discovery rate difference\", \"false omission rate difference\",\n",
    "            \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "BLDM = BinaryLabelDatasetMetric(dataset, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "CM = ClassificationMetric(dataset_test, EOP.fit_predict(dataset_test, dataset_test_pred), unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "#df[\"Prejudice Remover\"] = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, inprocessing_algo=PR)\n",
    "#df[\"GerryFair Classifier\"] = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, inprocessing_algo=GF)\n",
    "df[\"Cal EOP\"] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"German Dataset\"))\n",
    "\n",
    "dataset = AdultDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"Adult Dataset\"))\n",
    "\n",
    "dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"Bank Dataset\"))\n",
    "\n",
    "dataset = CompasDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"Compas Dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 641.579346\n",
      "epoch 1; iter: 0; batch classifier loss: 32.879578\n",
      "epoch 2; iter: 0; batch classifier loss: 17.136475\n",
      "epoch 3; iter: 0; batch classifier loss: 12.746425\n",
      "epoch 4; iter: 0; batch classifier loss: 9.400681\n",
      "epoch 5; iter: 0; batch classifier loss: 6.140807\n",
      "epoch 6; iter: 0; batch classifier loss: 2.270022\n",
      "epoch 7; iter: 0; batch classifier loss: 2.144179\n",
      "epoch 8; iter: 0; batch classifier loss: 0.836270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.199547\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470885\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263953\n",
      "epoch 14; iter: 0; batch classifier loss: 0.381343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.254617\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229809\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286453\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254371\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186551\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314237\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269565\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177701\n",
      "epoch 23; iter: 0; batch classifier loss: 0.305265\n",
      "epoch 24; iter: 0; batch classifier loss: 0.290146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.281725\n",
      "epoch 26; iter: 0; batch classifier loss: 0.235768\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176383\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342565\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170852\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238003\n",
      "epoch 31; iter: 0; batch classifier loss: 0.301277\n",
      "epoch 32; iter: 0; batch classifier loss: 0.263933\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165310\n",
      "epoch 34; iter: 0; batch classifier loss: 0.312401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244240\n",
      "epoch 36; iter: 0; batch classifier loss: 0.202886\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250031\n",
      "epoch 38; iter: 0; batch classifier loss: 0.224527\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.211093\n",
      "epoch 41; iter: 0; batch classifier loss: 0.251995\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.232339\n",
      "epoch 44; iter: 0; batch classifier loss: 0.193809\n",
      "epoch 45; iter: 0; batch classifier loss: 0.317659\n",
      "epoch 46; iter: 0; batch classifier loss: 0.261861\n",
      "epoch 47; iter: 0; batch classifier loss: 0.228658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.283354\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221239\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-d5d97aa90246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                            scope_name=scope_name_2, sess=sess2)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mfair_AD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdataset_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfair_AD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/aif360/algorithms/transformer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnew_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                     \u001b[0munit_adversary_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversary_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                     \u001b[0mgrad\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_adversary_grad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_adversary_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mgrad\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversary_loss_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0madversary_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 adversary_grads = {var: grad for (grad, var) in adversary_opt.compute_gradients(pred_protected_attributes_loss,\n\u001b[1;32m    175\u001b[0m                                                                                       var_list=classifier_vars)}\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mclassifier_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 instructions)\n\u001b[0;32m--> 538\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/linalg_ops.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(tensor, ord, axis, keepdims, name, keep_dims)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'fro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 281\u001b[0;31m       tensor_util.make_tensor_proto(\n\u001b[0m\u001b[1;32m    282\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m           allow_broadcast=allow_broadcast))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "sess1 = tf.compat.v1.Session()\n",
    "with tf.compat.v1.variable_scope(\"var1\", reuse=tf.compat.v1.AUTO_REUSE) as scope_name_1:\n",
    "    AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_1, sess=sess1, debias=False)\n",
    "\n",
    "    AD.fit(dataset_train)\n",
    "    dataset_test_pred = AD.predict(dataset_test)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    AD_metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "\n",
    "sess1.close()\n",
    "\n",
    "metrics = AD_metrics\n",
    "df = pd.DataFrame(metrics, columns=[\"No Intervention\"])\n",
    "df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "            \"false negative rate difference\", \"error rate difference\",\n",
    "            \"false discovery rate difference\", \"false omission rate difference\",\n",
    "            \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "\n",
    "sess2 = tf.compat.v1.Session()\n",
    "with tf.compat.v1.variable_scope(\"var2\", reuse=tf.compat.v1.AUTO_REUSE) as scope_name_2:\n",
    "    fair_AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_2, sess=sess2)\n",
    "\n",
    "    fair_AD.fit(dataset_train)\n",
    "    dataset_test_pred = fair_AD.predict(dataset_test)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    df[\"Adversarial Debiasing w/o dataset\"] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "sess2.close()\n",
    "\n",
    "'''sess3 = tf.compat.v1.Session()\n",
    "with tf.compat.v1.variable_scope(\"var3\", reuse=tf.compat.v1.AUTO_REUSE) as scope_name_3:\n",
    "    fair_AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_3, sess=sess3, debias=True)\n",
    "\n",
    "    fair_AD.fit(dataset_train.copy())\n",
    "    fair_dataset_train = fair_AD.transform(dataset_train)\n",
    "    fair_AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_3, sess=sess3, debias=True)\n",
    "    fair_AD.fit(fair_dataset_train)\n",
    "    dataset_test_pred = fair_AD.predict(dataset_test)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    df[\"Adversarial Debiasing w dataset\"] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "\n",
    "sess3.close()'''\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fairness_metrics(CM:ClassificationMetric):\n",
    "    print(f\"accuracy = {round(CM.accuracy(), 4)}\")\n",
    "    print(f\"theil index (goal:0) = {round(CM.theil_index(), 4)}\")\n",
    "    print(f\"binary confusion matrix = {CM.binary_confusion_matrix()}\")\n",
    "    print(f\"consistency (goal:1) = {round(CM.consistency()[0], 4)}\")\n",
    "    print(f\"false positive rate difference (negative:privileged bias) = {round(CM.false_positive_rate_difference(), 4)}\")\n",
    "    print(f\"false negative rate difference (negative:privileged bias) = {round(CM.false_negative_rate_difference(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fairness_metrics_as_df(CM1:ClassificationMetric, CM2:ClassificationMetric,\n",
    "                                   intervention:str) -> pd.DataFrame:\n",
    "    metrics = np.array([[round(CM1.accuracy(), 4), round(CM2.accuracy(), 4)],\n",
    "        [round(CM1.theil_index(), 4), round(CM2.theil_index(), 4)],\n",
    "        [round(CM1.consistency()[0], 4), round(CM2.consistency()[0], 4)],\n",
    "        [round(CM1.false_positive_rate_difference(), 4), round(CM2.false_positive_rate_difference(), 4)],\n",
    "        [round(CM1.false_negative_rate_difference(), 4), round(CM2.false_negative_rate_difference(), 4)]]\n",
    "    )\n",
    "    df = pd.DataFrame(metrics, columns=[\"no intervention\", intervention])\n",
    "    df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "                \"false negative rate difference\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_debiasing_algos(dataset, privileged_groups, unprivileged_groups, classifier, \n",
    "                             preprocessing_algo:preprocessing = None, inprocessing_algo:inprocessing = None, \n",
    "                             postprocessing_algo:postprocessing = None):\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "    classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = classifier.predict(dataset_test.features)\n",
    "    \n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM1 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "\n",
    "    if preprocessing_algo is not None:\n",
    "        dataset_train = preprocessing_algo.fit_transform(dataset_train)\n",
    "    fair_classifier = clone(classifier)\n",
    "    fair_classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    \n",
    "    results = fair_classifier.predict(dataset_test.features)\n",
    "    \n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "    \n",
    "    CM2 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    return compare_fairness_metrics_as_df(CM1, CM2, \"preprocessing\")\n",
    "        \n",
    "    '''_________________________\n",
    "    RW = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                                 privileged_groups=privileged_groups)\n",
    "\n",
    "    fair_dataset_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "    fair_RF = RandomForestClassifier(n_estimators=1100)\n",
    "    fair_RF.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "\n",
    "    results = fair_RF.predict(dataset_test.features)\n",
    "\n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM2 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    compare_fairness_metrics(CM1, CM2, side_by_side=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"78b37c0b-09d7-418a-96f4-eeb1f52508ec\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"78b37c0b-09d7-418a-96f4-eeb1f52508ec\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=1100)\n",
    "RF.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "\n",
    "results = RF.predict(dataset_test.features)\n",
    "\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "CM1 = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "\n",
    "RW = preprocessing.LFR(unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "fair_dataset_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "fair_RF = RandomForestClassifier(n_estimators=1100)\n",
    "fair_RF.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "\n",
    "results = fair_RF.predict(dataset_test.features)\n",
    "\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "CM2 = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
