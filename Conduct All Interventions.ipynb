{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from aif360.algorithms.inprocessing import GerryFairClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "import copy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    def f1_score(priv=None):\n",
    "            numer = CM.num_true_positives(privileged=priv)\n",
    "            denom = CM.num_true_positives(privileged=priv) + 0.5*float(CM.num_false_positives(privileged=priv) + CM.num_false_negatives(privileged=priv))\n",
    "            return float(numer/denom)\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(f1_score(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.false_positive_rate(privileged=False), 4),\n",
    "        round(CM.false_positive_rate(privileged=True), 4),\n",
    "        round(CM.false_negative_rate(privileged=False), 4),\n",
    "        round(CM.false_negative_rate(privileged=True), 4),\n",
    "        round(1-CM.error_rate(privileged=False), 4),\n",
    "        round(1-CM.error_rate(privileged=True), 4),\n",
    "        round(CM.false_discovery_rate(privileged=False), 4),\n",
    "        round(CM.false_discovery_rate(privileged=True), 4),\n",
    "        round(CM.false_omission_rate(privileged=False), 4),\n",
    "        round(CM.false_omission_rate(privileged=True), 4),\n",
    "        \n",
    "        #all results\n",
    "        CM.num_true_positives(),\n",
    "        CM.num_true_negatives(),\n",
    "        CM.num_false_positives(),\n",
    "        CM.num_false_negatives(),\n",
    "        \n",
    "        #privileged\n",
    "        CM.num_true_positives(privileged=True),\n",
    "        CM.num_true_negatives(privileged=True),\n",
    "        CM.num_false_positives(privileged=True),\n",
    "        CM.num_false_negatives(privileged=True),\n",
    "        \n",
    "        #unprivileged\n",
    "        CM.num_true_positives(privileged=False),\n",
    "        CM.num_true_negatives(privileged=False),\n",
    "        CM.num_false_positives(privileged=False),\n",
    "        CM.num_false_negatives(privileged=False),\n",
    "        \n",
    "        round(f1_score(True), 4),\n",
    "        round(f1_score(False), 4),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    #print(\"Consistency: \", BLDM.consistency())\n",
    "    return np.array([\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "        round(BLDM.consistency()[0], 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, preprocessing.DisparateImpactRemover):\n",
    "        return \"DIR\"\n",
    "    if isinstance(model, preprocessing.LFR):\n",
    "        return \"LFR\"\n",
    "    if isinstance(model, preprocessing.OptimPreproc):\n",
    "        return \"OP\"\n",
    "    if isinstance(model, preprocessing.Reweighing):\n",
    "        return \"RW\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"PR\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"AD\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ARTC\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"EGR\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GFC\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GSR\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MFC\"\n",
    "    \n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"EOP\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"CEOP\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"ROC\"\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if isinstance(dataset, aif360.datasets.german_dataset.GermanDataset):\n",
    "        return \"German Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.adult_dataset.AdultDataset):\n",
    "        return \"Adult Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.bank_dataset.BankDataset):\n",
    "        return \"Bank Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.compas_dataset.CompasDataset):\n",
    "        return \"Compas Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specialized dataset for Optimized Preprocessing\n",
    "def get_OP_dataset(dataset_name):\n",
    "    dataset = None\n",
    "    if dataset_name==\"bank\":\n",
    "        return\n",
    "    if dataset_name==\"adult\":\n",
    "        dataset = load_preproc_data_adult(['sex'])\n",
    "    elif dataset_name==\"compas\":\n",
    "        dataset = load_preproc_data_compas(['race'])\n",
    "    elif dataset_name==\"german\":\n",
    "        dataset = load_preproc_data_german(['age'])\n",
    "        dataset.labels = (2.0 - dataset.labels).astype('float64')\n",
    "        dataset.favorable_label = 1.0\n",
    "        dataset.unfavorable_label = 0.0\n",
    "        dataset.metadata['label_maps'] = [{1.0: 'Good Credit', 0.0: 'Bad Credit'}]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_options(dataset_name):\n",
    "    optim_options = None\n",
    "    if dataset_name==\"adult\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_adult,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'sex'\n",
    "        return (AdultDataset(), pro_attr, [{'sex': 1}], [{'sex': 0}], optim_options)\n",
    "    elif dataset_name==\"compas\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_compas,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'race'\n",
    "        return (CompasDataset(), pro_attr, [{'race': 1}], [{'race': 0}], optim_options)\n",
    "    elif dataset_name==\"bank\":\n",
    "        pro_attr = 'age'\n",
    "        return (BankDataset(protected_attribute_names=['age'],\n",
    "            privileged_classes=[lambda x: x >= 25], \n",
    "            features_to_drop=['day_of_week']), pro_attr, [{'age': 1}], [{'age': 0}], None)\n",
    "    elif dataset_name==\"german\":\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_german,\n",
    "            \"epsilon\": 0.1,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }   \n",
    "        pro_attr = 'age'\n",
    "        label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "        #g = load_preproc_data_german(['age'])\n",
    "        g = GermanDataset(metadata={'label_maps': [label_map]})\n",
    "        g.labels = (2.0 - g.labels).astype('float64')\n",
    "        g.favorable_label = 1.0\n",
    "        g.unfavorable_label = 0.0\n",
    "        #g.metadata['label_maps'] = [label_map]\n",
    "\n",
    "        # load_preproc_data_german(['age'])\n",
    "        return (g, pro_attr, [{'age': 1}], [{'age': 0}], optim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None, seed=123):\n",
    "    print(seed, get_model_name(preprocessing_algo), get_model_name(inprocessing_algo), get_model_name(postprocessing_algo))\n",
    "    scale_orig = StandardScaler()\n",
    "    dataset.features = scale_orig.fit_transform(dataset.features)\n",
    "    \n",
    "    # get specialized dataset for Optimized Preprocessing technique\n",
    "    if get_model_name(preprocessing_algo)==\"OP\" and dataset_name!=\"bank\":\n",
    "        #print(\"Specialized function: \", dataset_name)\n",
    "        dataset = get_OP_dataset(dataset_name) \n",
    "        \n",
    "    #np.random.seed(seed)\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=seed)\n",
    "\n",
    "    #model = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "    model = sklearn.svm.SVC(probability=True)\n",
    "    \n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "            \n",
    "    if preprocessing_algo is not None:\n",
    "        if get_model_name(preprocessing_algo)==\"DIR\":\n",
    "            dataset_train_pred = preprocessing_algo.fit_transform(dataset_train_pred)\n",
    "            dataset_test_pred = preprocessing_algo.fit_transform(dataset_test_pred)\n",
    "        elif get_model_name(preprocessing_algo) in [\"OP\", \"LFR\"]:\n",
    "            preprocessing_algo.fit(dataset_train_pred)\n",
    "            dataset_train_pred = preprocessing_algo.transform(dataset_train_pred)\n",
    "            dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "            dataset_test_pred = preprocessing_algo.transform(dataset_test_pred)\n",
    "            dataset_test_pred = dataset_test.align_datasets(dataset_test_pred)\n",
    "    \n",
    "    if inprocessing_algo is not None:\n",
    "        inp = inprocessing_algo\n",
    "        inp.fit(dataset_train_pred)\n",
    "        dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "        dataset_test_pred = inp.predict(dataset_test_pred) \n",
    "        \n",
    "        # exception for GFC \n",
    "        if get_model_name(inprocessing_algo)==\"GFC\":\n",
    "            dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "            dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "            dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "            dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "    else:\n",
    "        model.fit(dataset_train_pred.features, dataset_train_pred.labels)   # .ravel()\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1) \n",
    "        dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)  \n",
    "            \n",
    "    if postprocessing_algo is not None:\n",
    "        dataset_train.features = dataset_train_pred.features\n",
    "        pp = postprocessing_algo\n",
    "        pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "        dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    \n",
    "    dataset_test_pred.features = dataset_test.features \n",
    "    \n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "     \n",
    "    name = \"\"\n",
    "    if preprocessing_algo is not None:\n",
    "        name += get_model_name(preprocessing_algo) + \" + \"\n",
    "    if inprocessing_algo is not None:\n",
    "        name += get_model_name(inprocessing_algo) + \" + \"\n",
    "    if postprocessing_algo is not None:\n",
    "        name += get_model_name(postprocessing_algo)\n",
    "    if name == \"\":\n",
    "        name = get_model_name(model)\n",
    "        \n",
    "    if name.endswith(\" + \"):\n",
    "        lastIndex = name.rindex(\" + \")\n",
    "        name = name[:lastIndex]\n",
    "    \n",
    "    #print(run_classification_metrics(CM))\n",
    "    #print(run_binary_dataset_metrics(BLDM))\n",
    "    metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "       \n",
    "    return {\"key\":name, \"val\":metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  adult\n",
      "3 OP None None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP None EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP None CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP None ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 DIR None None\n",
      "11 DIR None None\n",
      "17 DIR None None\n",
      "3 DIR None EOP\n",
      "11 DIR None EOP\n",
      "17 DIR None EOP\n",
      "3 DIR None CEOP\n",
      "11 DIR None CEOP\n",
      "17 DIR None CEOP\n",
      "3 DIR None ROC\n",
      "11 DIR None ROC\n",
      "17 DIR None ROC\n",
      "3 DIR GFC None\n",
      "11 DIR GFC None\n",
      "17 DIR GFC None\n",
      "3 DIR GFC EOP\n",
      "11 DIR GFC EOP\n",
      "17 DIR GFC EOP\n",
      "3 DIR GFC CEOP\n",
      "11 DIR GFC CEOP\n",
      "17 DIR GFC CEOP\n",
      "3 DIR GFC ROC\n",
      "11 DIR GFC ROC\n",
      "17 DIR GFC ROC\n",
      "3 DIR PR None\n",
      "11 DIR PR None\n",
      "17 DIR PR None\n",
      "3 DIR PR EOP\n",
      "11 DIR PR EOP\n",
      "17 DIR PR EOP\n",
      "3 DIR PR CEOP\n",
      "11 DIR PR CEOP\n",
      "17 DIR PR CEOP\n",
      "3 DIR PR ROC\n",
      "11 DIR PR ROC\n",
      "17 DIR PR ROC\n",
      "3 DIR EGR None\n",
      "11 DIR EGR None\n",
      "17 DIR EGR None\n",
      "3 DIR EGR EOP\n",
      "11 DIR EGR EOP\n",
      "FAILED: DIR, EGR, EOP on dataset Adult Dataset \n",
      "17 DIR EGR EOP\n",
      "FAILED: DIR, EGR, EOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "3 DIR EGR CEOP\n",
      "FAILED: DIR, EGR, CEOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "11 DIR EGR CEOP\n",
      "FAILED: DIR, EGR, CEOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "17 DIR EGR CEOP\n",
      "FAILED: DIR, EGR, CEOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "3 DIR EGR ROC\n",
      "FAILED: DIR, EGR, ROC on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "11 DIR EGR ROC\n",
      "FAILED: DIR, EGR, ROC on dataset Adult Dataset Unable to allocate 23.7 MiB for an array with shape (31655, 98) and data type float64\n",
      "17 DIR EGR ROC\n",
      "FAILED: DIR, EGR, ROC on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "3 DIR GSR None\n",
      "FAILED: DIR, GSR, None on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "11 DIR GSR None\n",
      "FAILED: DIR, GSR, None on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "17 DIR GSR None\n",
      "FAILED: DIR, GSR, None on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "3 DIR GSR EOP\n",
      "FAILED: DIR, GSR, EOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "11 DIR GSR EOP\n",
      "FAILED: DIR, GSR, EOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "17 DIR GSR EOP\n",
      "FAILED: DIR, GSR, EOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "3 DIR GSR CEOP\n",
      "FAILED: DIR, GSR, CEOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "11 DIR GSR CEOP\n",
      "FAILED: DIR, GSR, CEOP on dataset Adult Dataset Unable to allocate 33.8 MiB for an array with shape (45222, 98) and data type float64\n",
      "17 DIR GSR CEOP\n",
      "FAILED: DIR, GSR, CEOP on dataset Adult Dataset Unable to allocate 34.2 MiB for an array with shape (99, 45222) and data type float64\n",
      "3 DIR GSR ROC\n",
      "FAILED: DIR, GSR, ROC on dataset Adult Dataset \n",
      "11 DIR GSR ROC\n",
      "FAILED: DIR, GSR, ROC on dataset Adult Dataset \n",
      "17 DIR GSR ROC\n",
      "FAILED: DIR, GSR, ROC on dataset Adult Dataset \n",
      "3 None None None\n"
     ]
    }
   ],
   "source": [
    "#datasets = [\"compas\", \"german\", \"adult\", \"bank\"]\n",
    "datasets = [\"adult\"]\n",
    "for dataset_name in datasets:\n",
    "    print(\"DATASET NAME: \", dataset_name)\n",
    "    dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "    \n",
    "    preprocessing_algos = [OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups),\n",
    "                           preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr),\n",
    "                           None,\n",
    "                           #LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0),\n",
    "                          #preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                           ]\n",
    "                          \n",
    "    inprocessing_algos = [None,\n",
    "                           #inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=seed),\n",
    "                          GerryFairClassifier(),\n",
    "                          inprocessing.PrejudiceRemover(sensitive_attr=pro_attr),\n",
    "                          inprocessing.ExponentiatedGradientReduction(LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          ]\n",
    "\n",
    "    postprocessing_algos = [None,\n",
    "                            postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),  \n",
    "                            ]\n",
    "\n",
    "    df = {}\n",
    "    all_data = {}\n",
    "\n",
    "    for pre in preprocessing_algos:\n",
    "        for inproc in inprocessing_algos:\n",
    "            for post in postprocessing_algos:    \n",
    "                kfold_data = []   # store data for each fold\n",
    "                col_name = None\n",
    "                # k-fold cross vaidation - Repeat the process 3 times\n",
    "                for seed in [3, 11, 17]:  #[3, 5, 11, 17, 29]:\n",
    "                    try: \n",
    "                        res = execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                                 preprocessing_algo=copy.deepcopy(pre), \n",
    "                                 inprocessing_algo=copy.deepcopy(inproc),\n",
    "                                 postprocessing_algo=copy.deepcopy(post), seed=seed)\n",
    "                        \n",
    "                        col_name = res[\"key\"]\n",
    "                        if col_name:\n",
    "                            kfold_data.append(res[\"val\"])\n",
    "                            all_data[col_name+\" - \"+str(seed)] = res[\"val\"]\n",
    "                        \n",
    "                    except KeyboardInterrupt:\n",
    "                        raise KeyboardInterrupt()\n",
    "                    except Exception as e:\n",
    "                        print(\"FAILED: \" + get_model_name(pre) + \", \" + get_model_name(inproc) + \", \" + get_model_name(post) + \" on dataset \" + get_dataset_name(dataset), e)\n",
    "                \n",
    "                if col_name:\n",
    "                    df[col_name] = np.array(kfold_data).mean(axis=0).tolist()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    all_data = pd.DataFrame.from_dict(all_data)\n",
    "    df.index = all_data.index = [\"Accuracy\", \"F1 Score\", \"Theil Index\",\n",
    "                    \"False Positive Rate - Unprivileged\", \"False Positive Rate - Privileged\",\n",
    "                    \"False Negative Rate - Unprivileged\", \"False Negative Rate - Privileged\",\n",
    "                    \"Accuracy - Unprivileged\", \"Accuracy - Privileged\",\n",
    "                    \"False Discovery Rate - Unprivileged\", \"False Discovery Rate - Privileged\",\n",
    "                    \"False Omission Rate - Unprivileged\", \"False Omission Rate - Privileged\",\n",
    "                    \"Num True Pos\", \"Num True Neg\", \"Num False Pos\", \"Num False Neg\",\n",
    "                    \"Num True Pos - Privileged\", \"Num True Neg - Privileged\", \"Num False Pos - Privileged\", \"Num False Neg - Privileged\",\n",
    "                    \"Num True Pos - Unprivileged\", \"Num True Neg - Unprivileged\", \"Num False Pos - Unprivileged\", \"Num False Neg - Unprivileged\",\n",
    "                    \"F1 Score - Privileged\", \"F1 Score - Unprivileged\",\n",
    "                    \"Privileged base Rate\", \"Unprivileged base Rate\", \"Consistency\"]\n",
    "\n",
    "    df = df.T\n",
    "    all_data = all_data.T\n",
    "    df.to_csv(\"./data/svm/\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    all_data.to_csv(\"./data/svm/All_Data -\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    display(df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EXTRA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass=Federal-gov</th>\n",
       "      <th>workclass=Local-gov</th>\n",
       "      <th>workclass=Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country=Puerto-Rico</th>\n",
       "      <th>native-country=Scotland</th>\n",
       "      <th>native-country=South</th>\n",
       "      <th>native-country=Taiwan</th>\n",
       "      <th>native-country=Thailand</th>\n",
       "      <th>native-country=Trinadad&amp;Tobago</th>\n",
       "      <th>native-country=United-States</th>\n",
       "      <th>native-country=Vietnam</th>\n",
       "      <th>native-country=Yugoslavia</th>\n",
       "      <th>income-per-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.024983</td>\n",
       "      <td>-1.221559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.041455</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.798015</td>\n",
       "      <td>0.737034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>3.686155</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.046403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877467</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.344079</td>\n",
       "      <td>-1.613277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.910942</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>-0.873671</td>\n",
       "      <td>0.737034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.244684</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.109857</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>1.471665</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>-1.251951</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-1.743763</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>0.598108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1.017729</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.854773</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>-0.179133</td>\n",
       "      <td>-0.271285</td>\n",
       "      <td>-1.671940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.021035</td>\n",
       "      <td>-0.047312</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.025332</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.308506</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  education-num  race  sex  capital-gain  capital-loss  \\\n",
       "0     -1.024983      -1.221559   0.0  1.0     -0.146733      -0.21878   \n",
       "1     -0.041455      -0.438122   1.0  1.0     -0.146733      -0.21878   \n",
       "2     -0.798015       0.737034   1.0  1.0     -0.146733      -0.21878   \n",
       "3      0.412481      -0.046403   0.0  1.0      0.877467      -0.21878   \n",
       "5     -0.344079      -1.613277   1.0  1.0     -0.146733      -0.21878   \n",
       "...         ...            ...   ...  ...           ...           ...   \n",
       "48837 -0.873671       0.737034   1.0  0.0     -0.146733      -0.21878   \n",
       "48838  0.109857      -0.438122   1.0  1.0     -0.146733      -0.21878   \n",
       "48839  1.471665      -0.438122   1.0  0.0     -0.146733      -0.21878   \n",
       "48840 -1.251951      -0.438122   1.0  1.0     -0.146733      -0.21878   \n",
       "48841  1.017729      -0.438122   1.0  0.0      1.854773      -0.21878   \n",
       "\n",
       "       hours-per-week  workclass=Federal-gov  workclass=Local-gov  \\\n",
       "0           -0.078120              -0.179133            -0.271285   \n",
       "1            0.754701              -0.179133            -0.271285   \n",
       "2           -0.078120              -0.179133             3.686155   \n",
       "3           -0.078120              -0.179133            -0.271285   \n",
       "5           -0.910942              -0.179133            -0.271285   \n",
       "...               ...                    ...                  ...   \n",
       "48837       -0.244684              -0.179133            -0.271285   \n",
       "48838       -0.078120              -0.179133            -0.271285   \n",
       "48839       -0.078120              -0.179133            -0.271285   \n",
       "48840       -1.743763              -0.179133            -0.271285   \n",
       "48841       -0.078120              -0.179133            -0.271285   \n",
       "\n",
       "       workclass=Private  ...  native-country=Puerto-Rico  \\\n",
       "0               0.598108  ...                   -0.062328   \n",
       "1               0.598108  ...                   -0.062328   \n",
       "2              -1.671940  ...                   -0.062328   \n",
       "3               0.598108  ...                   -0.062328   \n",
       "5               0.598108  ...                   -0.062328   \n",
       "...                  ...  ...                         ...   \n",
       "48837           0.598108  ...                   -0.062328   \n",
       "48838           0.598108  ...                   -0.062328   \n",
       "48839           0.598108  ...                   -0.062328   \n",
       "48840           0.598108  ...                   -0.062328   \n",
       "48841          -1.671940  ...                   -0.062328   \n",
       "\n",
       "       native-country=Scotland  native-country=South  native-country=Taiwan  \\\n",
       "0                    -0.021035             -0.047312              -0.034896   \n",
       "1                    -0.021035             -0.047312              -0.034896   \n",
       "2                    -0.021035             -0.047312              -0.034896   \n",
       "3                    -0.021035             -0.047312              -0.034896   \n",
       "5                    -0.021035             -0.047312              -0.034896   \n",
       "...                        ...                   ...                    ...   \n",
       "48837                -0.021035             -0.047312              -0.034896   \n",
       "48838                -0.021035             -0.047312              -0.034896   \n",
       "48839                -0.021035             -0.047312              -0.034896   \n",
       "48840                -0.021035             -0.047312              -0.034896   \n",
       "48841                -0.021035             -0.047312              -0.034896   \n",
       "\n",
       "       native-country=Thailand  native-country=Trinadad&Tobago  \\\n",
       "0                    -0.025332                       -0.023985   \n",
       "1                    -0.025332                       -0.023985   \n",
       "2                    -0.025332                       -0.023985   \n",
       "3                    -0.025332                       -0.023985   \n",
       "5                    -0.025332                       -0.023985   \n",
       "...                        ...                             ...   \n",
       "48837                -0.025332                       -0.023985   \n",
       "48838                -0.025332                       -0.023985   \n",
       "48839                -0.025332                       -0.023985   \n",
       "48840                -0.025332                       -0.023985   \n",
       "48841                -0.025332                       -0.023985   \n",
       "\n",
       "       native-country=United-States  native-country=Vietnam  \\\n",
       "0                          0.308506               -0.042881   \n",
       "1                          0.308506               -0.042881   \n",
       "2                          0.308506               -0.042881   \n",
       "3                          0.308506               -0.042881   \n",
       "5                          0.308506               -0.042881   \n",
       "...                             ...                     ...   \n",
       "48837                      0.308506               -0.042881   \n",
       "48838                      0.308506               -0.042881   \n",
       "48839                      0.308506               -0.042881   \n",
       "48840                      0.308506               -0.042881   \n",
       "48841                      0.308506               -0.042881   \n",
       "\n",
       "       native-country=Yugoslavia  income-per-year  \n",
       "0                      -0.022558              0.0  \n",
       "1                      -0.022558              0.0  \n",
       "2                      -0.022558              1.0  \n",
       "3                      -0.022558              1.0  \n",
       "5                      -0.022558              0.0  \n",
       "...                          ...              ...  \n",
       "48837                  -0.022558              0.0  \n",
       "48838                  -0.022558              1.0  \n",
       "48839                  -0.022558              0.0  \n",
       "48840                  -0.022558              0.0  \n",
       "48841                  -0.022558              1.0  \n",
       "\n",
       "[45222 rows x 99 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_orig = StandardScaler()\n",
    "g = AdultDataset()\n",
    "g.features = scale_orig.fit_transform(g.features)\n",
    "g.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>Age (decade)=10</th>\n",
       "      <th>Age (decade)=20</th>\n",
       "      <th>Age (decade)=30</th>\n",
       "      <th>Age (decade)=40</th>\n",
       "      <th>Age (decade)=50</th>\n",
       "      <th>Age (decade)=60</th>\n",
       "      <th>Age (decade)=&gt;=70</th>\n",
       "      <th>Education Years=6</th>\n",
       "      <th>Education Years=7</th>\n",
       "      <th>Education Years=8</th>\n",
       "      <th>Education Years=9</th>\n",
       "      <th>Education Years=10</th>\n",
       "      <th>Education Years=11</th>\n",
       "      <th>Education Years=12</th>\n",
       "      <th>Education Years=&lt;6</th>\n",
       "      <th>Education Years=&gt;12</th>\n",
       "      <th>Income Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  sex  Age (decade)=10  Age (decade)=20  Age (decade)=30  \\\n",
       "0       0.0  1.0              0.0              1.0              0.0   \n",
       "1       1.0  1.0              0.0              0.0              1.0   \n",
       "2       1.0  1.0              0.0              1.0              0.0   \n",
       "3       0.0  1.0              0.0              0.0              0.0   \n",
       "4       1.0  0.0              1.0              0.0              0.0   \n",
       "...     ...  ...              ...              ...              ...   \n",
       "48837   1.0  0.0              0.0              1.0              0.0   \n",
       "48838   1.0  1.0              0.0              0.0              0.0   \n",
       "48839   1.0  0.0              0.0              0.0              0.0   \n",
       "48840   1.0  1.0              0.0              1.0              0.0   \n",
       "48841   1.0  0.0              0.0              0.0              0.0   \n",
       "\n",
       "       Age (decade)=40  Age (decade)=50  Age (decade)=60  Age (decade)=>=70  \\\n",
       "0                  0.0              0.0              0.0                0.0   \n",
       "1                  0.0              0.0              0.0                0.0   \n",
       "2                  0.0              0.0              0.0                0.0   \n",
       "3                  1.0              0.0              0.0                0.0   \n",
       "4                  0.0              0.0              0.0                0.0   \n",
       "...                ...              ...              ...                ...   \n",
       "48837              0.0              0.0              0.0                0.0   \n",
       "48838              1.0              0.0              0.0                0.0   \n",
       "48839              0.0              1.0              0.0                0.0   \n",
       "48840              0.0              0.0              0.0                0.0   \n",
       "48841              0.0              1.0              0.0                0.0   \n",
       "\n",
       "       Education Years=6  Education Years=7  Education Years=8  \\\n",
       "0                    0.0                1.0                0.0   \n",
       "1                    0.0                0.0                0.0   \n",
       "2                    0.0                0.0                0.0   \n",
       "3                    0.0                0.0                0.0   \n",
       "4                    0.0                0.0                0.0   \n",
       "...                  ...                ...                ...   \n",
       "48837                0.0                0.0                0.0   \n",
       "48838                0.0                0.0                0.0   \n",
       "48839                0.0                0.0                0.0   \n",
       "48840                0.0                0.0                0.0   \n",
       "48841                0.0                0.0                0.0   \n",
       "\n",
       "       Education Years=9  Education Years=10  Education Years=11  \\\n",
       "0                    0.0                 0.0                 0.0   \n",
       "1                    1.0                 0.0                 0.0   \n",
       "2                    0.0                 0.0                 0.0   \n",
       "3                    0.0                 1.0                 0.0   \n",
       "4                    0.0                 1.0                 0.0   \n",
       "...                  ...                 ...                 ...   \n",
       "48837                0.0                 0.0                 0.0   \n",
       "48838                1.0                 0.0                 0.0   \n",
       "48839                1.0                 0.0                 0.0   \n",
       "48840                1.0                 0.0                 0.0   \n",
       "48841                1.0                 0.0                 0.0   \n",
       "\n",
       "       Education Years=12  Education Years=<6  Education Years=>12  \\\n",
       "0                     0.0                 0.0                  0.0   \n",
       "1                     0.0                 0.0                  0.0   \n",
       "2                     1.0                 0.0                  0.0   \n",
       "3                     0.0                 0.0                  0.0   \n",
       "4                     0.0                 0.0                  0.0   \n",
       "...                   ...                 ...                  ...   \n",
       "48837                 1.0                 0.0                  0.0   \n",
       "48838                 0.0                 0.0                  0.0   \n",
       "48839                 0.0                 0.0                  0.0   \n",
       "48840                 0.0                 0.0                  0.0   \n",
       "48841                 0.0                 0.0                  0.0   \n",
       "\n",
       "       Income Binary  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                1.0  \n",
       "3                1.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "48837            0.0  \n",
       "48838            1.0  \n",
       "48839            0.0  \n",
       "48840            0.0  \n",
       "48841            1.0  \n",
       "\n",
       "[48842 rows x 19 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = load_preproc_data_adult(['sex'])\n",
    "d.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>Age (decade)=10</th>\n",
       "      <th>Age (decade)=20</th>\n",
       "      <th>Age (decade)=30</th>\n",
       "      <th>Age (decade)=40</th>\n",
       "      <th>Age (decade)=50</th>\n",
       "      <th>Age (decade)=60</th>\n",
       "      <th>Age (decade)=&gt;=70</th>\n",
       "      <th>Education Years=6</th>\n",
       "      <th>Education Years=7</th>\n",
       "      <th>Education Years=8</th>\n",
       "      <th>Education Years=9</th>\n",
       "      <th>Education Years=10</th>\n",
       "      <th>Education Years=11</th>\n",
       "      <th>Education Years=12</th>\n",
       "      <th>Education Years=&lt;6</th>\n",
       "      <th>Education Years=&gt;12</th>\n",
       "      <th>Income Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.428701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>5.094580</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>1.666646</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>5.432051</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.428701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>1.885327</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>1.868149</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.296390</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>1.868149</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>5.432051</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>1.885327</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>2.525680</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>2.525680</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           race  sex  Age (decade)=10  Age (decade)=20  Age (decade)=30  \\\n",
       "0     -2.428701  1.0        -0.232754         1.751705        -0.600007   \n",
       "1      0.411743  1.0        -0.232754        -0.570872         1.666646   \n",
       "2      0.411743  1.0        -0.232754         1.751705        -0.600007   \n",
       "3     -2.428701  1.0        -0.232754        -0.570872        -0.600007   \n",
       "4      0.411743  0.0         4.296390        -0.570872        -0.600007   \n",
       "...         ...  ...              ...              ...              ...   \n",
       "48837  0.411743  0.0        -0.232754         1.751705        -0.600007   \n",
       "48838  0.411743  1.0        -0.232754        -0.570872        -0.600007   \n",
       "48839  0.411743  0.0        -0.232754        -0.570872        -0.600007   \n",
       "48840  0.411743  1.0        -0.232754         1.751705        -0.600007   \n",
       "48841  0.411743  0.0        -0.232754        -0.570872        -0.600007   \n",
       "\n",
       "       Age (decade)=40  Age (decade)=50  Age (decade)=60  Age (decade)=>=70  \\\n",
       "0            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "1            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "2            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "3             1.885327        -0.395933        -0.258261          -0.144649   \n",
       "4            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "...                ...              ...              ...                ...   \n",
       "48837        -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "48838         1.885327        -0.395933        -0.258261          -0.144649   \n",
       "48839        -0.530412         2.525680        -0.258261          -0.144649   \n",
       "48840        -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "48841        -0.530412         2.525680        -0.258261          -0.144649   \n",
       "\n",
       "       Education Years=6  Education Years=7  Education Years=8  \\\n",
       "0              -0.171088           5.094580          -0.116769   \n",
       "1              -0.171088          -0.196287          -0.116769   \n",
       "2              -0.171088          -0.196287          -0.116769   \n",
       "3              -0.171088          -0.196287          -0.116769   \n",
       "4              -0.171088          -0.196287          -0.116769   \n",
       "...                  ...                ...                ...   \n",
       "48837          -0.171088          -0.196287          -0.116769   \n",
       "48838          -0.171088          -0.196287          -0.116769   \n",
       "48839          -0.171088          -0.196287          -0.116769   \n",
       "48840          -0.171088          -0.196287          -0.116769   \n",
       "48841          -0.171088          -0.196287          -0.116769   \n",
       "\n",
       "       Education Years=9  Education Years=10  Education Years=11  \\\n",
       "0              -0.690988           -0.535289           -0.209896   \n",
       "1               1.447204           -0.535289           -0.209896   \n",
       "2              -0.690988           -0.535289           -0.209896   \n",
       "3              -0.690988            1.868149           -0.209896   \n",
       "4              -0.690988            1.868149           -0.209896   \n",
       "...                  ...                 ...                 ...   \n",
       "48837          -0.690988           -0.535289           -0.209896   \n",
       "48838           1.447204           -0.535289           -0.209896   \n",
       "48839           1.447204           -0.535289           -0.209896   \n",
       "48840           1.447204           -0.535289           -0.209896   \n",
       "48841           1.447204           -0.535289           -0.209896   \n",
       "\n",
       "       Education Years=12  Education Years=<6  Education Years=>12  \\\n",
       "0               -0.184093           -0.234702            -0.574182   \n",
       "1               -0.184093           -0.234702            -0.574182   \n",
       "2                5.432051           -0.234702            -0.574182   \n",
       "3               -0.184093           -0.234702            -0.574182   \n",
       "4               -0.184093           -0.234702            -0.574182   \n",
       "...                   ...                 ...                  ...   \n",
       "48837            5.432051           -0.234702            -0.574182   \n",
       "48838           -0.184093           -0.234702            -0.574182   \n",
       "48839           -0.184093           -0.234702            -0.574182   \n",
       "48840           -0.184093           -0.234702            -0.574182   \n",
       "48841           -0.184093           -0.234702            -0.574182   \n",
       "\n",
       "       Income Binary  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                1.0  \n",
       "3                1.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "48837            0.0  \n",
       "48838            1.0  \n",
       "48839            0.0  \n",
       "48840            0.0  \n",
       "48841            1.0  \n",
       "\n",
       "[48842 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_orig = StandardScaler()\n",
    "d.features = scale_orig.fit_transform(d.features)\n",
    "d.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.169e+03\n",
      " 7.978e+03 0.000e+00 0.000e+00 1.102e+03 7.786e+03 0.000e+00 0.000e+00\n",
      " 6.700e+01 1.920e+02 0.000e+00 0.000e+00 1.000e+00 1.000e+00]\n",
      "[0.124  0.2587 0.8816]\n"
     ]
    }
   ],
   "source": [
    "# Individual Testing\n",
    "dataset_name = \"bank\"\n",
    "\n",
    "dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "\n",
    "#print(\"Specialized function: \", dataset_name)\n",
    "#dataset = get_OP_dataset(dataset_name) \n",
    "\n",
    "scale_orig = StandardScaler()\n",
    "dataset.features = scale_orig.fit_transform(dataset.features)\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=7)\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "#pre = LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0)\n",
    "#pre = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\n",
    "'''\n",
    "pre = OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups)\n",
    "pre.fit(dataset_train_pred)\n",
    "dataset_train_pred = pre.transform(dataset_train_pred)\n",
    "dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "dataset_test_pred = pre.transform(dataset_test_pred)\n",
    "dataset_test_pred = dataset_test.align_datasets(dataset_test_pred)\n",
    "'''\n",
    "\n",
    "'''\n",
    "X_train = dataset_train_pred.features\n",
    "y_train = dataset_train_pred.labels #.ravel()\n",
    "model = LogisticRegression()  \n",
    "model.fit(X_train, y_train)\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1)\n",
    "dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)     \n",
    "'''\n",
    "\n",
    "#inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "#inp = inprocessing.PrejudiceRemover(sensitive_attr=pro_attr)\n",
    "#inp = GerryFairClassifier()\n",
    "#inp.fit(dataset_train_pred)\n",
    "\n",
    "\n",
    "#dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "#dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "#dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "#dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "\n",
    "#dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "#dataset_test_pred = inp.predict(dataset_test_pred)\n",
    "\n",
    "'''\n",
    "y_train_pred = np.zeros_like(dataset_train_pred.scores)\n",
    "y_train_pred[dataset_train_pred.scores >= class_thresh] = dataset_train_pred.favorable_label\n",
    "y_train_pred[~(dataset_train_pred.scores >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_test_pred.scores)\n",
    "y_test_pred[dataset_test_pred.scores >= class_thresh] = dataset_test_pred.favorable_label\n",
    "y_test_pred[~(dataset_test_pred.scores >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "dataset_test_pred.labels = y_test_pred\n",
    "#dataset_test_pred.labels = y_test_pred#dataset_train_pred.features = dataset_train.features\n",
    "'''\n",
    "\n",
    "#pp = postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=7)\n",
    "#pp = postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "#pp = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0)\n",
    "#dataset_train_pred.features = dataset_train.features\n",
    "#pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "#dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "\n",
    "BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "dataset_test_pred.features = dataset_test.features \n",
    "CM = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "    \n",
    "\n",
    "print(run_classification_metrics(CM))\n",
    "print(run_binary_dataset_metrics(BLDM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12780146496118946, 0.123987398739874, 0.25868725868725867)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLDM.base_rate(), BLDM.base_rate(privileged=True), BLDM.base_rate(privileged=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    26629\n",
       "1.0     3859\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BankDataset().convert_to_dataframe()[0][\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BankDataset().favorable_label, GermanDataset().favorable_label, load_preproc_data_german(['age']).favorable_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BankDataset().unprivileged_protected_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>665</td>\n",
       "      <td>199</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>25964</td>\n",
       "      <td>3660</td>\n",
       "      <td>29624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>26629</td>\n",
       "      <td>3859</td>\n",
       "      <td>30488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y      0.0   1.0    All\n",
       "age                    \n",
       "0.0    665   199    864\n",
       "1.0  25964  3660  29624\n",
       "All  26629  3859  30488"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = BankDataset().convert_to_dataframe()[0]\n",
    "pd.crosstab(b[\"age\"], b[\"y\"], normalize=False, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23032407407407407, 0.12354847421009992)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "199/864, 3660/29624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3353.0, 'FP': 10214.0, 'TN': 0.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "dataset_test_pred = inp.predict(dataset_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3330.0, 'FP': 0.0, 'TN': 10237.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_train.metadata  #.labels.ravel()\n",
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566666666666667"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(dataset_test.labels, dataset_test_pred.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_pred.labels = dataset_test_pred.labels.astype('float64') #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aif360.datasets.german_dataset.GermanDataset"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(dataset_test_pred.labels[0][0])\n",
    "type(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.grid_search_reduction.GridSearchReduction at 0x24a2689c850>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GermanDataset()\n",
    "dataset.labels = dataset.labels-1\n",
    "inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "inp.fit(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
