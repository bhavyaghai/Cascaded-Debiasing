{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import aif360\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "            import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "\n",
    "import art\n",
    "\n",
    "import copy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.consistency()[0], 4),\n",
    "        round(CM.false_positive_rate_difference(), 4),\n",
    "        round(CM.false_negative_rate_difference(), 4),\n",
    "        round(-CM.error_rate_difference(), 4),\n",
    "        round(CM.false_discovery_rate_difference(), 4),\n",
    "        round(CM.false_omission_rate_difference(), 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    return np.array([\n",
    "        round(BLDM.statistical_parity_difference(), 4), # negative means privileged bias\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparison_algo(inprocessing_algo):\n",
    "    if isinstance(inprocessing_algo, inprocessing.PrejudiceRemover):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.GerryFairClassifier):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.MetaFairClassifier):\n",
    "        return BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "    if isinstance(inprocessing_algo, inprocessing.ExponentiatedGradientReduction):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.GridSearchReduction):\n",
    "        return sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, preprocessing.DisparateImpactRemover):\n",
    "        return \"Disparate Impact Remover\"\n",
    "    if isinstance(model, preprocessing.LFR):\n",
    "        return \"Learning Fair Representations\"\n",
    "    if isinstance(model, preprocessing.OptimPreproc):\n",
    "        return \"Optimized Preprocessing\"\n",
    "    if isinstance(model, preprocessing.Reweighing):\n",
    "        return \"Reweighing\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"Prejudice Remover\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"Adversarial Debiasing\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ART Classifier\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"Exp Grad Reduction\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GerryFair Classifier\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GridSearch Reduction\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MetaFair Classifier\"\n",
    "    \n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"Eq Odds Post.\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"Calibrated Eq Odds Post.\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"RejectOption Classification\"\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if isinstance(dataset, aif360.datasets.german_dataset.GermanDataset):\n",
    "        return \"German Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.adult_dataset.AdultDataset):\n",
    "        return \"Adult Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.bank_dataset.BankDataset):\n",
    "        return \"Bank Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.compas_dataset.CompasDataset):\n",
    "        return \"Compas Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim_preproc_options_dict(dataset):\n",
    "    if isinstance(dataset, aif360.datasets.german_dataset.GermanDataset):\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_german,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "    elif isinstance(dataset, aif360.datasets.adult_dataset.AdultDataset):\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_adult,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "    elif isinstance(dataset, aif360.datasets.bank_dataset.BankDataset):\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_bank,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "    elif isinstance(dataset, aif360.datasets.compas_dataset.CompasDataset):\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_compas,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "    return optim_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_base(dataset_train, dataset_test, model):\n",
    "    model.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = model.predict(dataset_test.features)\n",
    "    \n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        results = np.rint(results)\n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    return np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, classifier=None, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None):\n",
    "    base = sklearn.linear_model.LogisticRegression()\n",
    "    if inprocessing_algo is not None:\n",
    "        base = get_comparison_algo(inprocessing_algo)\n",
    "    '''base.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = base.predict(dataset_test.features)\n",
    "    if isinstance(base, sklearn.linear_model.LinearRegression):\n",
    "        results = np.rint(results)\n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()'''\n",
    "    \n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "    \n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(dataset_train.features)\n",
    "    y_train = dataset_train.labels.ravel()\n",
    "    model = base\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "    y_train_pred_prob = model.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "    # Prediction probs for testing data\n",
    "    X_test = scale_orig.transform(dataset_test.features)\n",
    "    y_test_pred_prob = model.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "    dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "    dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "    class_thresh = 0.5\n",
    "    y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "    y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "    y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "    dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "    y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "    y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "    y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "    dataset_test_pred.labels = y_test_pred\n",
    "    \n",
    "    \n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "    df = pd.DataFrame(metrics, columns=[get_model_name(base)])\n",
    "    df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "                \"false negative rate difference\", \"accuracy difference\",\n",
    "                \"false discovery rate difference\", \"false omission rate difference\",\n",
    "                \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "    \n",
    "    if preprocessing_algo is not None:\n",
    "        dataset_train = preprocessing_algo.fit_transform(dataset_train)\n",
    "    \n",
    "    if inprocessing_algo is not None:\n",
    "        inprocessing_algo.fit(dataset_train)\n",
    "        fair_results = inprocessing_algo.predict(dataset_test)\n",
    "        dataset_test_pred = dataset_test.copy()\n",
    "        dataset_test_pred.labels = fair_results.labels\n",
    "        #dataset_test_pred = results\n",
    "        \n",
    "        dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "        dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "        scale_orig = StandardScaler()\n",
    "        X_train = scale_orig.fit_transform(dataset_train.features)\n",
    "        y_train = dataset_train.labels.ravel()\n",
    "        inprocessing_algo.fit(dataset_train)\n",
    "\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        y_train_pred_prob = inprocessing_algo.predict(dataset_train).favorable_label\n",
    "\n",
    "        # Prediction probs for testing data\n",
    "        X_test = scale_orig.transform(dataset_test.features)\n",
    "        y_test_pred_prob = inprocessing_algo.predict(dataset_test)\n",
    "\n",
    "        dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "        dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "        class_thresh = 0.5\n",
    "        y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "        y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "        y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "        dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "        y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "        y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "        y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "        dataset_test_pred.labels = y_test_pred\n",
    "    else:\n",
    "        dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "        dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "        scale_orig = StandardScaler()\n",
    "        X_train = scale_orig.fit_transform(dataset_train.features)\n",
    "        y_train = dataset_train.labels.ravel()\n",
    "        model = base\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        y_train_pred_prob = model.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "        # Prediction probs for testing data\n",
    "        X_test = scale_orig.transform(dataset_test.features)\n",
    "        y_test_pred_prob = model.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "        dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "        dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "        class_thresh = 0.5\n",
    "        y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "        y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "        y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "        dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "        y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "        y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "        y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "        dataset_test_pred.labels = y_test_pred\n",
    "    \n",
    "    if postprocessing_algo is not None:\n",
    "        dataset_test_pred = postprocessing_algo.fit_predict(dataset_test, dataset_test_pred)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    name = \"\"\n",
    "    if preprocessing_algo is not None:\n",
    "        name += get_model_name(preprocessing_algo) + \" + \"\n",
    "    if inprocessing_algo is not None:\n",
    "        name += get_model_name(inprocessing_algo) + \" + \"\n",
    "    if postprocessing_algo is not None:\n",
    "        name += get_model_name(postprocessing_algo)\n",
    "    df[name] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inproc_algo(dataset_train, dataset_test, unprivileged_groups, privileged_groups, inprocessing_algo, ):\n",
    "\n",
    "    base = get_comparison_algo(inprocessing_algo)\n",
    "\n",
    "    metrics = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, base)\n",
    "    df = pd.DataFrame(metrics, columns=[get_model_name(base)])\n",
    "    df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "                \"false negative rate difference\", \"accuracy difference\",\n",
    "                \"false discovery rate difference\", \"false omission rate difference\",\n",
    "                \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "    if isinstance(dataset, GermanDataset) and isinstance(inprocessing_algo, inprocessing.GridSearchReduction):\n",
    "        dataset_train = dataset_train.copy()\n",
    "        dataset_train.labels = dataset_train.labels%2\n",
    "        dataset_test = dataset_test.copy()\n",
    "        dataset_test.labels = dataset_test.labels%2\n",
    "                  \n",
    "    df[get_model_name(inprocessing_algo)] = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, inprocessing_algo=inprocessing_algo)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-77d2ef4fea5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessing_algos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 df = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, \n\u001b[0m\u001b[1;32m     26\u001b[0m                          \u001b[0mpreprocessing_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                          \u001b[0minprocessing_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-8bd37e49836b>\u001b[0m in \u001b[0;36manalyze_algo\u001b[0;34m(dataset_train, dataset_test, privileged_groups, unprivileged_groups, classifier, preprocessing_algo, inprocessing_algo, postprocessing_algo)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0my_test_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minprocessing_algo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mdataset_train_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_pred_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mdataset_test_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_pred_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'reshape'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"15b203ae-443b-47ec-964b-8b26812e08c1\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"15b203ae-443b-47ec-964b-8b26812e08c1\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "dataset = CompasDataset()\n",
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "preprocessing_algos = [preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                      preprocessing.DisparateImpactRemover(),\n",
    "                      None]\n",
    "inprocessing_algos = [#inprocessing.ExponentiatedGradientReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                     inprocessing.GerryFairClassifier(),\n",
    "                     inprocessing.GridSearchReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                     inprocessing.MetaFairClassifier(),\n",
    "                     inprocessing.PrejudiceRemover(),\n",
    "                     None]\n",
    "postprocessing_algos = [postprocessing.calibrated_eq_odds_postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                        postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                        #postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                        None]\n",
    "\n",
    "for post in postprocessing_algos:\n",
    "    for inproc in inprocessing_algos:\n",
    "        for pre in preprocessing_algos:\n",
    "            try:\n",
    "                df = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, \n",
    "                         preprocessing_algo=copy.deepcopy(pre), \n",
    "                         inprocessing_algo=copy.deepcopy(inproc),\n",
    "                         postprocessing_algo=copy.deepcopy(post))\n",
    "                display(df)\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            #except:\n",
    "            #    print(\"FAILED: \" + get_model_name(pre) + \", \" + get_model_name(inproc) + \", \" + get_model_name(post) + \" on dataset \" + get_dataset_name(dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disregard everything underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%notify\n",
    "dataset = CompasDataset()\n",
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "'''dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]'''\n",
    "'''dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]'''\n",
    "'''dataset = AdultDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]'''\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "\n",
    "base_model = sklearn.linear_model.LogisticRegression()\n",
    "base_metrics = run_base(dataset_train, dataset_test, base_model)\n",
    "\n",
    "df = pd.DataFrame(base_metrics, columns=[\"Logistic Regression\"])\n",
    "df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "            \"false negative rate difference\", \"accuracy difference\",\n",
    "            \"false discovery rate difference\", \"false omission rate difference\",\n",
    "            \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "\n",
    "RW = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "fair_dataset_train = RW.fit_transform(dataset_train.copy())\n",
    "\n",
    "fair_base_model = sklearn.linear_model.LogisticRegression()\n",
    "fair_base_model.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "results = fair_base_model.predict(dataset_test.features)\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "EOP = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "CM = ClassificationMetric(dataset_test, EOP.fit_predict(dataset_test, dataset_test_pred), unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "df[\"RW + EOP\"] = run_classification_metrics(CM)\n",
    "\n",
    "''''''\n",
    "DIR = preprocessing.DisparateImpactRemover()\n",
    "fair_dataset_train = DIR.fit_transform(dataset_train.copy())\n",
    "\n",
    "fair_base_model = sklearn.linear_model.LogisticRegression()\n",
    "fair_base_model.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "results = fair_base_model.predict(dataset_test.features)\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "EOP = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "CM = ClassificationMetric(dataset_test, EOP.fit_predict(dataset_test, dataset_test_pred), unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "df[\"DIR + EOP\"] = run_classification_metrics(CM)\n",
    "\n",
    "''''''\n",
    "'''optim_options = get_optim_preproc_options_dict(dataset)\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "              unprivileged_groups = unprivileged_groups,\n",
    "              privileged_groups = privileged_groups)\n",
    "fair_dataset_train = OP.fit_transform(dataset_train.copy())\n",
    "\n",
    "fair_base_model = RandomForestClassifier(n_estimators=1100)\n",
    "fair_base_model.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "results = fair_base_model.predict(dataset_test.features)\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "EOP = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "CM = ClassificationMetric(dataset_test, EOP.fit_predict(dataset_test, dataset_test_pred), unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "BLDM = BinaryLabelDatasetMetric(fair_dataset_train,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "df[\"OP + EOP\"] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))'''\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "#dataset.labels = dataset.labels%2\n",
    "\n",
    "preprocessing_algos = [preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                      preprocessing.DisparateImpactRemover(),\n",
    "                      None]\n",
    "inprocessing_algos = [inprocessing.ExponentiatedGradientReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                     inprocessing.GerryFairClassifier(),\n",
    "                     inprocessing.GridSearchReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                     inprocessing.MetaFairClassifier(),\n",
    "                     inprocessing.PrejudiceRemover(),\n",
    "                     None]\n",
    "postprocessing_algos = [postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                       None]\n",
    "\n",
    "pre = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "inproc = inprocessing.GerryFairClassifier()\n",
    "post = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "df = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, \n",
    "                     #preprocessing_algo=copy.deepcopy(pre), \n",
    "                     inprocessing_algo=inproc,\n",
    "                     #postprocessing_algo=post\n",
    "                 )\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
