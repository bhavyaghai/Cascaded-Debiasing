{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from aif360.algorithms.inprocessing import GerryFairClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "import copy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    def f1_score(priv=None):\n",
    "            numer = CM.num_true_positives(privileged=priv)\n",
    "            denom = CM.num_true_positives(privileged=priv) + 0.5*float(CM.num_false_positives(privileged=priv) + CM.num_false_negatives(privileged=priv))\n",
    "            return float(numer/denom)\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.false_positive_rate(privileged=False), 4),\n",
    "        round(CM.false_positive_rate(privileged=True), 4),\n",
    "        round(CM.false_negative_rate(privileged=False), 4),\n",
    "        round(CM.false_negative_rate(privileged=True), 4),\n",
    "        round(1-CM.error_rate(privileged=False), 4),\n",
    "        round(1-CM.error_rate(privileged=True), 4),\n",
    "        round(CM.false_discovery_rate(privileged=False), 4),\n",
    "        round(CM.false_discovery_rate(privileged=True), 4),\n",
    "        round(CM.false_omission_rate(privileged=False), 4),\n",
    "        round(CM.false_omission_rate(privileged=True), 4),\n",
    "        \n",
    "        #all results\n",
    "        CM.num_true_positives(),\n",
    "        CM.num_true_negatives(),\n",
    "        CM.num_false_positives(),\n",
    "        CM.num_false_negatives(),\n",
    "        \n",
    "        #privileged\n",
    "        CM.num_true_positives(privileged=True),\n",
    "        CM.num_true_negatives(privileged=True),\n",
    "        CM.num_false_positives(privileged=True),\n",
    "        CM.num_false_negatives(privileged=True),\n",
    "        \n",
    "        #unprivileged\n",
    "        CM.num_true_positives(privileged=False),\n",
    "        CM.num_true_negatives(privileged=False),\n",
    "        CM.num_false_positives(privileged=False),\n",
    "        CM.num_false_negatives(privileged=False),\n",
    "        \n",
    "        round(f1_score(), 4),\n",
    "        round(f1_score(True), 4),\n",
    "        round(f1_score(False), 4),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    #print(\"Consistency: \", BLDM.consistency())\n",
    "    return np.array([\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "        round(BLDM.consistency()[0], 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, preprocessing.DisparateImpactRemover):\n",
    "        return \"DIR\"\n",
    "    if isinstance(model, preprocessing.LFR):\n",
    "        return \"LFR\"\n",
    "    if isinstance(model, preprocessing.OptimPreproc):\n",
    "        return \"OP\"\n",
    "    if isinstance(model, preprocessing.Reweighing):\n",
    "        return \"RW\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"PR\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"AD\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ARTC\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"EGR\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GFC\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GSR\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MFC\"\n",
    "    \n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"EOP\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"CEOP\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"ROC\"\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if isinstance(dataset, aif360.datasets.german_dataset.GermanDataset):\n",
    "        return \"German Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.adult_dataset.AdultDataset):\n",
    "        return \"Adult Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.bank_dataset.BankDataset):\n",
    "        return \"Bank Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.compas_dataset.CompasDataset):\n",
    "        return \"Compas Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, classifier=None, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None):\n",
    "    print(get_model_name(preprocessing_algo), get_model_name(inprocessing_algo), get_model_name(postprocessing_algo))\n",
    "\n",
    "    model = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "    \n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "    \n",
    "    '''\n",
    "    scale_orig = StandardScaler()\n",
    "    dataset_train.features = scale_orig.fit_transform(dataset_train.features)\n",
    "    dataset_test.features = scale_orig.fit_transform(dataset_test.features)\n",
    "    dataset_train_pred.features = scale_orig.fit_transform(dataset_train_pred.features)\n",
    "    dataset_test_pred.features = scale_orig.fit_transform(dataset_test_pred.features)\n",
    "    '''   \n",
    "\n",
    "    #if preprocessing_algo is None and inprocessing_algo is None and postprocessing_algo is None:\n",
    "    X_train = dataset_train_pred.features\n",
    "    y_train = dataset_train_pred.labels #.ravel()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "    # scores for train dataset required for post-processing algos\n",
    "    dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "    dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1) \n",
    "    dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "    dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1) \n",
    "    \n",
    "    #class_thresh = 0.5\n",
    "    #y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "    #y_test_pred[dataset_test_pred.scores >= class_thresh] = dataset_test_pred.favorable_label\n",
    "    #y_test_pred[~(dataset_test_pred.scores >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "    #dataset_test_pred.labels = y_test_pred\n",
    "        \n",
    "    if preprocessing_algo is not None:\n",
    "        #dataset_train_pred = preprocessing_algo.fit_transform(dataset_train_pred)\n",
    "        #dataset_train_pred = dataset_test_pred.align_datasets(dataset_train_pred)\n",
    "        \n",
    "        dataset_train_pred = preprocessing_algo.fit_transform(dataset_train_pred)\n",
    "        dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "        \n",
    "        #dataset_test_pred = preprocessing_algo.fit_transform(dataset_test_pred)\n",
    "        \n",
    "        model.fit(dataset_train_pred.features, dataset_train_pred.labels)   # .ravel()\n",
    "        # sample_weight=dataset_train_pred.instance_weights\n",
    "\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1) \n",
    "        dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "\n",
    "        #class_thresh = 0.5\n",
    "        #y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "        #y_test_pred[dataset_test_pred.scores >= class_thresh] = dataset_test_pred.favorable_label\n",
    "        #y_test_pred[~(dataset_test_pred.scores >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "        #dataset_test_pred.labels = y_test_pred\n",
    "        dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)  \n",
    "    \n",
    "    if inprocessing_algo is not None:\n",
    "        model = inprocessing_algo\n",
    "        model.fit(dataset_train_pred)\n",
    "        dataset_train_pred = model.predict(dataset_train_pred)\n",
    "        dataset_test_pred = model.predict(dataset_test_pred) \n",
    "        \n",
    "    if postprocessing_algo is not None:\n",
    "        pp = postprocessing_algo\n",
    "        pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "        dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    \n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    name = \"\"\n",
    "    if preprocessing_algo is not None:\n",
    "        name += get_model_name(preprocessing_algo) + \" + \"\n",
    "    if inprocessing_algo is not None:\n",
    "        name += get_model_name(inprocessing_algo) + \" + \"\n",
    "    if postprocessing_algo is not None:\n",
    "        name += get_model_name(postprocessing_algo)\n",
    "    if name == \"\":\n",
    "        name = get_model_name(model)\n",
    "        \n",
    "    if name.endswith(\" + \"):\n",
    "        lastIndex = name.rindex(\" + \")\n",
    "        name = name[:lastIndex]\n",
    "    \n",
    "    #print(run_classification_metrics(CM))\n",
    "    #print(run_binary_dataset_metrics(BLDM))\n",
    "    metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "       \n",
    "    return {\"key\":name, \"val\":metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_options(dataset_name):\n",
    "    optim_options = {\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "    }\n",
    "    if dataset_name==\"adult\":\n",
    "        optim_options[\"distortion_fun\"] = get_distortion_adult\n",
    "        pro_attr = 'sex'\n",
    "        return (load_preproc_data_adult(['sex']), pro_attr, [{'sex': 1}], [{'sex': 0}], optim_options)\n",
    "    elif dataset_name==\"compas\":\n",
    "        optim_options[\"distortion_fun\"] = get_distortion_compas\n",
    "        pro_attr = 'race'\n",
    "        return (load_preproc_data_compas(['race']), pro_attr, [{'race': 1}], [{'race': 0}], optim_options)\n",
    "    elif dataset_name==\"bank\":\n",
    "        pro_attr = 'age'\n",
    "        return (BankDataset(protected_attribute_names=['age'],\n",
    "            privileged_classes=[lambda x: x >= 25], \n",
    "            features_to_drop=['day_of_week']), pro_attr, [{'age': 1}], [{'age': 0}], None)\n",
    "    elif dataset_name==\"german\":\n",
    "        pro_attr = 'age'\n",
    "        #g = load_preproc_data_german(['age'])\n",
    "        #g.labels = g.labels -1\n",
    "        g = GermanDataset()\n",
    "        optim_options[\"distortion_fun\"] = get_distortion_german\n",
    "        # load_preproc_data_german(['age'])\n",
    "        return (g, pro_attr, \n",
    "                    [{'age': 1}], [{'age': 0}], optim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  german\n",
      "None None EOP\n",
      "None None CEOP\n",
      "None None ROC\n",
      "None None None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Theil Index</th>\n",
       "      <th>False Positive Rate - Unprivileged</th>\n",
       "      <th>False Positive Rate - Privileged</th>\n",
       "      <th>False Negative Rate - Unprivileged</th>\n",
       "      <th>False Negative Rate - Privileged</th>\n",
       "      <th>Accuracy - Unprivileged</th>\n",
       "      <th>Accuracy - Privileged</th>\n",
       "      <th>False Discovery Rate - Unprivileged</th>\n",
       "      <th>False Discovery Rate - Privileged</th>\n",
       "      <th>...</th>\n",
       "      <th>Num True Pos - Unprivileged</th>\n",
       "      <th>Num True Neg - Unprivileged</th>\n",
       "      <th>Num False Pos - Unprivileged</th>\n",
       "      <th>Num False Neg - Unprivileged</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F1 Score - Privileged</th>\n",
       "      <th>F1 Score - Unprivileged</th>\n",
       "      <th>Privileged base Rate</th>\n",
       "      <th>Unprivileged base Rate</th>\n",
       "      <th>Consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EOP</th>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7746</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>0.6393</td>\n",
       "      <td>0.6707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEOP</th>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.7280</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2620</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.8433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.2697</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.7649</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>0.8204</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Theil Index  \\\n",
       "EOP                    0.6800       0.2148   \n",
       "CEOP                   0.7200       0.1047   \n",
       "ROC                    0.6867       0.2697   \n",
       "Logistic Regression    0.7133       0.1584   \n",
       "\n",
       "                     False Positive Rate - Unprivileged  \\\n",
       "EOP                                              0.4167   \n",
       "CEOP                                             0.3750   \n",
       "ROC                                              0.3750   \n",
       "Logistic Regression                              0.3750   \n",
       "\n",
       "                     False Positive Rate - Privileged  \\\n",
       "EOP                                            0.6154   \n",
       "CEOP                                           0.9231   \n",
       "ROC                                            0.3538   \n",
       "Logistic Regression                            0.7077   \n",
       "\n",
       "                     False Negative Rate - Unprivileged  \\\n",
       "EOP                                              0.2162   \n",
       "CEOP                                             0.2703   \n",
       "ROC                                              0.2703   \n",
       "Logistic Regression                              0.2703   \n",
       "\n",
       "                     False Negative Rate - Privileged  \\\n",
       "EOP                                            0.2184   \n",
       "CEOP                                           0.0287   \n",
       "ROC                                            0.2989   \n",
       "Logistic Regression                            0.1207   \n",
       "\n",
       "                     Accuracy - Unprivileged  Accuracy - Privileged  \\\n",
       "EOP                                   0.7049                 0.6736   \n",
       "CEOP                                  0.6885                 0.7280   \n",
       "ROC                                   0.6885                 0.6862   \n",
       "Logistic Regression                   0.6885                 0.7197   \n",
       "\n",
       "                     False Discovery Rate - Unprivileged  \\\n",
       "EOP                                               0.2564   \n",
       "CEOP                                              0.2500   \n",
       "ROC                                               0.2500   \n",
       "Logistic Regression                               0.2500   \n",
       "\n",
       "                     False Discovery Rate - Privileged  ...  \\\n",
       "EOP                                             0.2273  ...   \n",
       "CEOP                                            0.2620  ...   \n",
       "ROC                                             0.1586  ...   \n",
       "Logistic Regression                             0.2312  ...   \n",
       "\n",
       "                     Num True Pos - Unprivileged  Num True Neg - Unprivileged  \\\n",
       "EOP                                         29.0                         14.0   \n",
       "CEOP                                        27.0                         15.0   \n",
       "ROC                                         27.0                         15.0   \n",
       "Logistic Regression                         27.0                         15.0   \n",
       "\n",
       "                     Num False Pos - Unprivileged  \\\n",
       "EOP                                          10.0   \n",
       "CEOP                                          9.0   \n",
       "ROC                                           9.0   \n",
       "Logistic Regression                           9.0   \n",
       "\n",
       "                     Num False Neg - Unprivileged  F1 Score  \\\n",
       "EOP                                           8.0    0.7746   \n",
       "CEOP                                         10.0    0.8235   \n",
       "ROC                                          10.0    0.7602   \n",
       "Logistic Regression                          10.0    0.8072   \n",
       "\n",
       "                     F1 Score - Privileged  F1 Score - Unprivileged  \\\n",
       "EOP                                 0.7771                   0.7632   \n",
       "CEOP                                0.8387                   0.7397   \n",
       "ROC                                 0.7649                   0.7397   \n",
       "Logistic Regression                 0.8204                   0.7397   \n",
       "\n",
       "                     Privileged base Rate  Unprivileged base Rate  Consistency  \n",
       "EOP                                0.7364                  0.6393       0.6707  \n",
       "CEOP                               0.9582                  0.5902       0.8433  \n",
       "ROC                                0.6067                  0.5902       0.6200  \n",
       "Logistic Regression                0.8326                  0.5902       0.7200  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  adult\n",
      "None None EOP\n",
      "None None CEOP\n",
      "None None ROC\n",
      "None None None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Theil Index</th>\n",
       "      <th>False Positive Rate - Unprivileged</th>\n",
       "      <th>False Positive Rate - Privileged</th>\n",
       "      <th>False Negative Rate - Unprivileged</th>\n",
       "      <th>False Negative Rate - Privileged</th>\n",
       "      <th>Accuracy - Unprivileged</th>\n",
       "      <th>Accuracy - Privileged</th>\n",
       "      <th>False Discovery Rate - Unprivileged</th>\n",
       "      <th>False Discovery Rate - Privileged</th>\n",
       "      <th>...</th>\n",
       "      <th>Num True Pos - Unprivileged</th>\n",
       "      <th>Num True Neg - Unprivileged</th>\n",
       "      <th>Num False Pos - Unprivileged</th>\n",
       "      <th>Num False Neg - Unprivileged</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F1 Score - Privileged</th>\n",
       "      <th>F1 Score - Unprivileged</th>\n",
       "      <th>Privileged base Rate</th>\n",
       "      <th>Unprivileged base Rate</th>\n",
       "      <th>Consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EOP</th>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.1877</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>0.5043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEOP</th>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.7653</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.4966</td>\n",
       "      <td>0.5487</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>...</td>\n",
       "      <td>414.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>0.4406</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.7653</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.4966</td>\n",
       "      <td>0.5487</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Theil Index  \\\n",
       "EOP                    0.4978       0.1877   \n",
       "CEOP                   0.8069       0.1748   \n",
       "ROC                    0.6918       0.1166   \n",
       "Logistic Regression    0.8069       0.1748   \n",
       "\n",
       "                     False Positive Rate - Unprivileged  \\\n",
       "EOP                                              0.5017   \n",
       "CEOP                                             0.0000   \n",
       "ROC                                              0.3579   \n",
       "Logistic Regression                              0.0000   \n",
       "\n",
       "                     False Positive Rate - Privileged  \\\n",
       "EOP                                            0.5013   \n",
       "CEOP                                           0.1060   \n",
       "ROC                                            0.3071   \n",
       "Logistic Regression                            0.1060   \n",
       "\n",
       "                     False Negative Rate - Unprivileged  \\\n",
       "EOP                                              0.5150   \n",
       "CEOP                                             1.0000   \n",
       "ROC                                              0.2247   \n",
       "Logistic Regression                              1.0000   \n",
       "\n",
       "                     False Negative Rate - Privileged  \\\n",
       "EOP                                            0.5027   \n",
       "CEOP                                           0.5300   \n",
       "ROC                                            0.2532   \n",
       "Logistic Regression                            0.5300   \n",
       "\n",
       "                     Accuracy - Unprivileged  Accuracy - Privileged  \\\n",
       "EOP                                   0.4968                 0.4983   \n",
       "CEOP                                  0.8904                 0.7653   \n",
       "ROC                                   0.6567                 0.7093   \n",
       "Logistic Regression                   0.8904                 0.7653   \n",
       "\n",
       "                     False Discovery Rate - Unprivileged  \\\n",
       "EOP                                               0.8936   \n",
       "CEOP                                              0.0000   \n",
       "ROC                                               0.7894   \n",
       "Logistic Regression                               0.0000   \n",
       "\n",
       "                     False Discovery Rate - Privileged  ...  \\\n",
       "EOP                                             0.6981  ...   \n",
       "CEOP                                            0.3409  ...   \n",
       "ROC                                             0.4854  ...   \n",
       "Logistic Regression                             0.3409  ...   \n",
       "\n",
       "                     Num True Pos - Unprivileged  Num True Neg - Unprivileged  \\\n",
       "EOP                                        259.0                       2161.0   \n",
       "CEOP                                         0.0                       4337.0   \n",
       "ROC                                        414.0                       2785.0   \n",
       "Logistic Regression                          0.0                       4337.0   \n",
       "\n",
       "                     Num False Pos - Unprivileged  \\\n",
       "EOP                                        2176.0   \n",
       "CEOP                                          0.0   \n",
       "ROC                                        1552.0   \n",
       "Logistic Regression                           0.0   \n",
       "\n",
       "                     Num False Neg - Unprivileged  F1 Score  \\\n",
       "EOP                                         275.0    0.3206   \n",
       "CEOP                                        534.0    0.4966   \n",
       "ROC                                         120.0    0.5382   \n",
       "Logistic Regression                         534.0    0.4966   \n",
       "\n",
       "                     F1 Score - Privileged  F1 Score - Unprivileged  \\\n",
       "EOP                                 0.3757                   0.1745   \n",
       "CEOP                                0.5487                   0.0000   \n",
       "ROC                                 0.6093                   0.3312   \n",
       "Logistic Regression                 0.5487                   0.0000   \n",
       "\n",
       "                     Privileged base Rate  Unprivileged base Rate  Consistency  \n",
       "EOP                                0.5001                  0.4999       0.5043  \n",
       "CEOP                               0.2165                  0.0000       0.9999  \n",
       "ROC                                0.4406                  0.4036       0.9997  \n",
       "Logistic Regression                0.2165                  0.0000       0.9999  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  compas\n",
      "None None EOP\n",
      "None None CEOP\n",
      "None None ROC\n",
      "None None None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Theil Index</th>\n",
       "      <th>False Positive Rate - Unprivileged</th>\n",
       "      <th>False Positive Rate - Privileged</th>\n",
       "      <th>False Negative Rate - Unprivileged</th>\n",
       "      <th>False Negative Rate - Privileged</th>\n",
       "      <th>Accuracy - Unprivileged</th>\n",
       "      <th>Accuracy - Privileged</th>\n",
       "      <th>False Discovery Rate - Unprivileged</th>\n",
       "      <th>False Discovery Rate - Privileged</th>\n",
       "      <th>...</th>\n",
       "      <th>Num True Pos - Unprivileged</th>\n",
       "      <th>Num True Neg - Unprivileged</th>\n",
       "      <th>Num False Pos - Unprivileged</th>\n",
       "      <th>Num False Neg - Unprivileged</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F1 Score - Privileged</th>\n",
       "      <th>F1 Score - Unprivileged</th>\n",
       "      <th>Privileged base Rate</th>\n",
       "      <th>Unprivileged base Rate</th>\n",
       "      <th>Consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EOP</th>\n",
       "      <td>0.6174</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.5314</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.2561</td>\n",
       "      <td>0.6063</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.4251</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.6471</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>0.8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEOP</th>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.3341</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.6559</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.3891</td>\n",
       "      <td>0.3249</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>...</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.7024</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>0.5941</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.3341</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.9972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Theil Index  \\\n",
       "EOP                    0.6174       0.2047   \n",
       "CEOP                   0.6534       0.2117   \n",
       "ROC                    0.6559       0.2388   \n",
       "Logistic Regression    0.6616       0.2216   \n",
       "\n",
       "                     False Positive Rate - Unprivileged  \\\n",
       "EOP                                              0.5210   \n",
       "CEOP                                             0.2894   \n",
       "ROC                                              0.3573   \n",
       "Logistic Regression                              0.2894   \n",
       "\n",
       "                     False Positive Rate - Privileged  \\\n",
       "EOP                                            0.5314   \n",
       "CEOP                                           0.7155   \n",
       "ROC                                            0.3891   \n",
       "Logistic Regression                            0.5941   \n",
       "\n",
       "                     False Negative Rate - Unprivileged  \\\n",
       "EOP                                              0.2600   \n",
       "CEOP                                             0.3941   \n",
       "ROC                                              0.3249   \n",
       "Logistic Regression                              0.3941   \n",
       "\n",
       "                     False Negative Rate - Privileged  \\\n",
       "EOP                                            0.2561   \n",
       "CEOP                                           0.1226   \n",
       "ROC                                            0.3215   \n",
       "Logistic Regression                            0.1662   \n",
       "\n",
       "                     Accuracy - Unprivileged  Accuracy - Privileged  \\\n",
       "EOP                                   0.6063                 0.6353   \n",
       "CEOP                                  0.6595                 0.6436   \n",
       "ROC                                   0.6585                 0.6518   \n",
       "Logistic Regression                   0.6595                 0.6650   \n",
       "\n",
       "                     False Discovery Rate - Unprivileged  \\\n",
       "EOP                                               0.4251   \n",
       "CEOP                                              0.3341   \n",
       "ROC                                               0.3573   \n",
       "Logistic Regression                               0.3341   \n",
       "\n",
       "                     False Discovery Rate - Privileged  ...  \\\n",
       "EOP                                             0.3175  ...   \n",
       "CEOP                                            0.3469  ...   \n",
       "ROC                                             0.2719  ...   \n",
       "Logistic Regression                             0.3170  ...   \n",
       "\n",
       "                     Num True Pos - Unprivileged  Num True Neg - Unprivileged  \\\n",
       "EOP                                        353.0                        240.0   \n",
       "CEOP                                       289.0                        356.0   \n",
       "ROC                                        322.0                        322.0   \n",
       "Logistic Regression                        289.0                        356.0   \n",
       "\n",
       "                     Num False Pos - Unprivileged  \\\n",
       "EOP                                         261.0   \n",
       "CEOP                                        145.0   \n",
       "ROC                                         179.0   \n",
       "Logistic Regression                         145.0   \n",
       "\n",
       "                     Num False Neg - Unprivileged  F1 Score  \\\n",
       "EOP                                         124.0    0.6738   \n",
       "CEOP                                        188.0    0.6900   \n",
       "ROC                                         155.0    0.6769   \n",
       "Logistic Regression                         188.0    0.6895   \n",
       "\n",
       "                     F1 Score - Privileged  F1 Score - Unprivileged  \\\n",
       "EOP                                 0.7119                   0.6471   \n",
       "CEOP                                0.7488                   0.6345   \n",
       "ROC                                 0.7024                   0.6585   \n",
       "Logistic Regression                 0.7509                   0.6345   \n",
       "\n",
       "                     Privileged base Rate  Unprivileged base Rate  Consistency  \n",
       "EOP                                0.6601                  0.6278       0.8018  \n",
       "CEOP                               0.8135                  0.4438       0.9609  \n",
       "ROC                                0.5644                  0.5123       0.9976  \n",
       "Logistic Regression                0.7393                  0.4438       0.9972  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  bank\n",
      "None None EOP\n",
      "None None CEOP\n",
      "None None ROC\n",
      "None None None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Theil Index</th>\n",
       "      <th>False Positive Rate - Unprivileged</th>\n",
       "      <th>False Positive Rate - Privileged</th>\n",
       "      <th>False Negative Rate - Unprivileged</th>\n",
       "      <th>False Negative Rate - Privileged</th>\n",
       "      <th>Accuracy - Unprivileged</th>\n",
       "      <th>Accuracy - Privileged</th>\n",
       "      <th>False Discovery Rate - Unprivileged</th>\n",
       "      <th>False Discovery Rate - Privileged</th>\n",
       "      <th>...</th>\n",
       "      <th>Num True Pos - Unprivileged</th>\n",
       "      <th>Num True Neg - Unprivileged</th>\n",
       "      <th>Num False Pos - Unprivileged</th>\n",
       "      <th>Num False Neg - Unprivileged</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F1 Score - Privileged</th>\n",
       "      <th>F1 Score - Unprivileged</th>\n",
       "      <th>Privileged base Rate</th>\n",
       "      <th>Unprivileged base Rate</th>\n",
       "      <th>Consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EOP</th>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.9643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEOP</th>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.1838</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.9819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.9015</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.5669</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.3494</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.5201</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.9796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Theil Index  \\\n",
       "EOP                    0.8919       0.0870   \n",
       "CEOP                   0.8835       0.1197   \n",
       "ROC                    0.9002       0.0887   \n",
       "Logistic Regression    0.9015       0.0837   \n",
       "\n",
       "                     False Positive Rate - Unprivileged  \\\n",
       "EOP                                              0.0582   \n",
       "CEOP                                             0.0688   \n",
       "ROC                                              0.0688   \n",
       "Logistic Regression                              0.0688   \n",
       "\n",
       "                     False Positive Rate - Privileged  \\\n",
       "EOP                                            0.0431   \n",
       "CEOP                                           0.0054   \n",
       "ROC                                            0.0258   \n",
       "Logistic Regression                            0.0316   \n",
       "\n",
       "                     False Negative Rate - Unprivileged  \\\n",
       "EOP                                              0.5942   \n",
       "CEOP                                             0.5652   \n",
       "ROC                                              0.6087   \n",
       "Logistic Regression                              0.5652   \n",
       "\n",
       "                     False Negative Rate - Privileged  \\\n",
       "EOP                                            0.5650   \n",
       "CEOP                                           0.9153   \n",
       "ROC                                            0.6177   \n",
       "Logistic Regression                            0.5669   \n",
       "\n",
       "                     Accuracy - Unprivileged  Accuracy - Privileged  \\\n",
       "EOP                                   0.7984                 0.8946   \n",
       "CEOP                                  0.7984                 0.8859   \n",
       "ROC                                   0.7868                 0.9035   \n",
       "Logistic Regression                   0.7984                 0.9045   \n",
       "\n",
       "                     False Discovery Rate - Unprivileged  \\\n",
       "EOP                                               0.2821   \n",
       "CEOP                                              0.3023   \n",
       "ROC                                               0.3250   \n",
       "Logistic Regression                               0.3023   \n",
       "\n",
       "                     False Discovery Rate - Privileged  ...  \\\n",
       "EOP                                             0.4218  ...   \n",
       "CEOP                                            0.3182  ...   \n",
       "ROC                                             0.3322  ...   \n",
       "Logistic Regression                             0.3494  ...   \n",
       "\n",
       "                     Num True Pos - Unprivileged  Num True Neg - Unprivileged  \\\n",
       "EOP                                         28.0                        178.0   \n",
       "CEOP                                        30.0                        176.0   \n",
       "ROC                                         27.0                        176.0   \n",
       "Logistic Regression                         30.0                        176.0   \n",
       "\n",
       "                     Num False Pos - Unprivileged  \\\n",
       "EOP                                          11.0   \n",
       "CEOP                                         13.0   \n",
       "ROC                                          13.0   \n",
       "Logistic Regression                          13.0   \n",
       "\n",
       "                     Num False Neg - Unprivileged  F1 Score  \\\n",
       "EOP                                          41.0    0.4977   \n",
       "CEOP                                         39.0    0.1838   \n",
       "ROC                                          42.0    0.4868   \n",
       "Logistic Regression                          39.0    0.5210   \n",
       "\n",
       "                     F1 Score - Privileged  F1 Score - Unprivileged  \\\n",
       "EOP                                 0.4965                   0.5185   \n",
       "CEOP                                0.1508                   0.5357   \n",
       "ROC                                 0.4862                   0.4954   \n",
       "Logistic Regression                 0.5201                   0.5357   \n",
       "\n",
       "                     Privileged base Rate  Unprivileged base Rate  Consistency  \n",
       "EOP                                0.0899                  0.1512       0.9643  \n",
       "CEOP                               0.0148                  0.1667       0.9758  \n",
       "ROC                                0.0684                  0.1550       0.9819  \n",
       "Logistic Regression                0.0795                  0.1667       0.9796  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#datasets = [\"adult\", \"compas\", \"german\", \"bank\"]\n",
    "datasets = [\"german\", \"adult\", \"compas\", \"bank\"]\n",
    "for dataset_name in datasets:\n",
    "    dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "    \n",
    "    print(\"DATASET NAME: \", dataset_name)\n",
    "    np.random.seed(123)\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "    preprocessing_algos = [#LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0),\n",
    "                           #OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups),\n",
    "                          #preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                          #preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr),\n",
    "                          None]\n",
    "                          \n",
    "    #preprocessing_algos = [None]\n",
    "\n",
    "    #inprocessing_algos = [GerryFairClassifier(),\n",
    "                          #inprocessing.PrejudiceRemover(sensitive_attr=pro_attr),\n",
    "    #                      inprocessing.ExponentiatedGradientReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "    #                      inprocessing.GridSearchReduction(sklearn.linear_model.LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          ##inprocessing.MetaFairClassifier(),\n",
    "    #                      None]\n",
    "    inprocessing_algos = [None]\n",
    "    postprocessing_algos = [postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),  \n",
    "                            None]\n",
    "\n",
    "    #postprocessing_algos = [None]\n",
    "\n",
    "    df = {}\n",
    "\n",
    "    for pre in preprocessing_algos:\n",
    "        for inproc in inprocessing_algos:\n",
    "            for post in postprocessing_algos:\n",
    "                try:\n",
    "                    res = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, \n",
    "                             preprocessing_algo=copy.deepcopy(pre), \n",
    "                             inprocessing_algo=copy.deepcopy(inproc),\n",
    "                             postprocessing_algo=copy.deepcopy(post))\n",
    "                    df[res[\"key\"]] = res[\"val\"]\n",
    "\n",
    "                except KeyboardInterrupt:\n",
    "                    raise KeyboardInterrupt()\n",
    "                except Exception as e:\n",
    "                    print(\"FAILED: \" + get_model_name(pre) + \", \" + get_model_name(inproc) + \", \" + get_model_name(post) + \" on dataset \" + get_dataset_name(dataset), e)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(df)                \n",
    "    df.index = [\"Accuracy\", \"Theil Index\",\n",
    "                    \"False Positive Rate - Unprivileged\", \"False Positive Rate - Privileged\",\n",
    "                    \"False Negative Rate - Unprivileged\", \"False Negative Rate - Privileged\",\n",
    "                    \"Accuracy - Unprivileged\", \"Accuracy - Privileged\",\n",
    "                    \"False Discovery Rate - Unprivileged\", \"False Discovery Rate - Privileged\",\n",
    "                    \"False Omission Rate - Unprivileged\", \"False Omission Rate - Privileged\",\n",
    "                    \"Num True Pos\", \"Num True Neg\", \"Num False Pos\", \"Num False Neg\",\n",
    "                    \"Num True Pos - Privileged\", \"Num True Neg - Privileged\", \"Num False Pos - Privileged\", \"Num False Neg - Privileged\",\n",
    "                    \"Num True Pos - Unprivileged\", \"Num True Neg - Unprivileged\", \"Num False Pos - Unprivileged\", \"Num False Neg - Unprivileged\",\n",
    "                    \"F1 Score\", \"F1 Score - Privileged\", \"F1 Score - Unprivileged\",\n",
    "                    \"Privileged base Rate\", \"Unprivileged base Rate\", \"Consistency\"]\n",
    "\n",
    "    df = df.T\n",
    "    df.to_csv(\"Data -\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    display(df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.038e-01 2.920e-02 9.560e-01 9.141e-01 0.000e+00 2.700e-03 2.984e-01\n",
      " 2.011e-01 7.250e-01 8.636e-01 0.000e+00 4.500e-03 1.188e+03 6.760e+02\n",
      " 7.280e+03 3.000e+00 1.122e+03 6.680e+02 7.106e+03 3.000e+00 6.600e+01\n",
      " 8.000e+00 1.740e+02 0.000e+00 2.460e-01 2.399e-01 4.314e-01]\n",
      "[0.9246 0.9677 array([0.9523341])]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"bank\"\n",
    "dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "\n",
    "np.random.seed(0)\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "#inp = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\n",
    "#dataset_train_pred = inp.fit_transform(dataset_train_pred)\n",
    "\n",
    "    \n",
    "X_train = dataset_train_pred.features\n",
    "y_train = dataset_train_pred.labels #.ravel()\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "dataset_train.scores = model.predict_proba(dataset_train.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_train.labels = model.predict(dataset_train.features).reshape(-1,1)\n",
    "dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)     \n",
    "\n",
    "pp = postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "\n",
    "CM = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "    \n",
    "BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "\n",
    "print(run_classification_metrics(CM))\n",
    "print(run_binary_dataset_metrics(BLDM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(dataset_test.labels, dataset_test_pred.labels).ravel()\n",
    "(tn+tp)/(tn + fp + fn + tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM.num_false_positives()/(CM.num_false_positives() + CM.num_true_negatives())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 23.0, 0.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM.num_false_positives(), CM.num_false_negatives(), CM.num_true_positives(), CM.num_true_negatives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = load_preproc_data_compas(['race'])  \n",
    "#g = load_preproc_data_german(['age'])\n",
    "g = load_preproc_data_adult(['sex'])\n",
    "#g = BankDataset(protected_attribute_names=['age'],\n",
    "#            privileged_classes=[lambda x: x >= 25], \n",
    "#            features_to_drop=['day_of_week'])\n",
    "#g = GermanDataset(protected_attribute_names=['age'], metadata={'label_maps': [{0.0: 'Good Credit', 1.0: 'Bad Credit'}]})\n",
    "#g.labels = g.labels -1\n",
    "np.random.seed(123)\n",
    "dataset_train, dataset_test = g.split([0.7], shuffle = True)\n",
    "\n",
    "X_train = dataset_train.features\n",
    "y_train = dataset_train.labels #.ravel()\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "# scores for train dataset required for post-processing algos\n",
    "dataset_train.scores = model.predict_proba(dataset_train.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_train.labels = model.predict(dataset_train.features) #.reshape(-1,1)\n",
    "#dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "#dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)     \n",
    "#dataset_train.labels = np.array([[l[0].item()] for l in dataset_train.labels])\n",
    "\n",
    "#ip = GerryFairClassifier()\n",
    "#ip = inprocessing.PrejudiceRemover(sensitive_attr='sex')  # ,  class_attr='credit'\n",
    "inp = preprocessing.DisparateImpactRemover(sensitive_attribute='sex')\n",
    "\n",
    "#dataset_train.labels[:] = 0  #np.ones(300)\n",
    "dataset_tranf = inp.fit_transform(dataset_train)\n",
    "#tr = ip.predict(dataset_train)\n",
    "#ip.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dataset_tranf.labels.ravel() != dataset_train.labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = dataset_tranf.features\n",
    "y_tr = dataset_tranf.labels\n",
    "\n",
    "optim_options = {\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0],\n",
    "        \"distortion_fun\": get_distortion_adult\n",
    "}\n",
    "\n",
    "m = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "#m = OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups)\n",
    "m.fit(X_tr, y_tr)\n",
    "    \n",
    "pred = m.predict(dataset_test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
