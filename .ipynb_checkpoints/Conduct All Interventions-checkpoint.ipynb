{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from aif360.algorithms.inprocessing import GerryFairClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "import copy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    def f1_score(priv=None):\n",
    "            numer = CM.num_true_positives(privileged=priv)\n",
    "            denom = CM.num_true_positives(privileged=priv) + 0.5*float(CM.num_false_positives(privileged=priv) + CM.num_false_negatives(privileged=priv))\n",
    "            return float(numer/denom)\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(f1_score(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.false_positive_rate(privileged=False), 4),\n",
    "        round(CM.false_positive_rate(privileged=True), 4),\n",
    "        round(CM.false_negative_rate(privileged=False), 4),\n",
    "        round(CM.false_negative_rate(privileged=True), 4),\n",
    "        round(1-CM.error_rate(privileged=False), 4),\n",
    "        round(1-CM.error_rate(privileged=True), 4),\n",
    "        round(CM.false_discovery_rate(privileged=False), 4),\n",
    "        round(CM.false_discovery_rate(privileged=True), 4),\n",
    "        round(CM.false_omission_rate(privileged=False), 4),\n",
    "        round(CM.false_omission_rate(privileged=True), 4),\n",
    "        \n",
    "        #all results\n",
    "        CM.num_true_positives(),\n",
    "        CM.num_true_negatives(),\n",
    "        CM.num_false_positives(),\n",
    "        CM.num_false_negatives(),\n",
    "        \n",
    "        #privileged\n",
    "        CM.num_true_positives(privileged=True),\n",
    "        CM.num_true_negatives(privileged=True),\n",
    "        CM.num_false_positives(privileged=True),\n",
    "        CM.num_false_negatives(privileged=True),\n",
    "        \n",
    "        #unprivileged\n",
    "        CM.num_true_positives(privileged=False),\n",
    "        CM.num_true_negatives(privileged=False),\n",
    "        CM.num_false_positives(privileged=False),\n",
    "        CM.num_false_negatives(privileged=False),\n",
    "        \n",
    "        round(f1_score(True), 4),\n",
    "        round(f1_score(False), 4),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    #print(\"Consistency: \", BLDM.consistency())\n",
    "    return np.array([\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "        round(BLDM.consistency()[0], 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, preprocessing.DisparateImpactRemover):\n",
    "        return \"DIR\"\n",
    "    if isinstance(model, preprocessing.LFR):\n",
    "        return \"LFR\"\n",
    "    if isinstance(model, preprocessing.OptimPreproc):\n",
    "        return \"OP\"\n",
    "    if isinstance(model, preprocessing.Reweighing):\n",
    "        return \"RW\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"PR\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"AD\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ARTC\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"EGR\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GFC\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GSR\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MFC\"\n",
    "    \n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"EOP\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"CEOP\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"ROC\"\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if isinstance(dataset, aif360.datasets.german_dataset.GermanDataset):\n",
    "        return \"German Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.adult_dataset.AdultDataset):\n",
    "        return \"Adult Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.bank_dataset.BankDataset):\n",
    "        return \"Bank Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.compas_dataset.CompasDataset):\n",
    "        return \"Compas Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specialized dataset for Optimized Preprocessing\n",
    "def get_OP_dataset(dataset_name):\n",
    "    dataset = None\n",
    "    if dataset_name==\"bank\":\n",
    "        return\n",
    "    if dataset_name==\"adult\":\n",
    "        dataset = load_preproc_data_adult(['sex'])\n",
    "    elif dataset_name==\"compas\":\n",
    "        dataset = load_preproc_data_compas(['race'])\n",
    "    elif dataset_name==\"german\":\n",
    "        dataset = load_preproc_data_german(['age'])\n",
    "        dataset.labels = (dataset.labels-1.0).astype('float64')\n",
    "        dataset.favorable_label = 1.0\n",
    "        dataset.unfavorable_label = 0.0\n",
    "        dataset.metadata['label_maps'] = [{1.0: 'Good Credit', 0.0: 'Bad Credit'}]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_options(dataset_name):\n",
    "    optim_options = None\n",
    "    if dataset_name==\"adult\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_adult,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'sex'\n",
    "        return (AdultDataset(), pro_attr, [{'sex': 1}], [{'sex': 0}], optim_options)\n",
    "    elif dataset_name==\"compas\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_compas,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'race'\n",
    "        return (CompasDataset(), pro_attr, [{'race': 1}], [{'race': 0}], optim_options)\n",
    "    elif dataset_name==\"bank\":\n",
    "        pro_attr = 'age'\n",
    "        return (BankDataset(protected_attribute_names=['age'],\n",
    "            privileged_classes=[lambda x: x >= 25], \n",
    "            features_to_drop=['day_of_week']), pro_attr, [{'age': 1}], [{'age': 0}], None)\n",
    "    elif dataset_name==\"german\":\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_german,\n",
    "            \"epsilon\": 0.1,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }   \n",
    "        pro_attr = 'age'\n",
    "        label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "        #g = load_preproc_data_german(['age'])\n",
    "        g = GermanDataset(metadata={'label_maps': [label_map]})\n",
    "        g.labels = (g.labels-1.0).astype('float64')\n",
    "        g.favorable_label = 1.0\n",
    "        g.unfavorable_label = 0.0\n",
    "        #g.metadata['label_maps'] = [label_map]\n",
    "\n",
    "        # load_preproc_data_german(['age'])\n",
    "        return (g, pro_attr, [{'age': 1}], [{'age': 0}], optim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None, seed=123):\n",
    "    print(seed, get_model_name(preprocessing_algo), get_model_name(inprocessing_algo), get_model_name(postprocessing_algo))\n",
    "    scale_orig = StandardScaler()\n",
    "    dataset.features = scale_orig.fit_transform(dataset.features)\n",
    "    \n",
    "    # get specialized dataset for Optimized Preprocessing technique\n",
    "    if get_model_name(preprocessing_algo)==\"OP\" and dataset_name!=\"bank\":\n",
    "        #print(\"Specialized function: \", dataset_name)\n",
    "        dataset = get_OP_dataset(dataset_name) \n",
    "        \n",
    "    #np.random.seed(seed)\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=seed)\n",
    "\n",
    "    model = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "    \n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "            \n",
    "    if preprocessing_algo is not None:\n",
    "        if get_model_name(preprocessing_algo)==\"DIR\":\n",
    "            dataset_train_pred = preprocessing_algo.fit_transform(dataset_train_pred)\n",
    "            dataset_test_pred = preprocessing_algo.fit_transform(dataset_test_pred)\n",
    "        elif get_model_name(preprocessing_algo) in [\"OP\", \"LFR\"]:\n",
    "            preprocessing_algo.fit(dataset_train_pred)\n",
    "            dataset_train_pred = preprocessing_algo.transform(dataset_train_pred)\n",
    "            dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "            dataset_test_pred = preprocessing_algo.transform(dataset_test_pred)\n",
    "            dataset_test_pred = dataset_test.align_datasets(dataset_test_pred)\n",
    "    \n",
    "    if inprocessing_algo is not None:\n",
    "        inp = inprocessing_algo\n",
    "        inp.fit(dataset_train_pred)\n",
    "        dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "        dataset_test_pred = inp.predict(dataset_test_pred) \n",
    "        \n",
    "        # exception for GFC \n",
    "        if get_model_name(inprocessing_algo)==\"GFC\":\n",
    "            dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "            dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "            dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "            dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "    else:\n",
    "        model.fit(dataset_train_pred.features, dataset_train_pred.labels)   # .ravel()\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1) \n",
    "        dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)  \n",
    "            \n",
    "    if postprocessing_algo is not None:\n",
    "        dataset_train.features = dataset_train_pred.features\n",
    "        pp = postprocessing_algo\n",
    "        pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "        dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    \n",
    "    dataset_test_pred.features = dataset_test.features \n",
    "    \n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "     \n",
    "    name = \"\"\n",
    "    if preprocessing_algo is not None:\n",
    "        name += get_model_name(preprocessing_algo) + \" + \"\n",
    "    if inprocessing_algo is not None:\n",
    "        name += get_model_name(inprocessing_algo) + \" + \"\n",
    "    if postprocessing_algo is not None:\n",
    "        name += get_model_name(postprocessing_algo)\n",
    "    if name == \"\":\n",
    "        name = get_model_name(model)\n",
    "        \n",
    "    if name.endswith(\" + \"):\n",
    "        lastIndex = name.rindex(\" + \")\n",
    "        name = name[:lastIndex]\n",
    "    \n",
    "    #print(run_classification_metrics(CM))\n",
    "    #print(run_binary_dataset_metrics(BLDM))\n",
    "    metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "       \n",
    "    return {\"key\":name, \"val\":metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  bank\n",
      "3 OP None None\n",
      "FAILED: OP, None, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP None None\n",
      "FAILED: OP, None, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP None None\n",
      "FAILED: OP, None, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP None EOP\n",
      "FAILED: OP, None, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP None EOP\n",
      "FAILED: OP, None, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP None EOP\n",
      "FAILED: OP, None, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP None ROC\n",
      "FAILED: OP, None, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP None ROC\n",
      "FAILED: OP, None, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP None ROC\n",
      "FAILED: OP, None, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP GFC None\n",
      "FAILED: OP, GFC, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP GFC None\n",
      "FAILED: OP, GFC, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP GFC None\n",
      "FAILED: OP, GFC, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP GFC EOP\n",
      "FAILED: OP, GFC, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP GFC EOP\n",
      "FAILED: OP, GFC, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP GFC EOP\n",
      "FAILED: OP, GFC, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP GFC ROC\n",
      "FAILED: OP, GFC, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP GFC ROC\n",
      "FAILED: OP, GFC, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP GFC ROC\n",
      "FAILED: OP, GFC, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP PR None\n",
      "FAILED: OP, PR, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP PR None\n",
      "FAILED: OP, PR, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP PR None\n",
      "FAILED: OP, PR, None on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP PR EOP\n",
      "FAILED: OP, PR, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP PR EOP\n",
      "FAILED: OP, PR, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP PR EOP\n",
      "FAILED: OP, PR, EOP on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 OP PR ROC\n",
      "FAILED: OP, PR, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "11 OP PR ROC\n",
      "FAILED: OP, PR, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "17 OP PR ROC\n",
      "FAILED: OP, PR, ROC on dataset Bank Dataset 'NoneType' object is not subscriptable\n",
      "3 None None None\n",
      "11 None None None\n",
      "17 None None None\n",
      "3 None None EOP\n",
      "11 None None EOP\n",
      "17 None None EOP\n",
      "3 None None ROC\n",
      "11 None None ROC\n",
      "17 None None ROC\n",
      "3 None GFC None\n",
      "11 None GFC None\n",
      "17 None GFC None\n",
      "3 None GFC EOP\n",
      "11 None GFC EOP\n",
      "17 None GFC EOP\n",
      "3 None GFC ROC\n",
      "11 None GFC ROC\n",
      "17 None GFC ROC\n",
      "3 None PR None\n",
      "11 None PR None\n",
      "17 None PR None\n",
      "3 None PR EOP\n",
      "11 None PR EOP\n",
      "17 None PR EOP\n",
      "3 None PR ROC\n",
      "11 None PR ROC\n",
      "17 None PR ROC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Theil Index</th>\n",
       "      <th>False Positive Rate - Unprivileged</th>\n",
       "      <th>False Positive Rate - Privileged</th>\n",
       "      <th>False Negative Rate - Unprivileged</th>\n",
       "      <th>False Negative Rate - Privileged</th>\n",
       "      <th>Accuracy - Unprivileged</th>\n",
       "      <th>Accuracy - Privileged</th>\n",
       "      <th>False Discovery Rate - Unprivileged</th>\n",
       "      <th>...</th>\n",
       "      <th>Num False Neg - Privileged</th>\n",
       "      <th>Num True Pos - Unprivileged</th>\n",
       "      <th>Num True Neg - Unprivileged</th>\n",
       "      <th>Num False Pos - Unprivileged</th>\n",
       "      <th>Num False Neg - Unprivileged</th>\n",
       "      <th>F1 Score - Privileged</th>\n",
       "      <th>F1 Score - Unprivileged</th>\n",
       "      <th>Privileged base Rate</th>\n",
       "      <th>Unprivileged base Rate</th>\n",
       "      <th>Consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.900467</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.523533</td>\n",
       "      <td>0.577533</td>\n",
       "      <td>0.824067</td>\n",
       "      <td>0.902733</td>\n",
       "      <td>0.334767</td>\n",
       "      <td>...</td>\n",
       "      <td>632.666667</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.516933</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.951133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOP</th>\n",
       "      <td>0.881033</td>\n",
       "      <td>0.478233</td>\n",
       "      <td>0.091867</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.053833</td>\n",
       "      <td>0.620733</td>\n",
       "      <td>0.564767</td>\n",
       "      <td>0.807367</td>\n",
       "      <td>0.883167</td>\n",
       "      <td>0.366933</td>\n",
       "      <td>...</td>\n",
       "      <td>618.666667</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>187.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>0.478567</td>\n",
       "      <td>0.471633</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.919267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.889467</td>\n",
       "      <td>0.332833</td>\n",
       "      <td>0.108733</td>\n",
       "      <td>0.021567</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>0.720700</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.818700</td>\n",
       "      <td>0.891533</td>\n",
       "      <td>0.191967</td>\n",
       "      <td>...</td>\n",
       "      <td>859.333333</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>196.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>0.328667</td>\n",
       "      <td>0.407633</td>\n",
       "      <td>0.038367</td>\n",
       "      <td>0.079633</td>\n",
       "      <td>0.968667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFC</th>\n",
       "      <td>0.895367</td>\n",
       "      <td>0.446033</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.612767</td>\n",
       "      <td>0.668967</td>\n",
       "      <td>0.823900</td>\n",
       "      <td>0.897467</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>...</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>191.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>0.443133</td>\n",
       "      <td>0.497533</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.123067</td>\n",
       "      <td>0.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFC + EOP</th>\n",
       "      <td>0.886600</td>\n",
       "      <td>0.431267</td>\n",
       "      <td>0.098667</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>0.664967</td>\n",
       "      <td>0.658900</td>\n",
       "      <td>0.816267</td>\n",
       "      <td>0.888667</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>...</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>0.450733</td>\n",
       "      <td>0.072167</td>\n",
       "      <td>0.107833</td>\n",
       "      <td>0.955400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFC + ROC</th>\n",
       "      <td>0.895333</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>0.669267</td>\n",
       "      <td>0.825167</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>0.279533</td>\n",
       "      <td>...</td>\n",
       "      <td>733.333333</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>191.333333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.442767</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.124333</td>\n",
       "      <td>0.972067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR</th>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.517733</td>\n",
       "      <td>0.086033</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.575833</td>\n",
       "      <td>0.577433</td>\n",
       "      <td>0.827567</td>\n",
       "      <td>0.902800</td>\n",
       "      <td>0.276633</td>\n",
       "      <td>...</td>\n",
       "      <td>632.666667</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>190.333333</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>0.517233</td>\n",
       "      <td>0.522433</td>\n",
       "      <td>0.078133</td>\n",
       "      <td>0.134467</td>\n",
       "      <td>0.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR + EOP</th>\n",
       "      <td>0.893300</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.088467</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.039033</td>\n",
       "      <td>0.609900</td>\n",
       "      <td>0.573467</td>\n",
       "      <td>0.830133</td>\n",
       "      <td>0.895100</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>...</td>\n",
       "      <td>628.333333</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.504767</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.116467</td>\n",
       "      <td>0.938733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR + ROC</th>\n",
       "      <td>0.891533</td>\n",
       "      <td>0.370433</td>\n",
       "      <td>0.104733</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.016033</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.748267</td>\n",
       "      <td>0.816033</td>\n",
       "      <td>0.893733</td>\n",
       "      <td>0.225867</td>\n",
       "      <td>...</td>\n",
       "      <td>819.333333</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>194.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.367667</td>\n",
       "      <td>0.417833</td>\n",
       "      <td>0.045167</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.965167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  F1 Score  Theil Index  \\\n",
       "Logistic Regression  0.900467  0.518767     0.085833   \n",
       "EOP                  0.881033  0.478233     0.091867   \n",
       "ROC                  0.889467  0.332833     0.108733   \n",
       "GFC                  0.895367  0.446033     0.096067   \n",
       "GFC + EOP            0.886600  0.431267     0.098667   \n",
       "GFC + ROC            0.895333  0.446000     0.096100   \n",
       "PR                   0.900667  0.517733     0.086033   \n",
       "PR + EOP             0.893300  0.501000     0.088467   \n",
       "PR + ROC             0.891533  0.370433     0.104733   \n",
       "\n",
       "                     False Positive Rate - Unprivileged  \\\n",
       "Logistic Regression                            0.072500   \n",
       "EOP                                            0.065900   \n",
       "ROC                                            0.021567   \n",
       "GFC                                            0.046100   \n",
       "GFC + EOP                                      0.041200   \n",
       "GFC + ROC                                      0.046100   \n",
       "PR                                             0.051000   \n",
       "PR + EOP                                       0.037800   \n",
       "PR + ROC                                       0.029833   \n",
       "\n",
       "                     False Positive Rate - Privileged  \\\n",
       "Logistic Regression                          0.029800   \n",
       "EOP                                          0.053833   \n",
       "ROC                                          0.013433   \n",
       "GFC                                          0.022900   \n",
       "GFC + EOP                                    0.034333   \n",
       "GFC + ROC                                    0.022933   \n",
       "PR                                           0.029700   \n",
       "PR + EOP                                     0.039033   \n",
       "PR + ROC                                     0.016033   \n",
       "\n",
       "                     False Negative Rate - Unprivileged  \\\n",
       "Logistic Regression                            0.523533   \n",
       "EOP                                            0.620733   \n",
       "ROC                                            0.720700   \n",
       "GFC                                            0.612767   \n",
       "GFC + EOP                                      0.664967   \n",
       "GFC + ROC                                      0.606700   \n",
       "PR                                             0.575833   \n",
       "PR + EOP                                       0.609900   \n",
       "PR + ROC                                       0.701967   \n",
       "\n",
       "                     False Negative Rate - Privileged  \\\n",
       "Logistic Regression                          0.577533   \n",
       "EOP                                          0.564767   \n",
       "ROC                                          0.784500   \n",
       "GFC                                          0.668967   \n",
       "GFC + EOP                                    0.658900   \n",
       "GFC + ROC                                    0.669267   \n",
       "PR                                           0.577433   \n",
       "PR + EOP                                     0.573467   \n",
       "PR + ROC                                     0.748267   \n",
       "\n",
       "                     Accuracy - Unprivileged  Accuracy - Privileged  \\\n",
       "Logistic Regression                 0.824067               0.902733   \n",
       "EOP                                 0.807367               0.883167   \n",
       "ROC                                 0.818700               0.891533   \n",
       "GFC                                 0.823900               0.897467   \n",
       "GFC + EOP                           0.816267               0.888667   \n",
       "GFC + ROC                           0.825167               0.897400   \n",
       "PR                                  0.827567               0.902800   \n",
       "PR + EOP                            0.830133               0.895100   \n",
       "PR + ROC                            0.816033               0.893733   \n",
       "\n",
       "                     False Discovery Rate - Unprivileged  ...  \\\n",
       "Logistic Regression                             0.334767  ...   \n",
       "EOP                                             0.366933  ...   \n",
       "ROC                                             0.191967  ...   \n",
       "GFC                                             0.282600  ...   \n",
       "GFC + EOP                                       0.286000  ...   \n",
       "GFC + ROC                                       0.279533  ...   \n",
       "PR                                              0.276633  ...   \n",
       "PR + EOP                                        0.238100  ...   \n",
       "PR + ROC                                        0.225867  ...   \n",
       "\n",
       "                     Num False Neg - Privileged  Num True Pos - Unprivileged  \\\n",
       "Logistic Regression                  632.666667                    28.000000   \n",
       "EOP                                  618.666667                    22.333333   \n",
       "ROC                                  859.333333                    16.333333   \n",
       "GFC                                  733.000000                    22.666667   \n",
       "GFC + EOP                            722.000000                    19.666667   \n",
       "GFC + ROC                            733.333333                    23.000000   \n",
       "PR                                   632.666667                    24.666667   \n",
       "PR + EOP                             628.333333                    22.666667   \n",
       "PR + ROC                             819.333333                    17.333333   \n",
       "\n",
       "                     Num True Neg - Unprivileged  \\\n",
       "Logistic Regression                   186.000000   \n",
       "EOP                                   187.333333   \n",
       "ROC                                   196.333333   \n",
       "GFC                                   191.333333   \n",
       "GFC + EOP                             192.333333   \n",
       "GFC + ROC                             191.333333   \n",
       "PR                                    190.333333   \n",
       "PR + EOP                              193.000000   \n",
       "PR + ROC                              194.666667   \n",
       "\n",
       "                     Num False Pos - Unprivileged  \\\n",
       "Logistic Regression                     14.666667   \n",
       "EOP                                     13.333333   \n",
       "ROC                                      4.333333   \n",
       "GFC                                      9.333333   \n",
       "GFC + EOP                                8.333333   \n",
       "GFC + ROC                                9.333333   \n",
       "PR                                      10.333333   \n",
       "PR + EOP                                 7.666667   \n",
       "PR + ROC                                 6.000000   \n",
       "\n",
       "                     Num False Neg - Unprivileged  F1 Score - Privileged  \\\n",
       "Logistic Regression                     31.000000               0.516933   \n",
       "EOP                                     36.666667               0.478567   \n",
       "ROC                                     42.666667               0.328667   \n",
       "GFC                                     36.333333               0.443133   \n",
       "GFC + EOP                               39.333333               0.430200   \n",
       "GFC + ROC                               36.000000               0.442767   \n",
       "PR                                      34.333333               0.517233   \n",
       "PR + EOP                                36.333333               0.500600   \n",
       "PR + ROC                                41.666667               0.367667   \n",
       "\n",
       "                     F1 Score - Unprivileged  Privileged base Rate  \\\n",
       "Logistic Regression                 0.551100              0.078200   \n",
       "EOP                                 0.471633              0.100900   \n",
       "ROC                                 0.407633              0.038367   \n",
       "GFC                                 0.497533              0.060900   \n",
       "GFC + EOP                           0.450733              0.072167   \n",
       "GFC + ROC                           0.503000              0.060833   \n",
       "PR                                  0.522433              0.078133   \n",
       "PR + EOP                            0.504767              0.086800   \n",
       "PR + ROC                            0.417833              0.045167   \n",
       "\n",
       "                     Unprivileged base Rate  Consistency  \n",
       "Logistic Regression                0.164200     0.951133  \n",
       "EOP                                0.137300     0.919267  \n",
       "ROC                                0.079633     0.968667  \n",
       "GFC                                0.123067     0.972000  \n",
       "GFC + EOP                          0.107833     0.955400  \n",
       "GFC + ROC                          0.124333     0.972067  \n",
       "PR                                 0.134467     0.951600  \n",
       "PR + EOP                           0.116467     0.938733  \n",
       "PR + ROC                           0.089800     0.965167  \n",
       "\n",
       "[9 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#datasets = [\"compas\", \"german\", \"adult\", \"bank\"]\n",
    "datasets = [\"bank\"]\n",
    "for dataset_name in datasets:\n",
    "    print(\"DATASET NAME: \", dataset_name)\n",
    "    dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "    \n",
    "    preprocessing_algos = [OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups),\n",
    "                           #preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr),\n",
    "                           None,\n",
    "                           #LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0),\n",
    "                          #preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                           ]\n",
    "                          \n",
    "    inprocessing_algos = [None,\n",
    "                           #inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=seed),\n",
    "                          GerryFairClassifier(),\n",
    "                          inprocessing.PrejudiceRemover(sensitive_attr=pro_attr),\n",
    "                          #inprocessing.ExponentiatedGradientReduction(LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          #inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          ]\n",
    "\n",
    "    postprocessing_algos = [None,\n",
    "                            postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            #postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),  \n",
    "                            ]\n",
    "\n",
    "    df = {}\n",
    "    all_data = {}\n",
    "\n",
    "    for pre in preprocessing_algos:\n",
    "        for inproc in inprocessing_algos:\n",
    "            for post in postprocessing_algos:    \n",
    "                kfold_data = []   # store data for each fold\n",
    "                col_name = None\n",
    "                # k-fold cross vaidation - Repeat the process 3 times\n",
    "                for seed in [3, 11, 17]:  #[3, 5, 11, 17, 29]:\n",
    "                    try:\n",
    "                        res = execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                                 preprocessing_algo=copy.deepcopy(pre), \n",
    "                                 inprocessing_algo=copy.deepcopy(inproc),\n",
    "                                 postprocessing_algo=copy.deepcopy(post), seed=seed)\n",
    "                        \n",
    "                        col_name = res[\"key\"]\n",
    "                        if col_name:\n",
    "                            kfold_data.append(res[\"val\"])\n",
    "                            all_data[col_name+\" - \"+str(seed)] = res[\"val\"]\n",
    "                        \n",
    "                    except KeyboardInterrupt:\n",
    "                        raise KeyboardInterrupt()\n",
    "                    except Exception as e:\n",
    "                        print(\"FAILED: \" + get_model_name(pre) + \", \" + get_model_name(inproc) + \", \" + get_model_name(post) + \" on dataset \" + get_dataset_name(dataset), e)\n",
    "                \n",
    "                if col_name:\n",
    "                    df[col_name] = np.array(kfold_data).mean(axis=0).tolist()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    all_data = pd.DataFrame.from_dict(all_data)\n",
    "    df.index = all_data.index = [\"Accuracy\", \"F1 Score\", \"Theil Index\",\n",
    "                    \"False Positive Rate - Unprivileged\", \"False Positive Rate - Privileged\",\n",
    "                    \"False Negative Rate - Unprivileged\", \"False Negative Rate - Privileged\",\n",
    "                    \"Accuracy - Unprivileged\", \"Accuracy - Privileged\",\n",
    "                    \"False Discovery Rate - Unprivileged\", \"False Discovery Rate - Privileged\",\n",
    "                    \"False Omission Rate - Unprivileged\", \"False Omission Rate - Privileged\",\n",
    "                    \"Num True Pos\", \"Num True Neg\", \"Num False Pos\", \"Num False Neg\",\n",
    "                    \"Num True Pos - Privileged\", \"Num True Neg - Privileged\", \"Num False Pos - Privileged\", \"Num False Neg - Privileged\",\n",
    "                    \"Num True Pos - Unprivileged\", \"Num True Neg - Unprivileged\", \"Num False Pos - Unprivileged\", \"Num False Neg - Unprivileged\",\n",
    "                    \"F1 Score - Privileged\", \"F1 Score - Unprivileged\",\n",
    "                    \"Privileged base Rate\", \"Unprivileged base Rate\", \"Consistency\"]\n",
    "\n",
    "    df = df.T\n",
    "    all_data = all_data.T\n",
    "    df.to_csv(\"./data/\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    all_data.to_csv(\"./data/All_Data -\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    display(df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EXTRA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>age_cat=25 - 45</th>\n",
       "      <th>age_cat=Greater than 45</th>\n",
       "      <th>age_cat=Less than 25</th>\n",
       "      <th>...</th>\n",
       "      <th>c_charge_desc=Viol Injunct Domestic Violence</th>\n",
       "      <th>c_charge_desc=Viol Injunction Protect Dom Vi</th>\n",
       "      <th>c_charge_desc=Viol Pretrial Release Dom Viol</th>\n",
       "      <th>c_charge_desc=Viol Prot Injunc Repeat Viol</th>\n",
       "      <th>c_charge_desc=Violation License Restrictions</th>\n",
       "      <th>c_charge_desc=Violation Of Boater Safety Id</th>\n",
       "      <th>c_charge_desc=Violation of Injunction Order/Stalking/Cyberstalking</th>\n",
       "      <th>c_charge_desc=Voyeurism</th>\n",
       "      <th>c_charge_desc=arrest case no charge</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.939659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>1.942478</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.898223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>1.888511</td>\n",
       "      <td>0.158601</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>2.266112</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.916224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>1.942478</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.130647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.052150</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.983510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.262901</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6167 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex       age  race  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
       "1      0.0  2.939659   0.0      -0.127668       -0.183308        -0.235203   \n",
       "3      0.0 -0.045361   0.0      -0.127668       -0.183308        -0.235203   \n",
       "4      0.0 -0.898223   0.0      -0.127668       -0.183308         1.888511   \n",
       "7      0.0  0.807502   0.0      -0.127668       -0.183308        -0.235203   \n",
       "8      0.0  0.551643   1.0      -0.127668       -0.183308        -0.235203   \n",
       "...    ...       ...   ...            ...             ...              ...   \n",
       "10996  0.0 -0.983510   0.0      -0.127668       -0.183308        -0.235203   \n",
       "10997  0.0 -0.983510   0.0      -0.127668       -0.183308        -0.235203   \n",
       "10999  0.0  1.916224   0.0      -0.127668       -0.183308        -0.235203   \n",
       "11000  1.0 -0.130647   0.0      -0.127668       -0.183308        -0.235203   \n",
       "11001  1.0 -0.983510   0.0      -0.127668       -0.183308        -0.235203   \n",
       "\n",
       "       priors_count  age_cat=25 - 45  age_cat=Greater than 45  \\\n",
       "1         -0.684403        -1.156231                 1.942478   \n",
       "3         -0.684403         0.864879                -0.514806   \n",
       "4          0.158601        -1.156231                -0.514806   \n",
       "7         -0.684403         0.864879                -0.514806   \n",
       "8          2.266112         0.864879                -0.514806   \n",
       "...             ...              ...                      ...   \n",
       "10996     -0.684403        -1.156231                -0.514806   \n",
       "10997     -0.684403        -1.156231                -0.514806   \n",
       "10999     -0.684403        -1.156231                 1.942478   \n",
       "11000     -0.052150         0.864879                -0.514806   \n",
       "11001     -0.262901        -1.156231                -0.514806   \n",
       "\n",
       "       age_cat=Less than 25  ...  \\\n",
       "1                 -0.528640  ...   \n",
       "3                 -0.528640  ...   \n",
       "4                  1.891645  ...   \n",
       "7                 -0.528640  ...   \n",
       "8                 -0.528640  ...   \n",
       "...                     ...  ...   \n",
       "10996              1.891645  ...   \n",
       "10997              1.891645  ...   \n",
       "10999             -0.528640  ...   \n",
       "11000             -0.528640  ...   \n",
       "11001              1.891645  ...   \n",
       "\n",
       "       c_charge_desc=Viol Injunct Domestic Violence  \\\n",
       "1                                         -0.087634   \n",
       "3                                         -0.087634   \n",
       "4                                         -0.087634   \n",
       "7                                         -0.087634   \n",
       "8                                         -0.087634   \n",
       "...                                             ...   \n",
       "10996                                     -0.087634   \n",
       "10997                                     -0.087634   \n",
       "10999                                     -0.087634   \n",
       "11000                                     -0.087634   \n",
       "11001                                     -0.087634   \n",
       "\n",
       "       c_charge_desc=Viol Injunction Protect Dom Vi  \\\n",
       "1                                         -0.031207   \n",
       "3                                         -0.031207   \n",
       "4                                         -0.031207   \n",
       "7                                         -0.031207   \n",
       "8                                         -0.031207   \n",
       "...                                             ...   \n",
       "10996                                     -0.031207   \n",
       "10997                                     -0.031207   \n",
       "10999                                     -0.031207   \n",
       "11000                                     -0.031207   \n",
       "11001                                     -0.031207   \n",
       "\n",
       "       c_charge_desc=Viol Pretrial Release Dom Viol  \\\n",
       "1                                         -0.044155   \n",
       "3                                         -0.044155   \n",
       "4                                         -0.044155   \n",
       "7                                         -0.044155   \n",
       "8                                         -0.044155   \n",
       "...                                             ...   \n",
       "10996                                     -0.044155   \n",
       "10997                                     -0.044155   \n",
       "10999                                     -0.044155   \n",
       "11000                                     -0.044155   \n",
       "11001                                     -0.044155   \n",
       "\n",
       "       c_charge_desc=Viol Prot Injunc Repeat Viol  \\\n",
       "1                                       -0.054105   \n",
       "3                                       -0.054105   \n",
       "4                                       -0.054105   \n",
       "7                                       -0.054105   \n",
       "8                                       -0.054105   \n",
       "...                                           ...   \n",
       "10996                                   -0.054105   \n",
       "10997                                   -0.054105   \n",
       "10999                                   -0.054105   \n",
       "11000                                   -0.054105   \n",
       "11001                                   -0.054105   \n",
       "\n",
       "       c_charge_desc=Violation License Restrictions  \\\n",
       "1                                         -0.012735   \n",
       "3                                         -0.012735   \n",
       "4                                         -0.012735   \n",
       "7                                         -0.012735   \n",
       "8                                         -0.012735   \n",
       "...                                             ...   \n",
       "10996                                     -0.012735   \n",
       "10997                                     -0.012735   \n",
       "10999                                     -0.012735   \n",
       "11000                                     -0.012735   \n",
       "11001                                     -0.012735   \n",
       "\n",
       "       c_charge_desc=Violation Of Boater Safety Id  \\\n",
       "1                                        -0.012735   \n",
       "3                                        -0.012735   \n",
       "4                                        -0.012735   \n",
       "7                                        -0.012735   \n",
       "8                                        -0.012735   \n",
       "...                                            ...   \n",
       "10996                                    -0.012735   \n",
       "10997                                    -0.012735   \n",
       "10999                                    -0.012735   \n",
       "11000                                    -0.012735   \n",
       "11001                                    -0.012735   \n",
       "\n",
       "       c_charge_desc=Violation of Injunction Order/Stalking/Cyberstalking  \\\n",
       "1                                              -0.012735                    \n",
       "3                                              -0.012735                    \n",
       "4                                              -0.012735                    \n",
       "7                                              -0.012735                    \n",
       "8                                              -0.012735                    \n",
       "...                                                  ...                    \n",
       "10996                                          -0.012735                    \n",
       "10997                                          -0.012735                    \n",
       "10999                                          -0.012735                    \n",
       "11000                                          -0.012735                    \n",
       "11001                                          -0.012735                    \n",
       "\n",
       "       c_charge_desc=Voyeurism  c_charge_desc=arrest case no charge  \\\n",
       "1                    -0.012735                            -0.381633   \n",
       "3                    -0.012735                            -0.381633   \n",
       "4                    -0.012735                            -0.381633   \n",
       "7                    -0.012735                            -0.381633   \n",
       "8                    -0.012735                            -0.381633   \n",
       "...                        ...                                  ...   \n",
       "10996                -0.012735                            -0.381633   \n",
       "10997                -0.012735                            -0.381633   \n",
       "10999                -0.012735                            -0.381633   \n",
       "11000                -0.012735                            -0.381633   \n",
       "11001                -0.012735                            -0.381633   \n",
       "\n",
       "       two_year_recid  \n",
       "1                 0.0  \n",
       "3                 1.0  \n",
       "4                 1.0  \n",
       "7                 0.0  \n",
       "8                 1.0  \n",
       "...               ...  \n",
       "10996             0.0  \n",
       "10997             0.0  \n",
       "10999             0.0  \n",
       "11000             0.0  \n",
       "11001             1.0  \n",
       "\n",
       "[6167 rows x 402 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_orig = StandardScaler()\n",
    "g.features = scale_orig.fit_transform(g.features)\n",
    "g.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>Age (decade)=10</th>\n",
       "      <th>Age (decade)=20</th>\n",
       "      <th>Age (decade)=30</th>\n",
       "      <th>Age (decade)=40</th>\n",
       "      <th>Age (decade)=50</th>\n",
       "      <th>Age (decade)=60</th>\n",
       "      <th>Age (decade)=&gt;=70</th>\n",
       "      <th>Education Years=6</th>\n",
       "      <th>Education Years=7</th>\n",
       "      <th>Education Years=8</th>\n",
       "      <th>Education Years=9</th>\n",
       "      <th>Education Years=10</th>\n",
       "      <th>Education Years=11</th>\n",
       "      <th>Education Years=12</th>\n",
       "      <th>Education Years=&lt;6</th>\n",
       "      <th>Education Years=&gt;12</th>\n",
       "      <th>Income Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  sex  Age (decade)=10  Age (decade)=20  Age (decade)=30  \\\n",
       "0       0.0  1.0              0.0              1.0              0.0   \n",
       "1       1.0  1.0              0.0              0.0              1.0   \n",
       "2       1.0  1.0              0.0              1.0              0.0   \n",
       "3       0.0  1.0              0.0              0.0              0.0   \n",
       "4       1.0  0.0              1.0              0.0              0.0   \n",
       "...     ...  ...              ...              ...              ...   \n",
       "48837   1.0  0.0              0.0              1.0              0.0   \n",
       "48838   1.0  1.0              0.0              0.0              0.0   \n",
       "48839   1.0  0.0              0.0              0.0              0.0   \n",
       "48840   1.0  1.0              0.0              1.0              0.0   \n",
       "48841   1.0  0.0              0.0              0.0              0.0   \n",
       "\n",
       "       Age (decade)=40  Age (decade)=50  Age (decade)=60  Age (decade)=>=70  \\\n",
       "0                  0.0              0.0              0.0                0.0   \n",
       "1                  0.0              0.0              0.0                0.0   \n",
       "2                  0.0              0.0              0.0                0.0   \n",
       "3                  1.0              0.0              0.0                0.0   \n",
       "4                  0.0              0.0              0.0                0.0   \n",
       "...                ...              ...              ...                ...   \n",
       "48837              0.0              0.0              0.0                0.0   \n",
       "48838              1.0              0.0              0.0                0.0   \n",
       "48839              0.0              1.0              0.0                0.0   \n",
       "48840              0.0              0.0              0.0                0.0   \n",
       "48841              0.0              1.0              0.0                0.0   \n",
       "\n",
       "       Education Years=6  Education Years=7  Education Years=8  \\\n",
       "0                    0.0                1.0                0.0   \n",
       "1                    0.0                0.0                0.0   \n",
       "2                    0.0                0.0                0.0   \n",
       "3                    0.0                0.0                0.0   \n",
       "4                    0.0                0.0                0.0   \n",
       "...                  ...                ...                ...   \n",
       "48837                0.0                0.0                0.0   \n",
       "48838                0.0                0.0                0.0   \n",
       "48839                0.0                0.0                0.0   \n",
       "48840                0.0                0.0                0.0   \n",
       "48841                0.0                0.0                0.0   \n",
       "\n",
       "       Education Years=9  Education Years=10  Education Years=11  \\\n",
       "0                    0.0                 0.0                 0.0   \n",
       "1                    1.0                 0.0                 0.0   \n",
       "2                    0.0                 0.0                 0.0   \n",
       "3                    0.0                 1.0                 0.0   \n",
       "4                    0.0                 1.0                 0.0   \n",
       "...                  ...                 ...                 ...   \n",
       "48837                0.0                 0.0                 0.0   \n",
       "48838                1.0                 0.0                 0.0   \n",
       "48839                1.0                 0.0                 0.0   \n",
       "48840                1.0                 0.0                 0.0   \n",
       "48841                1.0                 0.0                 0.0   \n",
       "\n",
       "       Education Years=12  Education Years=<6  Education Years=>12  \\\n",
       "0                     0.0                 0.0                  0.0   \n",
       "1                     0.0                 0.0                  0.0   \n",
       "2                     1.0                 0.0                  0.0   \n",
       "3                     0.0                 0.0                  0.0   \n",
       "4                     0.0                 0.0                  0.0   \n",
       "...                   ...                 ...                  ...   \n",
       "48837                 1.0                 0.0                  0.0   \n",
       "48838                 0.0                 0.0                  0.0   \n",
       "48839                 0.0                 0.0                  0.0   \n",
       "48840                 0.0                 0.0                  0.0   \n",
       "48841                 0.0                 0.0                  0.0   \n",
       "\n",
       "       Income Binary  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                1.0  \n",
       "3                1.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "48837            0.0  \n",
       "48838            1.0  \n",
       "48839            0.0  \n",
       "48840            0.0  \n",
       "48841            1.0  \n",
       "\n",
       "[48842 rows x 19 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = load_preproc_data_adult(['sex'])\n",
    "d.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>Age (decade)=10</th>\n",
       "      <th>Age (decade)=20</th>\n",
       "      <th>Age (decade)=30</th>\n",
       "      <th>Age (decade)=40</th>\n",
       "      <th>Age (decade)=50</th>\n",
       "      <th>Age (decade)=60</th>\n",
       "      <th>Age (decade)=&gt;=70</th>\n",
       "      <th>Education Years=6</th>\n",
       "      <th>Education Years=7</th>\n",
       "      <th>Education Years=8</th>\n",
       "      <th>Education Years=9</th>\n",
       "      <th>Education Years=10</th>\n",
       "      <th>Education Years=11</th>\n",
       "      <th>Education Years=12</th>\n",
       "      <th>Education Years=&lt;6</th>\n",
       "      <th>Education Years=&gt;12</th>\n",
       "      <th>Income Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.428701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>5.094580</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>1.666646</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>5.432051</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.428701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>1.885327</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>1.868149</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.296390</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>1.868149</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>5.432051</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>1.885327</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>2.525680</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>2.525680</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           race  sex  Age (decade)=10  Age (decade)=20  Age (decade)=30  \\\n",
       "0     -2.428701  1.0        -0.232754         1.751705        -0.600007   \n",
       "1      0.411743  1.0        -0.232754        -0.570872         1.666646   \n",
       "2      0.411743  1.0        -0.232754         1.751705        -0.600007   \n",
       "3     -2.428701  1.0        -0.232754        -0.570872        -0.600007   \n",
       "4      0.411743  0.0         4.296390        -0.570872        -0.600007   \n",
       "...         ...  ...              ...              ...              ...   \n",
       "48837  0.411743  0.0        -0.232754         1.751705        -0.600007   \n",
       "48838  0.411743  1.0        -0.232754        -0.570872        -0.600007   \n",
       "48839  0.411743  0.0        -0.232754        -0.570872        -0.600007   \n",
       "48840  0.411743  1.0        -0.232754         1.751705        -0.600007   \n",
       "48841  0.411743  0.0        -0.232754        -0.570872        -0.600007   \n",
       "\n",
       "       Age (decade)=40  Age (decade)=50  Age (decade)=60  Age (decade)=>=70  \\\n",
       "0            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "1            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "2            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "3             1.885327        -0.395933        -0.258261          -0.144649   \n",
       "4            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "...                ...              ...              ...                ...   \n",
       "48837        -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "48838         1.885327        -0.395933        -0.258261          -0.144649   \n",
       "48839        -0.530412         2.525680        -0.258261          -0.144649   \n",
       "48840        -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "48841        -0.530412         2.525680        -0.258261          -0.144649   \n",
       "\n",
       "       Education Years=6  Education Years=7  Education Years=8  \\\n",
       "0              -0.171088           5.094580          -0.116769   \n",
       "1              -0.171088          -0.196287          -0.116769   \n",
       "2              -0.171088          -0.196287          -0.116769   \n",
       "3              -0.171088          -0.196287          -0.116769   \n",
       "4              -0.171088          -0.196287          -0.116769   \n",
       "...                  ...                ...                ...   \n",
       "48837          -0.171088          -0.196287          -0.116769   \n",
       "48838          -0.171088          -0.196287          -0.116769   \n",
       "48839          -0.171088          -0.196287          -0.116769   \n",
       "48840          -0.171088          -0.196287          -0.116769   \n",
       "48841          -0.171088          -0.196287          -0.116769   \n",
       "\n",
       "       Education Years=9  Education Years=10  Education Years=11  \\\n",
       "0              -0.690988           -0.535289           -0.209896   \n",
       "1               1.447204           -0.535289           -0.209896   \n",
       "2              -0.690988           -0.535289           -0.209896   \n",
       "3              -0.690988            1.868149           -0.209896   \n",
       "4              -0.690988            1.868149           -0.209896   \n",
       "...                  ...                 ...                 ...   \n",
       "48837          -0.690988           -0.535289           -0.209896   \n",
       "48838           1.447204           -0.535289           -0.209896   \n",
       "48839           1.447204           -0.535289           -0.209896   \n",
       "48840           1.447204           -0.535289           -0.209896   \n",
       "48841           1.447204           -0.535289           -0.209896   \n",
       "\n",
       "       Education Years=12  Education Years=<6  Education Years=>12  \\\n",
       "0               -0.184093           -0.234702            -0.574182   \n",
       "1               -0.184093           -0.234702            -0.574182   \n",
       "2                5.432051           -0.234702            -0.574182   \n",
       "3               -0.184093           -0.234702            -0.574182   \n",
       "4               -0.184093           -0.234702            -0.574182   \n",
       "...                   ...                 ...                  ...   \n",
       "48837            5.432051           -0.234702            -0.574182   \n",
       "48838           -0.184093           -0.234702            -0.574182   \n",
       "48839           -0.184093           -0.234702            -0.574182   \n",
       "48840           -0.184093           -0.234702            -0.574182   \n",
       "48841           -0.184093           -0.234702            -0.574182   \n",
       "\n",
       "       Income Binary  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                1.0  \n",
       "3                1.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "48837            0.0  \n",
       "48838            1.0  \n",
       "48839            0.0  \n",
       "48840            0.0  \n",
       "48841            1.0  \n",
       "\n",
       "[48842 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_orig = StandardScaler()\n",
    "d.features = scale_orig.fit_transform(d.features)\n",
    "d.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6212/3491605419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#pre = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimPreproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOptTools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munprivileged_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munprivileged_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprivileged_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprivileged_groups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mdataset_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdataset_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cascade\\lib\\site-packages\\aif360\\algorithms\\transformer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mnew_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnew_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cascade\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\optim_preproc.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, sep)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Set Distortion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         self.OpT.set_distortion(self.optim_options['distortion_fun'],\n\u001b[0m\u001b[0;32m    116\u001b[0m                                 clist=self.optim_options['clist'])\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Individual Testing\n",
    "dataset_name = \"bank\"\n",
    "dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "\n",
    "#print(\"Specialized function: \", dataset_name)\n",
    "#dataset = get_OP_dataset(dataset_name) \n",
    "\n",
    "scale_orig = StandardScaler()\n",
    "dataset.features = scale_orig.fit_transform(dataset.features)\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=7)\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "#pre = LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0)\n",
    "#pre = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\n",
    "pre = OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups)\n",
    "pre.fit(dataset_train_pred)\n",
    "dataset_train_pred = pre.transform(dataset_train_pred)\n",
    "dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "dataset_test_pred = pre.transform(dataset_test_pred)\n",
    "dataset_test_pred = dataset_test.align_datasets(dataset_test_pred)\n",
    "\n",
    "\n",
    "X_train = dataset_train_pred.features\n",
    "y_train = dataset_train_pred.labels #.ravel()\n",
    "model = LogisticRegression()  \n",
    "model.fit(X_train, y_train)\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1)\n",
    "dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)     \n",
    "\n",
    "\n",
    "#inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "#inp = inprocessing.PrejudiceRemover(sensitive_attr=pro_attr)\n",
    "#inp = GerryFairClassifier()\n",
    "#inp.fit(dataset_train_pred)\n",
    "\n",
    "\n",
    "#dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "#dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "#dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "#dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "\n",
    "#dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "#dataset_test_pred = inp.predict(dataset_test_pred)\n",
    "\n",
    "'''\n",
    "y_train_pred = np.zeros_like(dataset_train_pred.scores)\n",
    "y_train_pred[dataset_train_pred.scores >= class_thresh] = dataset_train_pred.favorable_label\n",
    "y_train_pred[~(dataset_train_pred.scores >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_test_pred.scores)\n",
    "y_test_pred[dataset_test_pred.scores >= class_thresh] = dataset_test_pred.favorable_label\n",
    "y_test_pred[~(dataset_test_pred.scores >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "dataset_test_pred.labels = y_test_pred\n",
    "#dataset_test_pred.labels = y_test_pred#dataset_train_pred.features = dataset_train.features\n",
    "'''\n",
    "\n",
    "#pp = postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=7)\n",
    "#pp = postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "#pp = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0)\n",
    "#dataset_train_pred.features = dataset_train.features\n",
    "#pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "#dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "\n",
    "BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "dataset_test_pred.features = dataset_test.features \n",
    "CM = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "    \n",
    "\n",
    "print(run_classification_metrics(CM))\n",
    "print(run_binary_dataset_metrics(BLDM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dataset_train_pred.labels != dataset_train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88888889],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [0.88888889],\n",
       "       [0.88888889],\n",
       "       [0.88888889]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3353.0, 'FP': 10214.0, 'TN': 0.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "dataset_test_pred = inp.predict(dataset_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3330.0, 'FP': 0.0, 'TN': 10237.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_train.metadata  #.labels.ravel()\n",
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566666666666667"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(dataset_test.labels, dataset_test_pred.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_pred.labels = dataset_test_pred.labels.astype('float64') #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aif360.datasets.german_dataset.GermanDataset"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(dataset_test_pred.labels[0][0])\n",
    "type(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.grid_search_reduction.GridSearchReduction at 0x24a2689c850>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GermanDataset()\n",
    "dataset.labels = dataset.labels-1\n",
    "inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "inp.fit(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
