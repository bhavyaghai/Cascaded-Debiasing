{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from aif360.algorithms.inprocessing import GerryFairClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "import copy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    def f1_score(priv=None):\n",
    "            numer = CM.num_true_positives(privileged=priv)\n",
    "            denom = CM.num_true_positives(privileged=priv) + 0.5*float(CM.num_false_positives(privileged=priv) + CM.num_false_negatives(privileged=priv))\n",
    "            return float(numer/denom)\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(f1_score(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.false_positive_rate(privileged=False), 4),\n",
    "        round(CM.false_positive_rate(privileged=True), 4),\n",
    "        round(CM.false_negative_rate(privileged=False), 4),\n",
    "        round(CM.false_negative_rate(privileged=True), 4),\n",
    "        round(1-CM.error_rate(privileged=False), 4),\n",
    "        round(1-CM.error_rate(privileged=True), 4),\n",
    "        round(CM.false_discovery_rate(privileged=False), 4),\n",
    "        round(CM.false_discovery_rate(privileged=True), 4),\n",
    "        round(CM.false_omission_rate(privileged=False), 4),\n",
    "        round(CM.false_omission_rate(privileged=True), 4),\n",
    "        \n",
    "        #all results\n",
    "        CM.num_true_positives(),\n",
    "        CM.num_true_negatives(),\n",
    "        CM.num_false_positives(),\n",
    "        CM.num_false_negatives(),\n",
    "        \n",
    "        #privileged\n",
    "        CM.num_true_positives(privileged=True),\n",
    "        CM.num_true_negatives(privileged=True),\n",
    "        CM.num_false_positives(privileged=True),\n",
    "        CM.num_false_negatives(privileged=True),\n",
    "        \n",
    "        #unprivileged\n",
    "        CM.num_true_positives(privileged=False),\n",
    "        CM.num_true_negatives(privileged=False),\n",
    "        CM.num_false_positives(privileged=False),\n",
    "        CM.num_false_negatives(privileged=False),\n",
    "        \n",
    "        round(f1_score(True), 4),\n",
    "        round(f1_score(False), 4),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    #print(\"Consistency: \", BLDM.consistency())\n",
    "    return np.array([\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "        round(BLDM.consistency()[0], 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, preprocessing.DisparateImpactRemover):\n",
    "        return \"DIR\"\n",
    "    if isinstance(model, preprocessing.LFR):\n",
    "        return \"LFR\"\n",
    "    if isinstance(model, preprocessing.OptimPreproc):\n",
    "        return \"OP\"\n",
    "    if isinstance(model, preprocessing.Reweighing):\n",
    "        return \"RW\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"PR\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"AD\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ARTC\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"EGR\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GFC\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GSR\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MFC\"\n",
    "    \n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"EOP\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"CEOP\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"ROC\"\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if isinstance(dataset, aif360.datasets.german_dataset.GermanDataset):\n",
    "        return \"German Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.adult_dataset.AdultDataset):\n",
    "        return \"Adult Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.bank_dataset.BankDataset):\n",
    "        return \"Bank Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.compas_dataset.CompasDataset):\n",
    "        return \"Compas Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specialized dataset for Optimized Preprocessing\n",
    "def get_OP_dataset(dataset_name):\n",
    "    dataset = None\n",
    "    if dataset_name==\"bank\":\n",
    "        return\n",
    "    if dataset_name==\"adult\":\n",
    "        dataset = load_preproc_data_adult(['sex'])\n",
    "    elif dataset_name==\"compas\":\n",
    "        dataset = load_preproc_data_compas(['race'])\n",
    "    elif dataset_name==\"german\":\n",
    "        dataset = load_preproc_data_german(['age'])\n",
    "        dataset.labels = (dataset.labels-1.0).astype('float64')\n",
    "        dataset.favorable_label = 1.0\n",
    "        dataset.unfavorable_label = 0.0\n",
    "        dataset.metadata['label_maps'] = [{1.0: 'Good Credit', 0.0: 'Bad Credit'}]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_options(dataset_name):\n",
    "    optim_options = None\n",
    "    if dataset_name==\"adult\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_adult,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'sex'\n",
    "        return (AdultDataset(), pro_attr, [{'sex': 1}], [{'sex': 0}], optim_options)\n",
    "    elif dataset_name==\"compas\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_compas,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'race'\n",
    "        return (CompasDataset(), pro_attr, [{'race': 1}], [{'race': 0}], optim_options)\n",
    "    elif dataset_name==\"bank\":\n",
    "        pro_attr = 'age'\n",
    "        return (BankDataset(protected_attribute_names=['age'],\n",
    "            privileged_classes=[lambda x: x >= 25], \n",
    "            features_to_drop=['day_of_week']), pro_attr, [{'age': 1}], [{'age': 0}], None)\n",
    "    elif dataset_name==\"german\":\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_german,\n",
    "            \"epsilon\": 0.1,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }   \n",
    "        pro_attr = 'age'\n",
    "        label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "        #g = load_preproc_data_german(['age'])\n",
    "        g = GermanDataset(metadata={'label_maps': [label_map]})\n",
    "        g.labels = (g.labels-1.0).astype('float64')\n",
    "        g.favorable_label = 1.0\n",
    "        g.unfavorable_label = 0.0\n",
    "        #g.metadata['label_maps'] = [label_map]\n",
    "\n",
    "        # load_preproc_data_german(['age'])\n",
    "        return (g, pro_attr, [{'age': 1}], [{'age': 0}], optim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None, seed=123):\n",
    "    print(seed, get_model_name(preprocessing_algo), get_model_name(inprocessing_algo), get_model_name(postprocessing_algo))\n",
    "    scale_orig = StandardScaler()\n",
    "    dataset.features = scale_orig.fit_transform(dataset.features)\n",
    "    \n",
    "    # get specialized dataset for Optimized Preprocessing technique\n",
    "    if get_model_name(preprocessing_algo)==\"OP\" and dataset_name!=\"bank\":\n",
    "        #print(\"Specialized function: \", dataset_name)\n",
    "        dataset = get_OP_dataset(dataset_name) \n",
    "        \n",
    "    #np.random.seed(seed)\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=seed)\n",
    "\n",
    "    model = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "    \n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "            \n",
    "    if preprocessing_algo is not None:\n",
    "        if get_model_name(preprocessing_algo)==\"DIR\":\n",
    "            dataset_train_pred = preprocessing_algo.fit_transform(dataset_train_pred)\n",
    "            dataset_test_pred = preprocessing_algo.fit_transform(dataset_test_pred)\n",
    "        elif get_model_name(preprocessing_algo) in [\"OP\", \"LFR\"]:\n",
    "            preprocessing_algo.fit(dataset_train_pred)\n",
    "            dataset_train_pred = preprocessing_algo.transform(dataset_train_pred)\n",
    "            dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "            dataset_test_pred = preprocessing_algo.transform(dataset_test_pred)\n",
    "            dataset_test_pred = dataset_test.align_datasets(dataset_test_pred)\n",
    "    \n",
    "    if inprocessing_algo is not None:\n",
    "        inp = inprocessing_algo\n",
    "        inp.fit(dataset_train_pred)\n",
    "        dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "        dataset_test_pred = inp.predict(dataset_test_pred) \n",
    "        \n",
    "        # exception for GFC \n",
    "        if get_model_name(inprocessing_algo)==\"GFC\":\n",
    "            dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "            dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "            dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "            dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "    else:\n",
    "        model.fit(dataset_train_pred.features, dataset_train_pred.labels)   # .ravel()\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1) \n",
    "        dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)  \n",
    "            \n",
    "    if postprocessing_algo is not None:\n",
    "        dataset_train.features = dataset_train_pred.features\n",
    "        pp = postprocessing_algo\n",
    "        pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "        dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    \n",
    "    dataset_test_pred.features = dataset_test.features \n",
    "    \n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "     \n",
    "    name = \"\"\n",
    "    if preprocessing_algo is not None:\n",
    "        name += get_model_name(preprocessing_algo) + \" + \"\n",
    "    if inprocessing_algo is not None:\n",
    "        name += get_model_name(inprocessing_algo) + \" + \"\n",
    "    if postprocessing_algo is not None:\n",
    "        name += get_model_name(postprocessing_algo)\n",
    "    if name == \"\":\n",
    "        name = get_model_name(model)\n",
    "        \n",
    "    if name.endswith(\" + \"):\n",
    "        lastIndex = name.rindex(\" + \")\n",
    "        name = name[:lastIndex]\n",
    "    \n",
    "    #print(run_classification_metrics(CM))\n",
    "    #print(run_binary_dataset_metrics(BLDM))\n",
    "    metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "       \n",
    "    return {\"key\":name, \"val\":metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  adult\n",
      "3 OP None None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP None EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP None CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP None ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP None ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP None ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GFC ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GFC ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GFC ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP PR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP PR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP PR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP EGR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP EGR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP EGR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR None\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR None\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR None\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR EOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR CEOP\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 OP GSR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.011336\n",
      "11 OP GSR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.010862\n",
      "17 OP GSR ROC\n",
      "Optimized Preprocessing: Objective converged to 0.012627\n",
      "3 DIR None None\n",
      "11 DIR None None\n",
      "17 DIR None None\n",
      "3 DIR None EOP\n",
      "11 DIR None EOP\n",
      "17 DIR None EOP\n",
      "3 DIR None CEOP\n",
      "11 DIR None CEOP\n",
      "17 DIR None CEOP\n",
      "3 DIR None ROC\n",
      "11 DIR None ROC\n",
      "17 DIR None ROC\n",
      "3 DIR GFC None\n",
      "11 DIR GFC None\n",
      "17 DIR GFC None\n",
      "3 DIR GFC EOP\n",
      "11 DIR GFC EOP\n",
      "17 DIR GFC EOP\n",
      "3 DIR GFC CEOP\n",
      "11 DIR GFC CEOP\n",
      "17 DIR GFC CEOP\n",
      "3 DIR GFC ROC\n",
      "11 DIR GFC ROC\n",
      "17 DIR GFC ROC\n",
      "3 DIR PR None\n",
      "11 DIR PR None\n",
      "17 DIR PR None\n",
      "3 DIR PR EOP\n",
      "11 DIR PR EOP\n",
      "17 DIR PR EOP\n",
      "3 DIR PR CEOP\n",
      "11 DIR PR CEOP\n",
      "17 DIR PR CEOP\n",
      "3 DIR PR ROC\n",
      "11 DIR PR ROC\n",
      "17 DIR PR ROC\n",
      "3 DIR EGR None\n",
      "11 DIR EGR None\n",
      "17 DIR EGR None\n",
      "3 DIR EGR EOP\n",
      "11 DIR EGR EOP\n",
      "17 DIR EGR EOP\n",
      "3 DIR EGR CEOP\n",
      "11 DIR EGR CEOP\n",
      "17 DIR EGR CEOP\n",
      "3 DIR EGR ROC\n",
      "11 DIR EGR ROC\n",
      "17 DIR EGR ROC\n",
      "3 DIR GSR None\n",
      "11 DIR GSR None\n",
      "17 DIR GSR None\n",
      "3 DIR GSR EOP\n",
      "11 DIR GSR EOP\n",
      "17 DIR GSR EOP\n",
      "3 DIR GSR CEOP\n",
      "11 DIR GSR CEOP\n",
      "17 DIR GSR CEOP\n",
      "3 DIR GSR ROC\n",
      "11 DIR GSR ROC\n",
      "17 DIR GSR ROC\n",
      "3 None None None\n",
      "11 None None None\n",
      "17 None None None\n",
      "3 None None EOP\n",
      "11 None None EOP\n",
      "17 None None EOP\n",
      "3 None None CEOP\n",
      "11 None None CEOP\n",
      "17 None None CEOP\n",
      "3 None None ROC\n",
      "11 None None ROC\n",
      "17 None None ROC\n"
     ]
    }
   ],
   "source": [
    "#datasets = [\"compas\", \"german\", \"adult\", \"bank\"]\n",
    "datasets = [\"adult\"]\n",
    "for dataset_name in datasets:\n",
    "    print(\"DATASET NAME: \", dataset_name)\n",
    "    dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "    \n",
    "    preprocessing_algos = [OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups),\n",
    "                           preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr),\n",
    "                           None,\n",
    "                           #LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0),\n",
    "                          #preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                           ]\n",
    "                          \n",
    "    inprocessing_algos = [None,\n",
    "                           #inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=seed),\n",
    "                          GerryFairClassifier(),\n",
    "                          inprocessing.PrejudiceRemover(sensitive_attr=pro_attr),\n",
    "                          inprocessing.ExponentiatedGradientReduction(LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          ]\n",
    "\n",
    "    postprocessing_algos = [None,\n",
    "                            postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),  \n",
    "                            ]\n",
    "\n",
    "    df = {}\n",
    "    all_data = {}\n",
    "\n",
    "    for pre in preprocessing_algos:\n",
    "        for inproc in inprocessing_algos:\n",
    "            for post in postprocessing_algos:    \n",
    "                kfold_data = []   # store data for each fold\n",
    "                col_name = None\n",
    "                # k-fold cross vaidation - Repeat the process 3 times\n",
    "                for seed in [3, 11, 17]:  #[3, 5, 11, 17, 29]:\n",
    "                    try: \n",
    "                        res = execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                                 preprocessing_algo=copy.deepcopy(pre), \n",
    "                                 inprocessing_algo=copy.deepcopy(inproc),\n",
    "                                 postprocessing_algo=copy.deepcopy(post), seed=seed)\n",
    "                        \n",
    "                        col_name = res[\"key\"]\n",
    "                        if col_name:\n",
    "                            kfold_data.append(res[\"val\"])\n",
    "                            all_data[col_name+\" - \"+str(seed)] = res[\"val\"]\n",
    "                        \n",
    "                    except KeyboardInterrupt:\n",
    "                        raise KeyboardInterrupt()\n",
    "                    except Exception as e:\n",
    "                        print(\"FAILED: \" + get_model_name(pre) + \", \" + get_model_name(inproc) + \", \" + get_model_name(post) + \" on dataset \" + get_dataset_name(dataset), e)\n",
    "                \n",
    "                if col_name:\n",
    "                    df[col_name] = np.array(kfold_data).mean(axis=0).tolist()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    all_data = pd.DataFrame.from_dict(all_data)\n",
    "    df.index = all_data.index = [\"Accuracy\", \"F1 Score\", \"Theil Index\",\n",
    "                    \"False Positive Rate - Unprivileged\", \"False Positive Rate - Privileged\",\n",
    "                    \"False Negative Rate - Unprivileged\", \"False Negative Rate - Privileged\",\n",
    "                    \"Accuracy - Unprivileged\", \"Accuracy - Privileged\",\n",
    "                    \"False Discovery Rate - Unprivileged\", \"False Discovery Rate - Privileged\",\n",
    "                    \"False Omission Rate - Unprivileged\", \"False Omission Rate - Privileged\",\n",
    "                    \"Num True Pos\", \"Num True Neg\", \"Num False Pos\", \"Num False Neg\",\n",
    "                    \"Num True Pos - Privileged\", \"Num True Neg - Privileged\", \"Num False Pos - Privileged\", \"Num False Neg - Privileged\",\n",
    "                    \"Num True Pos - Unprivileged\", \"Num True Neg - Unprivileged\", \"Num False Pos - Unprivileged\", \"Num False Neg - Unprivileged\",\n",
    "                    \"F1 Score - Privileged\", \"F1 Score - Unprivileged\",\n",
    "                    \"Privileged base Rate\", \"Unprivileged base Rate\", \"Consistency\"]\n",
    "\n",
    "    df = df.T\n",
    "    all_data = all_data.T\n",
    "    df.to_csv(\"./data/\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    all_data.to_csv(\"./data/All_Data -\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    display(df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EXTRA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>age_cat=25 - 45</th>\n",
       "      <th>age_cat=Greater than 45</th>\n",
       "      <th>age_cat=Less than 25</th>\n",
       "      <th>...</th>\n",
       "      <th>c_charge_desc=Viol Injunct Domestic Violence</th>\n",
       "      <th>c_charge_desc=Viol Injunction Protect Dom Vi</th>\n",
       "      <th>c_charge_desc=Viol Pretrial Release Dom Viol</th>\n",
       "      <th>c_charge_desc=Viol Prot Injunc Repeat Viol</th>\n",
       "      <th>c_charge_desc=Violation License Restrictions</th>\n",
       "      <th>c_charge_desc=Violation Of Boater Safety Id</th>\n",
       "      <th>c_charge_desc=Violation of Injunction Order/Stalking/Cyberstalking</th>\n",
       "      <th>c_charge_desc=Voyeurism</th>\n",
       "      <th>c_charge_desc=arrest case no charge</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.939659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>1.942478</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.898223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>1.888511</td>\n",
       "      <td>0.158601</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>2.266112</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.916224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.684403</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>1.942478</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.130647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.052150</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.983510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127668</td>\n",
       "      <td>-0.183308</td>\n",
       "      <td>-0.235203</td>\n",
       "      <td>-0.262901</td>\n",
       "      <td>-1.156231</td>\n",
       "      <td>-0.514806</td>\n",
       "      <td>1.891645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087634</td>\n",
       "      <td>-0.031207</td>\n",
       "      <td>-0.044155</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6167 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex       age  race  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
       "1      0.0  2.939659   0.0      -0.127668       -0.183308        -0.235203   \n",
       "3      0.0 -0.045361   0.0      -0.127668       -0.183308        -0.235203   \n",
       "4      0.0 -0.898223   0.0      -0.127668       -0.183308         1.888511   \n",
       "7      0.0  0.807502   0.0      -0.127668       -0.183308        -0.235203   \n",
       "8      0.0  0.551643   1.0      -0.127668       -0.183308        -0.235203   \n",
       "...    ...       ...   ...            ...             ...              ...   \n",
       "10996  0.0 -0.983510   0.0      -0.127668       -0.183308        -0.235203   \n",
       "10997  0.0 -0.983510   0.0      -0.127668       -0.183308        -0.235203   \n",
       "10999  0.0  1.916224   0.0      -0.127668       -0.183308        -0.235203   \n",
       "11000  1.0 -0.130647   0.0      -0.127668       -0.183308        -0.235203   \n",
       "11001  1.0 -0.983510   0.0      -0.127668       -0.183308        -0.235203   \n",
       "\n",
       "       priors_count  age_cat=25 - 45  age_cat=Greater than 45  \\\n",
       "1         -0.684403        -1.156231                 1.942478   \n",
       "3         -0.684403         0.864879                -0.514806   \n",
       "4          0.158601        -1.156231                -0.514806   \n",
       "7         -0.684403         0.864879                -0.514806   \n",
       "8          2.266112         0.864879                -0.514806   \n",
       "...             ...              ...                      ...   \n",
       "10996     -0.684403        -1.156231                -0.514806   \n",
       "10997     -0.684403        -1.156231                -0.514806   \n",
       "10999     -0.684403        -1.156231                 1.942478   \n",
       "11000     -0.052150         0.864879                -0.514806   \n",
       "11001     -0.262901        -1.156231                -0.514806   \n",
       "\n",
       "       age_cat=Less than 25  ...  \\\n",
       "1                 -0.528640  ...   \n",
       "3                 -0.528640  ...   \n",
       "4                  1.891645  ...   \n",
       "7                 -0.528640  ...   \n",
       "8                 -0.528640  ...   \n",
       "...                     ...  ...   \n",
       "10996              1.891645  ...   \n",
       "10997              1.891645  ...   \n",
       "10999             -0.528640  ...   \n",
       "11000             -0.528640  ...   \n",
       "11001              1.891645  ...   \n",
       "\n",
       "       c_charge_desc=Viol Injunct Domestic Violence  \\\n",
       "1                                         -0.087634   \n",
       "3                                         -0.087634   \n",
       "4                                         -0.087634   \n",
       "7                                         -0.087634   \n",
       "8                                         -0.087634   \n",
       "...                                             ...   \n",
       "10996                                     -0.087634   \n",
       "10997                                     -0.087634   \n",
       "10999                                     -0.087634   \n",
       "11000                                     -0.087634   \n",
       "11001                                     -0.087634   \n",
       "\n",
       "       c_charge_desc=Viol Injunction Protect Dom Vi  \\\n",
       "1                                         -0.031207   \n",
       "3                                         -0.031207   \n",
       "4                                         -0.031207   \n",
       "7                                         -0.031207   \n",
       "8                                         -0.031207   \n",
       "...                                             ...   \n",
       "10996                                     -0.031207   \n",
       "10997                                     -0.031207   \n",
       "10999                                     -0.031207   \n",
       "11000                                     -0.031207   \n",
       "11001                                     -0.031207   \n",
       "\n",
       "       c_charge_desc=Viol Pretrial Release Dom Viol  \\\n",
       "1                                         -0.044155   \n",
       "3                                         -0.044155   \n",
       "4                                         -0.044155   \n",
       "7                                         -0.044155   \n",
       "8                                         -0.044155   \n",
       "...                                             ...   \n",
       "10996                                     -0.044155   \n",
       "10997                                     -0.044155   \n",
       "10999                                     -0.044155   \n",
       "11000                                     -0.044155   \n",
       "11001                                     -0.044155   \n",
       "\n",
       "       c_charge_desc=Viol Prot Injunc Repeat Viol  \\\n",
       "1                                       -0.054105   \n",
       "3                                       -0.054105   \n",
       "4                                       -0.054105   \n",
       "7                                       -0.054105   \n",
       "8                                       -0.054105   \n",
       "...                                           ...   \n",
       "10996                                   -0.054105   \n",
       "10997                                   -0.054105   \n",
       "10999                                   -0.054105   \n",
       "11000                                   -0.054105   \n",
       "11001                                   -0.054105   \n",
       "\n",
       "       c_charge_desc=Violation License Restrictions  \\\n",
       "1                                         -0.012735   \n",
       "3                                         -0.012735   \n",
       "4                                         -0.012735   \n",
       "7                                         -0.012735   \n",
       "8                                         -0.012735   \n",
       "...                                             ...   \n",
       "10996                                     -0.012735   \n",
       "10997                                     -0.012735   \n",
       "10999                                     -0.012735   \n",
       "11000                                     -0.012735   \n",
       "11001                                     -0.012735   \n",
       "\n",
       "       c_charge_desc=Violation Of Boater Safety Id  \\\n",
       "1                                        -0.012735   \n",
       "3                                        -0.012735   \n",
       "4                                        -0.012735   \n",
       "7                                        -0.012735   \n",
       "8                                        -0.012735   \n",
       "...                                            ...   \n",
       "10996                                    -0.012735   \n",
       "10997                                    -0.012735   \n",
       "10999                                    -0.012735   \n",
       "11000                                    -0.012735   \n",
       "11001                                    -0.012735   \n",
       "\n",
       "       c_charge_desc=Violation of Injunction Order/Stalking/Cyberstalking  \\\n",
       "1                                              -0.012735                    \n",
       "3                                              -0.012735                    \n",
       "4                                              -0.012735                    \n",
       "7                                              -0.012735                    \n",
       "8                                              -0.012735                    \n",
       "...                                                  ...                    \n",
       "10996                                          -0.012735                    \n",
       "10997                                          -0.012735                    \n",
       "10999                                          -0.012735                    \n",
       "11000                                          -0.012735                    \n",
       "11001                                          -0.012735                    \n",
       "\n",
       "       c_charge_desc=Voyeurism  c_charge_desc=arrest case no charge  \\\n",
       "1                    -0.012735                            -0.381633   \n",
       "3                    -0.012735                            -0.381633   \n",
       "4                    -0.012735                            -0.381633   \n",
       "7                    -0.012735                            -0.381633   \n",
       "8                    -0.012735                            -0.381633   \n",
       "...                        ...                                  ...   \n",
       "10996                -0.012735                            -0.381633   \n",
       "10997                -0.012735                            -0.381633   \n",
       "10999                -0.012735                            -0.381633   \n",
       "11000                -0.012735                            -0.381633   \n",
       "11001                -0.012735                            -0.381633   \n",
       "\n",
       "       two_year_recid  \n",
       "1                 0.0  \n",
       "3                 1.0  \n",
       "4                 1.0  \n",
       "7                 0.0  \n",
       "8                 1.0  \n",
       "...               ...  \n",
       "10996             0.0  \n",
       "10997             0.0  \n",
       "10999             0.0  \n",
       "11000             0.0  \n",
       "11001             1.0  \n",
       "\n",
       "[6167 rows x 402 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_orig = StandardScaler()\n",
    "g.features = scale_orig.fit_transform(g.features)\n",
    "g.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>Age (decade)=10</th>\n",
       "      <th>Age (decade)=20</th>\n",
       "      <th>Age (decade)=30</th>\n",
       "      <th>Age (decade)=40</th>\n",
       "      <th>Age (decade)=50</th>\n",
       "      <th>Age (decade)=60</th>\n",
       "      <th>Age (decade)=&gt;=70</th>\n",
       "      <th>Education Years=6</th>\n",
       "      <th>Education Years=7</th>\n",
       "      <th>Education Years=8</th>\n",
       "      <th>Education Years=9</th>\n",
       "      <th>Education Years=10</th>\n",
       "      <th>Education Years=11</th>\n",
       "      <th>Education Years=12</th>\n",
       "      <th>Education Years=&lt;6</th>\n",
       "      <th>Education Years=&gt;12</th>\n",
       "      <th>Income Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  sex  Age (decade)=10  Age (decade)=20  Age (decade)=30  \\\n",
       "0       0.0  1.0              0.0              1.0              0.0   \n",
       "1       1.0  1.0              0.0              0.0              1.0   \n",
       "2       1.0  1.0              0.0              1.0              0.0   \n",
       "3       0.0  1.0              0.0              0.0              0.0   \n",
       "4       1.0  0.0              1.0              0.0              0.0   \n",
       "...     ...  ...              ...              ...              ...   \n",
       "48837   1.0  0.0              0.0              1.0              0.0   \n",
       "48838   1.0  1.0              0.0              0.0              0.0   \n",
       "48839   1.0  0.0              0.0              0.0              0.0   \n",
       "48840   1.0  1.0              0.0              1.0              0.0   \n",
       "48841   1.0  0.0              0.0              0.0              0.0   \n",
       "\n",
       "       Age (decade)=40  Age (decade)=50  Age (decade)=60  Age (decade)=>=70  \\\n",
       "0                  0.0              0.0              0.0                0.0   \n",
       "1                  0.0              0.0              0.0                0.0   \n",
       "2                  0.0              0.0              0.0                0.0   \n",
       "3                  1.0              0.0              0.0                0.0   \n",
       "4                  0.0              0.0              0.0                0.0   \n",
       "...                ...              ...              ...                ...   \n",
       "48837              0.0              0.0              0.0                0.0   \n",
       "48838              1.0              0.0              0.0                0.0   \n",
       "48839              0.0              1.0              0.0                0.0   \n",
       "48840              0.0              0.0              0.0                0.0   \n",
       "48841              0.0              1.0              0.0                0.0   \n",
       "\n",
       "       Education Years=6  Education Years=7  Education Years=8  \\\n",
       "0                    0.0                1.0                0.0   \n",
       "1                    0.0                0.0                0.0   \n",
       "2                    0.0                0.0                0.0   \n",
       "3                    0.0                0.0                0.0   \n",
       "4                    0.0                0.0                0.0   \n",
       "...                  ...                ...                ...   \n",
       "48837                0.0                0.0                0.0   \n",
       "48838                0.0                0.0                0.0   \n",
       "48839                0.0                0.0                0.0   \n",
       "48840                0.0                0.0                0.0   \n",
       "48841                0.0                0.0                0.0   \n",
       "\n",
       "       Education Years=9  Education Years=10  Education Years=11  \\\n",
       "0                    0.0                 0.0                 0.0   \n",
       "1                    1.0                 0.0                 0.0   \n",
       "2                    0.0                 0.0                 0.0   \n",
       "3                    0.0                 1.0                 0.0   \n",
       "4                    0.0                 1.0                 0.0   \n",
       "...                  ...                 ...                 ...   \n",
       "48837                0.0                 0.0                 0.0   \n",
       "48838                1.0                 0.0                 0.0   \n",
       "48839                1.0                 0.0                 0.0   \n",
       "48840                1.0                 0.0                 0.0   \n",
       "48841                1.0                 0.0                 0.0   \n",
       "\n",
       "       Education Years=12  Education Years=<6  Education Years=>12  \\\n",
       "0                     0.0                 0.0                  0.0   \n",
       "1                     0.0                 0.0                  0.0   \n",
       "2                     1.0                 0.0                  0.0   \n",
       "3                     0.0                 0.0                  0.0   \n",
       "4                     0.0                 0.0                  0.0   \n",
       "...                   ...                 ...                  ...   \n",
       "48837                 1.0                 0.0                  0.0   \n",
       "48838                 0.0                 0.0                  0.0   \n",
       "48839                 0.0                 0.0                  0.0   \n",
       "48840                 0.0                 0.0                  0.0   \n",
       "48841                 0.0                 0.0                  0.0   \n",
       "\n",
       "       Income Binary  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                1.0  \n",
       "3                1.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "48837            0.0  \n",
       "48838            1.0  \n",
       "48839            0.0  \n",
       "48840            0.0  \n",
       "48841            1.0  \n",
       "\n",
       "[48842 rows x 19 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = load_preproc_data_adult(['sex'])\n",
    "d.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>Age (decade)=10</th>\n",
       "      <th>Age (decade)=20</th>\n",
       "      <th>Age (decade)=30</th>\n",
       "      <th>Age (decade)=40</th>\n",
       "      <th>Age (decade)=50</th>\n",
       "      <th>Age (decade)=60</th>\n",
       "      <th>Age (decade)=&gt;=70</th>\n",
       "      <th>Education Years=6</th>\n",
       "      <th>Education Years=7</th>\n",
       "      <th>Education Years=8</th>\n",
       "      <th>Education Years=9</th>\n",
       "      <th>Education Years=10</th>\n",
       "      <th>Education Years=11</th>\n",
       "      <th>Education Years=12</th>\n",
       "      <th>Education Years=&lt;6</th>\n",
       "      <th>Education Years=&gt;12</th>\n",
       "      <th>Income Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.428701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>5.094580</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>1.666646</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>5.432051</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.428701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>1.885327</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>1.868149</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.296390</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>1.868149</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>-0.690988</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>5.432051</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>1.885327</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>2.525680</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>1.751705</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>-0.395933</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.411743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232754</td>\n",
       "      <td>-0.570872</td>\n",
       "      <td>-0.600007</td>\n",
       "      <td>-0.530412</td>\n",
       "      <td>2.525680</td>\n",
       "      <td>-0.258261</td>\n",
       "      <td>-0.144649</td>\n",
       "      <td>-0.171088</td>\n",
       "      <td>-0.196287</td>\n",
       "      <td>-0.116769</td>\n",
       "      <td>1.447204</td>\n",
       "      <td>-0.535289</td>\n",
       "      <td>-0.209896</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>-0.234702</td>\n",
       "      <td>-0.574182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           race  sex  Age (decade)=10  Age (decade)=20  Age (decade)=30  \\\n",
       "0     -2.428701  1.0        -0.232754         1.751705        -0.600007   \n",
       "1      0.411743  1.0        -0.232754        -0.570872         1.666646   \n",
       "2      0.411743  1.0        -0.232754         1.751705        -0.600007   \n",
       "3     -2.428701  1.0        -0.232754        -0.570872        -0.600007   \n",
       "4      0.411743  0.0         4.296390        -0.570872        -0.600007   \n",
       "...         ...  ...              ...              ...              ...   \n",
       "48837  0.411743  0.0        -0.232754         1.751705        -0.600007   \n",
       "48838  0.411743  1.0        -0.232754        -0.570872        -0.600007   \n",
       "48839  0.411743  0.0        -0.232754        -0.570872        -0.600007   \n",
       "48840  0.411743  1.0        -0.232754         1.751705        -0.600007   \n",
       "48841  0.411743  0.0        -0.232754        -0.570872        -0.600007   \n",
       "\n",
       "       Age (decade)=40  Age (decade)=50  Age (decade)=60  Age (decade)=>=70  \\\n",
       "0            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "1            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "2            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "3             1.885327        -0.395933        -0.258261          -0.144649   \n",
       "4            -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "...                ...              ...              ...                ...   \n",
       "48837        -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "48838         1.885327        -0.395933        -0.258261          -0.144649   \n",
       "48839        -0.530412         2.525680        -0.258261          -0.144649   \n",
       "48840        -0.530412        -0.395933        -0.258261          -0.144649   \n",
       "48841        -0.530412         2.525680        -0.258261          -0.144649   \n",
       "\n",
       "       Education Years=6  Education Years=7  Education Years=8  \\\n",
       "0              -0.171088           5.094580          -0.116769   \n",
       "1              -0.171088          -0.196287          -0.116769   \n",
       "2              -0.171088          -0.196287          -0.116769   \n",
       "3              -0.171088          -0.196287          -0.116769   \n",
       "4              -0.171088          -0.196287          -0.116769   \n",
       "...                  ...                ...                ...   \n",
       "48837          -0.171088          -0.196287          -0.116769   \n",
       "48838          -0.171088          -0.196287          -0.116769   \n",
       "48839          -0.171088          -0.196287          -0.116769   \n",
       "48840          -0.171088          -0.196287          -0.116769   \n",
       "48841          -0.171088          -0.196287          -0.116769   \n",
       "\n",
       "       Education Years=9  Education Years=10  Education Years=11  \\\n",
       "0              -0.690988           -0.535289           -0.209896   \n",
       "1               1.447204           -0.535289           -0.209896   \n",
       "2              -0.690988           -0.535289           -0.209896   \n",
       "3              -0.690988            1.868149           -0.209896   \n",
       "4              -0.690988            1.868149           -0.209896   \n",
       "...                  ...                 ...                 ...   \n",
       "48837          -0.690988           -0.535289           -0.209896   \n",
       "48838           1.447204           -0.535289           -0.209896   \n",
       "48839           1.447204           -0.535289           -0.209896   \n",
       "48840           1.447204           -0.535289           -0.209896   \n",
       "48841           1.447204           -0.535289           -0.209896   \n",
       "\n",
       "       Education Years=12  Education Years=<6  Education Years=>12  \\\n",
       "0               -0.184093           -0.234702            -0.574182   \n",
       "1               -0.184093           -0.234702            -0.574182   \n",
       "2                5.432051           -0.234702            -0.574182   \n",
       "3               -0.184093           -0.234702            -0.574182   \n",
       "4               -0.184093           -0.234702            -0.574182   \n",
       "...                   ...                 ...                  ...   \n",
       "48837            5.432051           -0.234702            -0.574182   \n",
       "48838           -0.184093           -0.234702            -0.574182   \n",
       "48839           -0.184093           -0.234702            -0.574182   \n",
       "48840           -0.184093           -0.234702            -0.574182   \n",
       "48841           -0.184093           -0.234702            -0.574182   \n",
       "\n",
       "       Income Binary  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                1.0  \n",
       "3                1.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "48837            0.0  \n",
       "48838            1.0  \n",
       "48839            0.0  \n",
       "48840            0.0  \n",
       "48841            1.0  \n",
       "\n",
       "[48842 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_orig = StandardScaler()\n",
    "d.features = scale_orig.fit_transform(d.features)\n",
    "d.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6212/3491605419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#pre = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimPreproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOptTools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munprivileged_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munprivileged_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprivileged_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprivileged_groups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mdataset_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdataset_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cascade\\lib\\site-packages\\aif360\\algorithms\\transformer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mnew_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnew_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cascade\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\optim_preproc.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, sep)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Set Distortion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         self.OpT.set_distortion(self.optim_options['distortion_fun'],\n\u001b[0m\u001b[0;32m    116\u001b[0m                                 clist=self.optim_options['clist'])\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Individual Testing\n",
    "dataset_name = \"bank\"\n",
    "dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "\n",
    "#print(\"Specialized function: \", dataset_name)\n",
    "#dataset = get_OP_dataset(dataset_name) \n",
    "\n",
    "scale_orig = StandardScaler()\n",
    "dataset.features = scale_orig.fit_transform(dataset.features)\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=7)\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "#pre = LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0)\n",
    "#pre = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\n",
    "pre = OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups)\n",
    "pre.fit(dataset_train_pred)\n",
    "dataset_train_pred = pre.transform(dataset_train_pred)\n",
    "dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "dataset_test_pred = pre.transform(dataset_test_pred)\n",
    "dataset_test_pred = dataset_test.align_datasets(dataset_test_pred)\n",
    "\n",
    "\n",
    "X_train = dataset_train_pred.features\n",
    "y_train = dataset_train_pred.labels #.ravel()\n",
    "model = LogisticRegression()  \n",
    "model.fit(X_train, y_train)\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1)\n",
    "dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)     \n",
    "\n",
    "\n",
    "#inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "#inp = inprocessing.PrejudiceRemover(sensitive_attr=pro_attr)\n",
    "#inp = GerryFairClassifier()\n",
    "#inp.fit(dataset_train_pred)\n",
    "\n",
    "\n",
    "#dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "#dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "#dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "#dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "\n",
    "#dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "#dataset_test_pred = inp.predict(dataset_test_pred)\n",
    "\n",
    "'''\n",
    "y_train_pred = np.zeros_like(dataset_train_pred.scores)\n",
    "y_train_pred[dataset_train_pred.scores >= class_thresh] = dataset_train_pred.favorable_label\n",
    "y_train_pred[~(dataset_train_pred.scores >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_test_pred.scores)\n",
    "y_test_pred[dataset_test_pred.scores >= class_thresh] = dataset_test_pred.favorable_label\n",
    "y_test_pred[~(dataset_test_pred.scores >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "dataset_test_pred.labels = y_test_pred\n",
    "#dataset_test_pred.labels = y_test_pred#dataset_train_pred.features = dataset_train.features\n",
    "'''\n",
    "\n",
    "#pp = postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=7)\n",
    "#pp = postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "#pp = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0)\n",
    "#dataset_train_pred.features = dataset_train.features\n",
    "#pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "#dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "\n",
    "BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "dataset_test_pred.features = dataset_test.features \n",
    "CM = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "    \n",
    "\n",
    "print(run_classification_metrics(CM))\n",
    "print(run_binary_dataset_metrics(BLDM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dataset_train_pred.labels != dataset_train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88888889],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [0.88888889],\n",
       "       [0.88888889],\n",
       "       [0.88888889]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3353.0, 'FP': 10214.0, 'TN': 0.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "dataset_test_pred = inp.predict(dataset_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3330.0, 'FP': 0.0, 'TN': 10237.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_train.metadata  #.labels.ravel()\n",
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566666666666667"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(dataset_test.labels, dataset_test_pred.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_pred.labels = dataset_test_pred.labels.astype('float64') #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aif360.datasets.german_dataset.GermanDataset"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(dataset_test_pred.labels[0][0])\n",
    "type(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.grid_search_reduction.GridSearchReduction at 0x24a2689c850>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GermanDataset()\n",
    "dataset.labels = dataset.labels-1\n",
    "inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "inp.fit(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
