{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from aif360.algorithms.inprocessing import GerryFairClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "import copy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    def f1_score(priv=None):\n",
    "            numer = CM.num_true_positives(privileged=priv)\n",
    "            denom = CM.num_true_positives(privileged=priv) + 0.5*float(CM.num_false_positives(privileged=priv) + CM.num_false_negatives(privileged=priv))\n",
    "            return float(numer/denom)\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(f1_score(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.false_positive_rate(privileged=False), 4),\n",
    "        round(CM.false_positive_rate(privileged=True), 4),\n",
    "        round(CM.false_negative_rate(privileged=False), 4),\n",
    "        round(CM.false_negative_rate(privileged=True), 4),\n",
    "        round(1-CM.error_rate(privileged=False), 4),\n",
    "        round(1-CM.error_rate(privileged=True), 4),\n",
    "        round(CM.false_discovery_rate(privileged=False), 4),\n",
    "        round(CM.false_discovery_rate(privileged=True), 4),\n",
    "        round(CM.false_omission_rate(privileged=False), 4),\n",
    "        round(CM.false_omission_rate(privileged=True), 4),\n",
    "        \n",
    "        #all results\n",
    "        CM.num_true_positives(),\n",
    "        CM.num_true_negatives(),\n",
    "        CM.num_false_positives(),\n",
    "        CM.num_false_negatives(),\n",
    "        \n",
    "        #privileged\n",
    "        CM.num_true_positives(privileged=True),\n",
    "        CM.num_true_negatives(privileged=True),\n",
    "        CM.num_false_positives(privileged=True),\n",
    "        CM.num_false_negatives(privileged=True),\n",
    "        \n",
    "        #unprivileged\n",
    "        CM.num_true_positives(privileged=False),\n",
    "        CM.num_true_negatives(privileged=False),\n",
    "        CM.num_false_positives(privileged=False),\n",
    "        CM.num_false_negatives(privileged=False),\n",
    "        \n",
    "        round(f1_score(True), 4),\n",
    "        round(f1_score(False), 4),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    #print(\"Consistency: \", BLDM.consistency())\n",
    "    return np.array([\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "        round(BLDM.consistency()[0], 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, preprocessing.DisparateImpactRemover):\n",
    "        return \"DIR\"\n",
    "    if isinstance(model, preprocessing.LFR):\n",
    "        return \"LFR\"\n",
    "    if isinstance(model, preprocessing.OptimPreproc):\n",
    "        return \"OP\"\n",
    "    if isinstance(model, preprocessing.Reweighing):\n",
    "        return \"RW\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"PR\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"AD\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ARTC\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"EGR\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GFC\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GSR\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MFC\"\n",
    "    \n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"EOP\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"CEOP\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"ROC\"\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if isinstance(dataset, aif360.datasets.german_dataset.GermanDataset):\n",
    "        return \"German Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.adult_dataset.AdultDataset):\n",
    "        return \"Adult Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.bank_dataset.BankDataset):\n",
    "        return \"Bank Dataset\"\n",
    "    if isinstance(dataset, aif360.datasets.compas_dataset.CompasDataset):\n",
    "        return \"Compas Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specialized dataset for Optimized Preprocessing\n",
    "def get_OP_dataset(dataset_name):\n",
    "    dataset = None\n",
    "    if dataset_name==\"bank\":\n",
    "        return\n",
    "    if dataset_name==\"adult\":\n",
    "        dataset = load_preproc_data_adult(['sex'])\n",
    "    elif dataset_name==\"compas\":\n",
    "        dataset = load_preproc_data_compas(['race'])\n",
    "    elif dataset_name==\"german\":\n",
    "        dataset = load_preproc_data_german(['age'])\n",
    "        dataset.labels = (dataset.labels-1.0).astype('float64')\n",
    "        dataset.favorable_label = 1.0\n",
    "        dataset.unfavorable_label = 0.0\n",
    "        dataset.metadata['label_maps'] = [{1.0: 'Good Credit', 0.0: 'Bad Credit'}]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_options(dataset_name):\n",
    "    optim_options = None\n",
    "    if dataset_name==\"adult\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_adult,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'sex'\n",
    "        return (AdultDataset(), pro_attr, [{'sex': 1}], [{'sex': 0}], optim_options)\n",
    "    elif dataset_name==\"compas\":\n",
    "        optim_options = {\n",
    "        \"distortion_fun\": get_distortion_compas,\n",
    "        \"epsilon\": 0.05,\n",
    "        \"clist\": [0.99, 1.99, 2.99],\n",
    "        \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "        pro_attr = 'race'\n",
    "        return (CompasDataset(), pro_attr, [{'race': 1}], [{'race': 0}], optim_options)\n",
    "    elif dataset_name==\"bank\":\n",
    "        pro_attr = 'age'\n",
    "        return (BankDataset(protected_attribute_names=['age'],\n",
    "            privileged_classes=[lambda x: x >= 25], \n",
    "            features_to_drop=['day_of_week']), pro_attr, [{'age': 1}], [{'age': 0}], None)\n",
    "    elif dataset_name==\"german\":\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_german,\n",
    "            \"epsilon\": 0.1,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }   \n",
    "        pro_attr = 'age'\n",
    "        label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "        g = GermanDataset(metadata={'label_maps': [label_map]})\n",
    "        g.labels = (g.labels-1.0).astype('float64')\n",
    "        g.favorable_label = 1.0\n",
    "        g.unfavorable_label = 0.0\n",
    "        #g.metadata['label_maps'] = [label_map]\n",
    "\n",
    "        # load_preproc_data_german(['age'])\n",
    "        return (g, pro_attr, \n",
    "                    [{'age': 1}], [{'age': 0}], optim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None, seed=123):\n",
    "    print(seed, get_model_name(preprocessing_algo), get_model_name(inprocessing_algo), get_model_name(postprocessing_algo))\n",
    "    \n",
    "    # get specialized dataset for Optimized Preprocessing technique\n",
    "    if get_model_name(preprocessing_algo)==\"OP\" and dataset_name!=\"bank\":\n",
    "        print(\"Specialized function: \", dataset_name)\n",
    "        dataset = get_OP_dataset(dataset_name) \n",
    "\n",
    "    np.random.seed(seed)\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=seed)\n",
    "\n",
    "    model = sklearn.linear_model.LogisticRegression() # solver='liblinear', class_weight='balanced', \n",
    "    \n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "            \n",
    "    if preprocessing_algo is not None:\n",
    "        dataset_train_pred = preprocessing_algo.fit_transform(dataset_train_pred)\n",
    "        dataset_train_pred = dataset_train.align_datasets(dataset_train_pred)\n",
    "    \n",
    "    if inprocessing_algo is not None:\n",
    "        inp = inprocessing_algo\n",
    "        inp.fit(dataset_train_pred)\n",
    "        dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "        dataset_test_pred = inp.predict(dataset_test_pred) \n",
    "        \n",
    "        # exception for GFC \n",
    "        if get_model_name(inprocessing_algo)==\"GFC\":\n",
    "            dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "            dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "            dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "            dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "    else:\n",
    "        model.fit(dataset_train_pred.features, dataset_train_pred.labels)   # .ravel()\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1) \n",
    "        dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "        dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)  \n",
    "            \n",
    "    if postprocessing_algo is not None:\n",
    "        dataset_train_pred.features = dataset_train.features\n",
    "        pp = postprocessing_algo\n",
    "        pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "        dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    \n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    name = \"\"\n",
    "    if preprocessing_algo is not None:\n",
    "        name += get_model_name(preprocessing_algo) + \" + \"\n",
    "    if inprocessing_algo is not None:\n",
    "        name += get_model_name(inprocessing_algo) + \" + \"\n",
    "    if postprocessing_algo is not None:\n",
    "        name += get_model_name(postprocessing_algo)\n",
    "    if name == \"\":\n",
    "        name = get_model_name(model)\n",
    "        \n",
    "    if name.endswith(\" + \"):\n",
    "        lastIndex = name.rindex(\" + \")\n",
    "        name = name[:lastIndex]\n",
    "    \n",
    "    #print(run_classification_metrics(CM))\n",
    "    #print(run_binary_dataset_metrics(BLDM))\n",
    "    metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "       \n",
    "    return {\"key\":name, \"val\":metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME:  compas\n",
      "7 DIR None None\n",
      "7 DIR None EOP\n",
      "7 DIR None CEOP\n"
     ]
    }
   ],
   "source": [
    "#datasets = [\"compas\", \"german\", \"bank\", \"adult\"]\n",
    "datasets = [\"compas\", \"german\"]\n",
    "for dataset_name in datasets:\n",
    "    print(\"DATASET NAME: \", dataset_name)\n",
    "    dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "    \n",
    "    preprocessing_algos = [preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr),\n",
    "                           None,\n",
    "                           #LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0),\n",
    "                           OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups),\n",
    "                          #preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                           ]\n",
    "                          \n",
    "    inprocessing_algos = [None,\n",
    "                           #inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=seed),\n",
    "                          GerryFairClassifier(),\n",
    "                          inprocessing.PrejudiceRemover(sensitive_attr=pro_attr),\n",
    "                          inprocessing.ExponentiatedGradientReduction(LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                          ]\n",
    "\n",
    "    postprocessing_algos = [None,\n",
    "                            postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0),\n",
    "                            #postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),  \n",
    "                            ]\n",
    "\n",
    "    df = {}\n",
    "    all_data = {}\n",
    "\n",
    "    for pre in preprocessing_algos:\n",
    "        for inproc in inprocessing_algos:\n",
    "            for post in postprocessing_algos:    \n",
    "                kfold_data = []   # store data for each fold\n",
    "                col_name = None\n",
    "                # k-fold cross vaidation - Repeat the process 3 times\n",
    "                for seed in [7]:  #[3, 5, 11, 17, 29]:\n",
    "                    try:\n",
    "                        res = execute_intervention(dataset, dataset_name, privileged_groups, unprivileged_groups, \n",
    "                                 preprocessing_algo=copy.deepcopy(pre), \n",
    "                                 inprocessing_algo=copy.deepcopy(inproc),\n",
    "                                 postprocessing_algo=copy.deepcopy(post), seed=seed)\n",
    "                        col_name = res[\"key\"]\n",
    "                        kfold_data.append(res[\"val\"])\n",
    "                        all_data[col_name+\" - \"+str(seed)] = res[\"val\"]\n",
    "                        \n",
    "                    except KeyboardInterrupt:\n",
    "                        raise KeyboardInterrupt()\n",
    "                    except Exception as e:\n",
    "                        print(\"FAILED: \" + get_model_name(pre) + \", \" + get_model_name(inproc) + \", \" + get_model_name(post) + \" on dataset \" + get_dataset_name(dataset), e)\n",
    "\n",
    "                df[col_name] = np.array(kfold_data).mean(axis=0).tolist()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    all_data = pd.DataFrame.from_dict(all_data)\n",
    "    df.index = all_data.index = [\"Accuracy\", \"F1 Score\", \"Theil Index\",\n",
    "                    \"False Positive Rate - Unprivileged\", \"False Positive Rate - Privileged\",\n",
    "                    \"False Negative Rate - Unprivileged\", \"False Negative Rate - Privileged\",\n",
    "                    \"Accuracy - Unprivileged\", \"Accuracy - Privileged\",\n",
    "                    \"False Discovery Rate - Unprivileged\", \"False Discovery Rate - Privileged\",\n",
    "                    \"False Omission Rate - Unprivileged\", \"False Omission Rate - Privileged\",\n",
    "                    \"Num True Pos\", \"Num True Neg\", \"Num False Pos\", \"Num False Neg\",\n",
    "                    \"Num True Pos - Privileged\", \"Num True Neg - Privileged\", \"Num False Pos - Privileged\", \"Num False Neg - Privileged\",\n",
    "                    \"Num True Pos - Unprivileged\", \"Num True Neg - Unprivileged\", \"Num False Pos - Unprivileged\", \"Num False Neg - Unprivileged\",\n",
    "                    \"F1 Score - Privileged\", \"F1 Score - Unprivileged\",\n",
    "                    \"Privileged base Rate\", \"Unprivileged base Rate\", \"Consistency\"]\n",
    "\n",
    "    df = df.T\n",
    "    all_data = all_data.T\n",
    "    df.to_csv(\"./data/\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    all_data.to_csv(\"./data/All_Data -\"+ dataset_name +\".csv\", sep=',', encoding='utf-8')\n",
    "    display(df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EXTRA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data  #.mean(axis=0)\n",
    "#g = GermanDataset()\n",
    "#g.split([0.7], shuffle = True, seed=17)[0].convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR + GFC + CEOP\n",
    "DIR + GFC + ROC\n",
    "GFC + CEOP\n",
    "GFC + ROC\n",
    "OP + GFC + ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4710e-01 3.9630e-01 3.4200e-02 1.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0880e-01 3.1140e-01 8.9120e-01 6.8860e-01 0.0000e+00\n",
      " 0.0000e+00 3.3530e+03 0.0000e+00 1.0214e+04 0.0000e+00 2.8850e+03\n",
      " 0.0000e+00 6.3800e+03 0.0000e+00 4.6800e+02 0.0000e+00 3.8340e+03\n",
      " 0.0000e+00 4.7490e-01 1.9620e-01]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"\n",
    "dataset, pro_attr, privileged_groups, unprivileged_groups, optim_options = get_dataset_options(dataset_name)\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True, seed=7)\n",
    "\n",
    "#print(\"Specialized function: \", dataset_name)\n",
    "#dataset_train, dataset_test = get_OP_dataset(dataset_name)\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "#pre = LFR(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, k=10, Ax=0.1, Ay=1.0, Az=2.0, verbose=0)\n",
    "#pre = preprocessing.DisparateImpactRemover(sensitive_attribute=pro_attr)\n",
    "#pre = OptimPreproc(OptTools, optim_options, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups)\n",
    "#dataset_train_pred = pre.fit_transform(dataset_train_pred)\n",
    "\n",
    "'''\n",
    "X_train = dataset_train_pred.features\n",
    "y_train = dataset_train_pred.labels #.ravel()\n",
    "model = LogisticRegression()  \n",
    "model.fit(X_train, y_train)\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "dataset_train_pred.scores = model.predict_proba(dataset_train_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_train_pred.labels = model.predict(dataset_train_pred.features).reshape(-1,1)\n",
    "dataset_test_pred.scores = model.predict_proba(dataset_test_pred.features)[:,fav_idx].reshape(-1,1) \n",
    "dataset_test_pred.labels = model.predict(dataset_test_pred.features).reshape(-1,1)     \n",
    "'''\n",
    "\n",
    "#inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "#inp = inprocessing.PrejudiceRemover(sensitive_attr=pro_attr)\n",
    "inp = GerryFairClassifier()\n",
    "inp.fit(dataset_train_pred)\n",
    "\n",
    "\n",
    "dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "\n",
    "dataset_train_pred.scores = inp.predict(dataset_train_pred, threshold=None).labels\n",
    "dataset_test_pred.scores = inp.predict(dataset_test_pred, threshold=None).labels\n",
    "dataset_train_pred.labels = inp.predict(dataset_train_pred, threshold=0.5).labels\n",
    "dataset_test_pred.labels = inp.predict(dataset_test_pred, threshold=0.5).labels\n",
    "\n",
    "\n",
    "dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "dataset_test_pred = inp.predict(dataset_test_pred)\n",
    "\n",
    "'''\n",
    "y_train_pred = np.zeros_like(dataset_train_pred.scores)\n",
    "y_train_pred[dataset_train_pred.scores >= class_thresh] = dataset_train_pred.favorable_label\n",
    "y_train_pred[~(dataset_train_pred.scores >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_test_pred.scores)\n",
    "y_test_pred[dataset_test_pred.scores >= class_thresh] = dataset_test_pred.favorable_label\n",
    "y_test_pred[~(dataset_test_pred.scores >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "dataset_test_pred.labels = y_test_pred\n",
    "#dataset_test_pred.labels = y_test_pred#dataset_train_pred.features = dataset_train.features\n",
    "'''\n",
    "\n",
    "#pp = postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=7)\n",
    "#pp = postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "#pp = postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=0)\n",
    "#dataset_train_pred.features = dataset_train.features\n",
    "#pp = pp.fit(dataset_train, dataset_train_pred)\n",
    "#dataset_test_pred = pp.predict(dataset_test_pred)\n",
    "\n",
    "\n",
    "CM = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "    \n",
    "BLDM = BinaryLabelDatasetMetric(dataset_test_pred,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "\n",
    "print(run_classification_metrics(CM))\n",
    "print(run_binary_dataset_metrics(BLDM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3353.0, 'FP': 10214.0, 'TN': 0.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667],\n",
       "       [0.66666667],\n",
       "       [0.88888889],\n",
       "       ...,\n",
       "       [0.88888889],\n",
       "       [0.66666667],\n",
       "       [0.88888889]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_pred.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_pred.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_pred = inp.predict(dataset_train_pred)\n",
    "dataset_test_pred = inp.predict(dataset_test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 3330.0, 'FP': 0.0, 'TN': 10237.0, 'FN': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_train.metadata  #.labels.ravel()\n",
    "CM.binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566666666666667"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(dataset_test.labels, dataset_test_pred.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_pred.labels = dataset_test_pred.labels.astype('float64') #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_pred.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aif360.datasets.german_dataset.GermanDataset"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(dataset_test_pred.labels[0][0])\n",
    "type(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.grid_search_reduction.GridSearchReduction at 0x24a2689c850>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GermanDataset()\n",
    "dataset.labels = dataset.labels-1\n",
    "inp = inprocessing.GridSearchReduction(LogisticRegression(), prot_attr=pro_attr, constraints=\"DemographicParity\", drop_prot_attr=False)\n",
    "inp.fit(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
