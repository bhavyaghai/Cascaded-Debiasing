{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "import art\n",
    "import fairlearn\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_metrics(CM:ClassificationMetric):\n",
    "    return np.array([\n",
    "        round(CM.accuracy(), 4),\n",
    "        round(CM.theil_index(), 4),\n",
    "        round(CM.consistency()[0], 4),\n",
    "        round(CM.false_positive_rate_difference(), 4),\n",
    "        round(CM.false_negative_rate_difference(), 4),\n",
    "        round(CM.error_rate_difference(), 4),\n",
    "        round(CM.false_discovery_rate_difference(), 4),\n",
    "        round(CM.false_omission_rate_difference(), 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_dataset_metrics(BLDM:BinaryLabelDatasetMetric):\n",
    "    return np.array([\n",
    "        round(BLDM.statistical_parity_difference(), 4), # negative means privileged bias\n",
    "        round(BLDM.base_rate(privileged=True), 4), # 1 means privileged bias\n",
    "        round(BLDM.base_rate(privileged=False), 4), # 1 means unprivileged bias\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, classifier=None, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None):\n",
    "    if inprocessing_algo is not None:\n",
    "        model = inprocessing_algo\n",
    "        dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "        dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "        scale_orig = StandardScaler()\n",
    "        #X_train = scale_orig.fit_transform(dataset_train.features)\n",
    "        dataset_train.features = scale_orig.fit_transform(dataset_train.features)\n",
    "        y_train = dataset_train.labels.ravel()\n",
    "        #model = GSR\n",
    "        model.fit(dataset_train)\n",
    "\n",
    "        fav_idx = np.where(np.array([0, 1]) == dataset_train.favorable_label)[0][0]\n",
    "        y_train_pred_prob = model.predict(dataset_train).scores\n",
    "        print(y_train_pred_prob)\n",
    "        y_train_pred_prob = y_train_pred_prob#[:,fav_idx]\n",
    "\n",
    "        # Prediction probs for testing data\n",
    "        #X_test = scale_orig.transform(dataset_test.features)\n",
    "        dataset_transf_test = dataset_test.copy(deepcopy=True)\n",
    "        dataset_transf_test.features = scale_orig.transform(dataset_test.features)\n",
    "        y_test_pred_prob = model.predict(dataset_transf_test).scores#[:,fav_idx]\n",
    "\n",
    "        dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "        dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "        class_thresh = 0.5\n",
    "        y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "        y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "        y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "        dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "        y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "        y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "        y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "        dataset_test_pred.labels = y_test_pred\n",
    "    else:\n",
    "        classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "        results = classifier.predict(dataset_test.features)\n",
    "        #print(results)\n",
    "        if isinstance(classifier, sklearn.linear_model.LinearRegression):\n",
    "            results = np.rint(results)\n",
    "        dataset_test_pred = dataset_test.copy()\n",
    "        dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    #print(CM.binary_confusion_matrix())\n",
    "    return np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparison_algo(inprocessing_algo):\n",
    "    if isinstance(inprocessing_algo, inprocessing.PrejudiceRemover):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.GerryFairClassifier):\n",
    "        return sklearn.linear_model.LinearRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.MetaFairClassifier):\n",
    "        return BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "    if isinstance(inprocessing_algo, inprocessing.ExponentiatedGradientReduction):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.GridSearchReduction):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"Prejudice Remover\"\n",
    "    if isinstance(model, inprocessing.AdversarialDebiasing):\n",
    "        return \"Adversarial Debiasing\"\n",
    "    if isinstance(model, inprocessing.ARTClassifier):\n",
    "        return \"ART Classifier\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"Exp Grad Reduction\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GerryFair Classifier\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GridSearch Reduction\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MetaFair Classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inproc_algo(dataset, unprivileged_groups, privileged_groups, inprocessing_algo):\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "    standard = get_comparison_algo(inprocessing_algo)\n",
    "\n",
    "    metrics = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, standard)\n",
    "    df = pd.DataFrame(metrics, columns=[get_model_name(standard)])\n",
    "    df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "                \"false negative rate difference\", \"error rate difference\",\n",
    "                \"false discovery rate difference\", \"false omission rate difference\",\n",
    "                \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "    if isinstance(dataset, GermanDataset) and isinstance(inprocessing_algo, inprocessing.GridSearchReduction):\n",
    "        dataset_train = dataset_train.copy()\n",
    "        dataset_train.labels = dataset_train.labels%2\n",
    "        dataset_test = dataset_test.copy()\n",
    "        dataset_test.labels = dataset_test.labels%2\n",
    "                  \n",
    "    df[get_model_name(inprocessing_algo)] = analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, inprocessing_algo=inprocessing_algo)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inprocessing Algos Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92585001]\n",
      " [0.17366973]\n",
      " [0.38572737]\n",
      " ...\n",
      " [0.76997838]\n",
      " [0.72901029]\n",
      " [0.70805064]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Prejudice Remover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.6596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.6714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.2627</td>\n",
       "      <td>-0.2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>-0.0667</td>\n",
       "      <td>-0.1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1239</td>\n",
       "      <td>-0.1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.6351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.5112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Logistic Regression  Prejudice Remover\n",
       "accuracy                                      0.6840             0.6596\n",
       "theil index                                   0.2029             0.2295\n",
       "consistency                                   0.6714             0.6714\n",
       "false positive rate difference               -0.2627            -0.2553\n",
       "false negative rate difference                0.1613             0.1324\n",
       "error rate difference                         0.0336             0.0133\n",
       "false discovery rate difference               0.0455             0.0455\n",
       "false omission rate difference               -0.0667            -0.1357\n",
       "stat parity difference                       -0.1239            -0.1239\n",
       "priv base rate                                0.6351             0.6351\n",
       "unpriv base rate                              0.5112             0.5112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>GerryFair Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6267</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.3335</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>-0.1069</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1249</td>\n",
       "      <td>-0.1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.6485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.5236</td>\n",
       "      <td>0.5236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Linear Regression  GerryFair Classifier\n",
       "accuracy                                    0.6267                1.0000\n",
       "theil index                                 0.2300                0.0000\n",
       "consistency                                 0.6619                0.6619\n",
       "false positive rate difference             -0.3335                0.0000\n",
       "false negative rate difference              0.1848                0.0000\n",
       "error rate difference                       0.0245                0.0000\n",
       "false discovery rate difference             0.0397                0.0000\n",
       "false omission rate difference             -0.1069                0.0000\n",
       "stat parity difference                     -0.1249               -0.1249\n",
       "priv base rate                              0.6485                0.6485\n",
       "unpriv base rate                            0.5236                0.5236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70704421]\n",
      " [0.66408173]\n",
      " [0.61225193]\n",
      " ...\n",
      " [0.5101779 ]\n",
      " [0.58368872]\n",
      " [0.64853962]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meta Classifier</th>\n",
       "      <th>MetaFair Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.6256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.6612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.1775</td>\n",
       "      <td>-0.1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>-0.1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1137</td>\n",
       "      <td>-0.1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.6378</td>\n",
       "      <td>0.6378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.5242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Meta Classifier  MetaFair Classifier\n",
       "accuracy                                  0.6429               0.6256\n",
       "theil index                               0.2039               0.1602\n",
       "consistency                               0.6612               0.6612\n",
       "false positive rate difference           -0.1775              -0.1305\n",
       "false negative rate difference            0.2028               0.0847\n",
       "error rate difference                     0.1000               0.0749\n",
       "false discovery rate difference           0.1266               0.1267\n",
       "false omission rate difference            0.0073              -0.1168\n",
       "stat parity difference                   -0.1137              -0.1137\n",
       "priv base rate                            0.6378               0.6378\n",
       "unpriv base rate                          0.5242               0.5242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.11022302e-16]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00]\n",
      " [6.28342505e-01]\n",
      " [6.28342505e-01]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Exp Grad Reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.6613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.2633</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.1676</td>\n",
       "      <td>-0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>-0.1151</td>\n",
       "      <td>-0.1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1037</td>\n",
       "      <td>-0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.6304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Logistic Regression  Exp Grad Reduction\n",
       "accuracy                                      0.6694              0.6613\n",
       "theil index                                   0.1992              0.1984\n",
       "consistency                                   0.6650              0.6650\n",
       "false positive rate difference               -0.2633              0.0043\n",
       "false negative rate difference                0.1676             -0.0177\n",
       "error rate difference                         0.0491              0.0250\n",
       "false discovery rate difference               0.0959              0.1518\n",
       "false omission rate difference               -0.1151             -0.1968\n",
       "stat parity difference                       -0.1037             -0.1037\n",
       "priv base rate                                0.6304              0.6304\n",
       "unpriv base rate                              0.5267              0.5267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.42067064e-01]\n",
      " [7.68752974e-01]\n",
      " [1.21850039e-03]\n",
      " ...\n",
      " [2.01249646e-03]\n",
      " [2.11166140e-04]\n",
      " [7.57028811e-04]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>GridSearch Reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.5543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.3558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.3028</td>\n",
       "      <td>-0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.5573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>-0.0275</td>\n",
       "      <td>-0.0443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>0.1061</td>\n",
       "      <td>-0.4910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1648</td>\n",
       "      <td>-0.1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.6687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.5039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Logistic Regression  GridSearch Reduction\n",
       "accuracy                                      0.6548                0.5543\n",
       "theil index                                   0.2131                0.3558\n",
       "consistency                                   0.6686                0.6686\n",
       "false positive rate difference               -0.3028               -0.6900\n",
       "false negative rate difference                0.2257                0.5573\n",
       "error rate difference                         0.0157                0.0433\n",
       "false discovery rate difference              -0.0275               -0.0443\n",
       "false omission rate difference                0.1061               -0.4910\n",
       "stat parity difference                       -0.1648               -0.1648\n",
       "priv base rate                                0.6687                0.6687\n",
       "unpriv base rate                              0.5039                0.5039"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = CompasDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "display(run_inproc_algo(dataset, unprivileged_groups, privileged_groups, inprocessing.PrejudiceRemover(sensitive_attr=dataset.protected_attribute_names[0])))\n",
    "display(run_inproc_algo(dataset, unprivileged_groups, privileged_groups, inprocessing.GerryFairClassifier()))\n",
    "display(run_inproc_algo(dataset, unprivileged_groups, privileged_groups, inprocessing.MetaFairClassifier()))\n",
    "display(run_inproc_algo(dataset, unprivileged_groups, privileged_groups, inprocessing.ExponentiatedGradientReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\",\n",
    "                                              drop_prot_attr=False)))\n",
    "display(run_inproc_algo(dataset, unprivileged_groups, privileged_groups, inprocessing.GridSearchReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\",\n",
    "                                              drop_prot_attr=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disregard everything underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n",
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n",
      "WARNING:art.estimators.classification.scikitlearn:Input shape not recognised. The model might not have been fitted.\n",
      "WARNING:art.estimators.classification.scikitlearn:Number of classes not recognised. The model might not have been fitted.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Intervention</th>\n",
       "      <th>EGR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6688</td>\n",
       "      <td>0.5570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil index</th>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.3678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistency</th>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.6658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false positive rate difference</th>\n",
       "      <td>-0.2949</td>\n",
       "      <td>-0.7337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false negative rate difference</th>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.6477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error rate difference</th>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false discovery rate difference</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.0579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false omission rate difference</th>\n",
       "      <td>-0.0371</td>\n",
       "      <td>0.4757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat parity difference</th>\n",
       "      <td>-0.1272</td>\n",
       "      <td>-0.1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priv base rate</th>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpriv base rate</th>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.5261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 No Intervention     EGR\n",
       "accuracy                                  0.6688  0.5570\n",
       "theil index                               0.1702  0.3678\n",
       "consistency                               0.6658  0.6658\n",
       "false positive rate difference           -0.2949 -0.7337\n",
       "false negative rate difference            0.1592  0.6477\n",
       "error rate difference                     0.0171  0.0938\n",
       "false discovery rate difference           0.0424  0.0579\n",
       "false omission rate difference           -0.0371  0.4757\n",
       "stat parity difference                   -0.1272 -0.1272\n",
       "priv base rate                            0.6533  0.6533\n",
       "unpriv base rate                          0.5261  0.5261"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]'''\n",
    "\n",
    "dataset = AdultDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset = CompasDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "LR = sklearn.linear_model.LogisticRegression(solver='sag')\n",
    "'''.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "pred = LR.predict(dataset_test.features)\n",
    "print(pred)'''\n",
    "'''LR = sklearn.linear_model.LinearRegression().fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "pred = np.rint(LR.predict(dataset_test.features))\n",
    "print(pred)'''\n",
    "\n",
    "'''PR = inprocessing.PrejudiceRemover(sensitive_attr=dataset.protected_attribute_names[0])\n",
    "PR.fit(dataset_train)\n",
    "print(\"initial test not using algo func\")\n",
    "print(PR.predict(dataset_test))'''\n",
    "\n",
    "PR = inprocessing.PrejudiceRemover(sensitive_attr=dataset.protected_attribute_names[0])\n",
    "\n",
    "GF = inprocessing.GerryFairClassifier()\n",
    "\n",
    "MF = inprocessing.MetaFairClassifier()\n",
    "\n",
    "EGR = inprocessing.ExponentiatedGradientReduction(sklearn.linear_model.LogisticRegression(), constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "\n",
    "GSR = inprocessing.GridSearchReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\",\n",
    "                                              drop_prot_attr=False)\n",
    "\n",
    "base = art.estimators.classification.SklearnClassifier(model=sklearn.svm.SVC(C=1.0, kernel=\"rbf\"))\n",
    "ART = inprocessing.ARTClassifier(base)\n",
    "\n",
    "metrics = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, LR)\n",
    "df = pd.DataFrame(metrics, columns=[\"No Intervention\"])\n",
    "df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "            \"false negative rate difference\", \"error rate difference\",\n",
    "            \"false discovery rate difference\", \"false omission rate difference\",\n",
    "            \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "#BLDM = BinaryLabelDatasetMetric(dataset, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "#CM = ClassificationMetric(dataset_test, PR.predict(dataset_test), unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "#df[\"Prejudice Remover\"] = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, inprocessing_algo=PR)\n",
    "#df[\"GerryFair Classifier\"] = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, inprocessing_algo=GF)\n",
    "df[\"GSR\"] = analyze_algo(dataset_train.copy(), dataset_test, privileged_groups, unprivileged_groups, inprocessing_algo=GSR)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.55445517e-04]\n",
      " [7.05249500e-01]\n",
      " [2.47836698e-01]\n",
      " ...\n",
      " [3.16239271e-01]\n",
      " [9.98723823e-01]\n",
      " [6.34970564e-01]]\n"
     ]
    }
   ],
   "source": [
    "dataset = CompasDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "GSR = inprocessing.GridSearchReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\",\n",
    "                                              drop_prot_attr=False)\n",
    "\n",
    "'''GSR.fit(dataset_train)\n",
    "pred = GSR.predict(dataset_test)'''\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "scale_orig = StandardScaler()\n",
    "#X_train = scale_orig.fit_transform(dataset_train.features)\n",
    "dataset_train.features = scale_orig.fit_transform(dataset_train.features)\n",
    "y_train = dataset_train.labels.ravel()\n",
    "model = GSR\n",
    "model.fit(dataset_train)\n",
    "\n",
    "fav_idx = np.where(np.array([0, 1]) == dataset_train.favorable_label)[0][0]\n",
    "y_train_pred_prob = model.predict(dataset_train).scores\n",
    "print(y_train_pred_prob)\n",
    "y_train_pred_prob = y_train_pred_prob#[:,fav_idx]\n",
    "\n",
    "# Prediction probs for testing data\n",
    "#X_test = scale_orig.transform(dataset_test.features)\n",
    "dataset_transf_test = dataset_test.copy(deepcopy=True)\n",
    "dataset_transf_test.features = scale_orig.transform(dataset_test.features)\n",
    "y_test_pred_prob = model.predict(dataset_transf_test).scores#[:,fav_idx]\n",
    "\n",
    "dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "class_thresh = 0.5\n",
    "y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "dataset_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights            features                            \\\n",
      "                                protected attribute       protected attribute   \n",
      "                                                sex   age                race   \n",
      "instance names                                                                  \n",
      "7036                        1.0                 0.0  28.0                 0.0   \n",
      "5695                        1.0                 1.0  65.0                 1.0   \n",
      "3338                        1.0                 0.0  22.0                 0.0   \n",
      "7231                        1.0                 0.0  37.0                 0.0   \n",
      "10770                       1.0                 0.0  51.0                 1.0   \n",
      "...                         ...                 ...   ...                 ...   \n",
      "5812                        1.0                 0.0  49.0                 0.0   \n",
      "7076                        1.0                 1.0  27.0                 1.0   \n",
      "1020                        1.0                 0.0  54.0                 0.0   \n",
      "2356                        1.0                 0.0  51.0                 1.0   \n",
      "5354                        1.0                 0.0  24.0                 0.0   \n",
      "\n",
      "                                                                          \\\n",
      "                                                                           \n",
      "               juv_fel_count juv_misd_count juv_other_count priors_count   \n",
      "instance names                                                             \n",
      "7036                     0.0            0.0             0.0          0.0   \n",
      "5695                     0.0            0.0             0.0          0.0   \n",
      "3338                     0.0            0.0             0.0          0.0   \n",
      "7231                     0.0            0.0             0.0          3.0   \n",
      "10770                    0.0            0.0             0.0          0.0   \n",
      "...                      ...            ...             ...          ...   \n",
      "5812                     0.0            0.0             0.0          4.0   \n",
      "7076                     0.0            0.0             0.0          0.0   \n",
      "1020                     0.0            0.0             0.0          0.0   \n",
      "2356                     0.0            0.0             0.0          6.0   \n",
      "5354                     0.0            0.0             0.0          1.0   \n",
      "\n",
      "                                                        ...  \\\n",
      "                                                        ...   \n",
      "               age_cat=25 - 45 age_cat=Greater than 45  ...   \n",
      "instance names                                          ...   \n",
      "7036                       1.0                     0.0  ...   \n",
      "5695                       0.0                     1.0  ...   \n",
      "3338                       0.0                     0.0  ...   \n",
      "7231                       1.0                     0.0  ...   \n",
      "10770                      0.0                     1.0  ...   \n",
      "...                        ...                     ...  ...   \n",
      "5812                       0.0                     1.0  ...   \n",
      "7076                       1.0                     0.0  ...   \n",
      "1020                       0.0                     1.0  ...   \n",
      "2356                       0.0                     1.0  ...   \n",
      "5354                       0.0                     0.0  ...   \n",
      "\n",
      "                                                             \\\n",
      "                                                              \n",
      "               c_charge_desc=Viol Injunct Domestic Violence   \n",
      "instance names                                                \n",
      "7036                                                    0.0   \n",
      "5695                                                    0.0   \n",
      "3338                                                    0.0   \n",
      "7231                                                    0.0   \n",
      "10770                                                   0.0   \n",
      "...                                                     ...   \n",
      "5812                                                    0.0   \n",
      "7076                                                    0.0   \n",
      "1020                                                    0.0   \n",
      "2356                                                    0.0   \n",
      "5354                                                    0.0   \n",
      "\n",
      "                                                             \\\n",
      "                                                              \n",
      "               c_charge_desc=Viol Injunction Protect Dom Vi   \n",
      "instance names                                                \n",
      "7036                                                    0.0   \n",
      "5695                                                    0.0   \n",
      "3338                                                    0.0   \n",
      "7231                                                    0.0   \n",
      "10770                                                   0.0   \n",
      "...                                                     ...   \n",
      "5812                                                    0.0   \n",
      "7076                                                    0.0   \n",
      "1020                                                    0.0   \n",
      "2356                                                    0.0   \n",
      "5354                                                    0.0   \n",
      "\n",
      "                                                             \\\n",
      "                                                              \n",
      "               c_charge_desc=Viol Pretrial Release Dom Viol   \n",
      "instance names                                                \n",
      "7036                                                    0.0   \n",
      "5695                                                    0.0   \n",
      "3338                                                    0.0   \n",
      "7231                                                    0.0   \n",
      "10770                                                   0.0   \n",
      "...                                                     ...   \n",
      "5812                                                    0.0   \n",
      "7076                                                    0.0   \n",
      "1020                                                    0.0   \n",
      "2356                                                    0.0   \n",
      "5354                                                    0.0   \n",
      "\n",
      "                                                           \\\n",
      "                                                            \n",
      "               c_charge_desc=Viol Prot Injunc Repeat Viol   \n",
      "instance names                                              \n",
      "7036                                                  0.0   \n",
      "5695                                                  0.0   \n",
      "3338                                                  0.0   \n",
      "7231                                                  0.0   \n",
      "10770                                                 0.0   \n",
      "...                                                   ...   \n",
      "5812                                                  0.0   \n",
      "7076                                                  0.0   \n",
      "1020                                                  0.0   \n",
      "2356                                                  0.0   \n",
      "5354                                                  0.0   \n",
      "\n",
      "                                                             \\\n",
      "                                                              \n",
      "               c_charge_desc=Violation License Restrictions   \n",
      "instance names                                                \n",
      "7036                                                    0.0   \n",
      "5695                                                    0.0   \n",
      "3338                                                    0.0   \n",
      "7231                                                    0.0   \n",
      "10770                                                   0.0   \n",
      "...                                                     ...   \n",
      "5812                                                    0.0   \n",
      "7076                                                    0.0   \n",
      "1020                                                    0.0   \n",
      "2356                                                    0.0   \n",
      "5354                                                    0.0   \n",
      "\n",
      "                                                            \\\n",
      "                                                             \n",
      "               c_charge_desc=Violation Of Boater Safety Id   \n",
      "instance names                                               \n",
      "7036                                                   0.0   \n",
      "5695                                                   0.0   \n",
      "3338                                                   0.0   \n",
      "7231                                                   0.0   \n",
      "10770                                                  0.0   \n",
      "...                                                    ...   \n",
      "5812                                                   0.0   \n",
      "7076                                                   0.0   \n",
      "1020                                                   0.0   \n",
      "2356                                                   0.0   \n",
      "5354                                                   0.0   \n",
      "\n",
      "                                                                                   \\\n",
      "                                                                                    \n",
      "               c_charge_desc=Violation of Injunction Order/Stalking/Cyberstalking   \n",
      "instance names                                                                      \n",
      "7036                                                          0.0                   \n",
      "5695                                                          0.0                   \n",
      "3338                                                          0.0                   \n",
      "7231                                                          0.0                   \n",
      "10770                                                         0.0                   \n",
      "...                                                           ...                   \n",
      "5812                                                          0.0                   \n",
      "7076                                                          0.0                   \n",
      "1020                                                          0.0                   \n",
      "2356                                                          0.0                   \n",
      "5354                                                          0.0                   \n",
      "\n",
      "                                                                            \\\n",
      "                                                                             \n",
      "               c_charge_desc=Voyeurism c_charge_desc=arrest case no charge   \n",
      "instance names                                                               \n",
      "7036                               0.0                                 0.0   \n",
      "5695                               0.0                                 0.0   \n",
      "3338                               0.0                                 0.0   \n",
      "7231                               0.0                                 0.0   \n",
      "10770                              0.0                                 1.0   \n",
      "...                                ...                                 ...   \n",
      "5812                               0.0                                 0.0   \n",
      "7076                               0.0                                 0.0   \n",
      "1020                               0.0                                 0.0   \n",
      "2356                               0.0                                 1.0   \n",
      "5354                               0.0                                 0.0   \n",
      "\n",
      "               labels  \n",
      "                       \n",
      "                       \n",
      "instance names         \n",
      "7036              0.0  \n",
      "5695              0.0  \n",
      "3338              1.0  \n",
      "7231              0.0  \n",
      "10770             1.0  \n",
      "...               ...  \n",
      "5812              0.0  \n",
      "7076              0.0  \n",
      "1020              0.0  \n",
      "2356              1.0  \n",
      "5354              0.0  \n",
      "\n",
      "[1851 rows x 403 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"German Dataset\"))\n",
    "\n",
    "dataset = AdultDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"Adult Dataset\"))\n",
    "\n",
    "dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"Bank Dataset\"))\n",
    "\n",
    "dataset = CompasDataset()\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "df = run_preproc_algos_on_dataset(dataset, unprivileged_groups, privileged_groups)\n",
    "display(df.style.set_caption(\"Compas Dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 641.579346\n",
      "epoch 1; iter: 0; batch classifier loss: 32.879578\n",
      "epoch 2; iter: 0; batch classifier loss: 17.136475\n",
      "epoch 3; iter: 0; batch classifier loss: 12.746425\n",
      "epoch 4; iter: 0; batch classifier loss: 9.400681\n",
      "epoch 5; iter: 0; batch classifier loss: 6.140807\n",
      "epoch 6; iter: 0; batch classifier loss: 2.270022\n",
      "epoch 7; iter: 0; batch classifier loss: 2.144179\n",
      "epoch 8; iter: 0; batch classifier loss: 0.836270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.199547\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470885\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263953\n",
      "epoch 14; iter: 0; batch classifier loss: 0.381343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.254617\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229809\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286453\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254371\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186551\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314237\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269565\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177701\n",
      "epoch 23; iter: 0; batch classifier loss: 0.305265\n",
      "epoch 24; iter: 0; batch classifier loss: 0.290146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.281725\n",
      "epoch 26; iter: 0; batch classifier loss: 0.235768\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176383\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342565\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170852\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238003\n",
      "epoch 31; iter: 0; batch classifier loss: 0.301277\n",
      "epoch 32; iter: 0; batch classifier loss: 0.263933\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165310\n",
      "epoch 34; iter: 0; batch classifier loss: 0.312401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244240\n",
      "epoch 36; iter: 0; batch classifier loss: 0.202886\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250031\n",
      "epoch 38; iter: 0; batch classifier loss: 0.224527\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.211093\n",
      "epoch 41; iter: 0; batch classifier loss: 0.251995\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.232339\n",
      "epoch 44; iter: 0; batch classifier loss: 0.193809\n",
      "epoch 45; iter: 0; batch classifier loss: 0.317659\n",
      "epoch 46; iter: 0; batch classifier loss: 0.261861\n",
      "epoch 47; iter: 0; batch classifier loss: 0.228658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.283354\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221239\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-d5d97aa90246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                            scope_name=scope_name_2, sess=sess2)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mfair_AD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdataset_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfair_AD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/aif360/algorithms/transformer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnew_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                     \u001b[0munit_adversary_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversary_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                     \u001b[0mgrad\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_adversary_grad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_adversary_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mgrad\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversary_loss_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0madversary_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 adversary_grads = {var: grad for (grad, var) in adversary_opt.compute_gradients(pred_protected_attributes_loss,\n\u001b[1;32m    175\u001b[0m                                                                                       var_list=classifier_vars)}\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mclassifier_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 instructions)\n\u001b[0;32m--> 538\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/linalg_ops.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(tensor, ord, axis, keepdims, name, keep_dims)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'fro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 281\u001b[0;31m       tensor_util.make_tensor_proto(\n\u001b[0m\u001b[1;32m    282\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m           allow_broadcast=allow_broadcast))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "sess1 = tf.compat.v1.Session()\n",
    "with tf.compat.v1.variable_scope(\"var1\", reuse=tf.compat.v1.AUTO_REUSE) as scope_name_1:\n",
    "    AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_1, sess=sess1, debias=False)\n",
    "\n",
    "    AD.fit(dataset_train)\n",
    "    dataset_test_pred = AD.predict(dataset_test)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    AD_metrics = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "\n",
    "sess1.close()\n",
    "\n",
    "metrics = AD_metrics\n",
    "df = pd.DataFrame(metrics, columns=[\"No Intervention\"])\n",
    "df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "            \"false negative rate difference\", \"error rate difference\",\n",
    "            \"false discovery rate difference\", \"false omission rate difference\",\n",
    "            \"stat parity difference\", \"priv base rate\", \"unpriv base rate\"]\n",
    "\n",
    "sess2 = tf.compat.v1.Session()\n",
    "with tf.compat.v1.variable_scope(\"var2\", reuse=tf.compat.v1.AUTO_REUSE) as scope_name_2:\n",
    "    fair_AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_2, sess=sess2)\n",
    "\n",
    "    fair_AD.fit(dataset_train)\n",
    "    dataset_test_pred = fair_AD.predict(dataset_test)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    df[\"Adversarial Debiasing w/o dataset\"] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "sess2.close()\n",
    "\n",
    "'''sess3 = tf.compat.v1.Session()\n",
    "with tf.compat.v1.variable_scope(\"var3\", reuse=tf.compat.v1.AUTO_REUSE) as scope_name_3:\n",
    "    fair_AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_3, sess=sess3, debias=True)\n",
    "\n",
    "    fair_AD.fit(dataset_train.copy())\n",
    "    fair_dataset_train = fair_AD.transform(dataset_train)\n",
    "    fair_AD = inprocessing.AdversarialDebiasing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups,\n",
    "                                           scope_name=scope_name_3, sess=sess3, debias=True)\n",
    "    fair_AD.fit(fair_dataset_train)\n",
    "    dataset_test_pred = fair_AD.predict(dataset_test)\n",
    "\n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    BLDM = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    df[\"Adversarial Debiasing w dataset\"] = np.concatenate((run_classification_metrics(CM), run_binary_dataset_metrics(BLDM)))\n",
    "\n",
    "sess3.close()'''\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fairness_metrics(CM:ClassificationMetric):\n",
    "    print(f\"accuracy = {round(CM.accuracy(), 4)}\")\n",
    "    print(f\"theil index (goal:0) = {round(CM.theil_index(), 4)}\")\n",
    "    print(f\"binary confusion matrix = {CM.binary_confusion_matrix()}\")\n",
    "    print(f\"consistency (goal:1) = {round(CM.consistency()[0], 4)}\")\n",
    "    print(f\"false positive rate difference (negative:privileged bias) = {round(CM.false_positive_rate_difference(), 4)}\")\n",
    "    print(f\"false negative rate difference (negative:privileged bias) = {round(CM.false_negative_rate_difference(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fairness_metrics_as_df(CM1:ClassificationMetric, CM2:ClassificationMetric,\n",
    "                                   intervention:str) -> pd.DataFrame:\n",
    "    metrics = np.array([[round(CM1.accuracy(), 4), round(CM2.accuracy(), 4)],\n",
    "        [round(CM1.theil_index(), 4), round(CM2.theil_index(), 4)],\n",
    "        [round(CM1.consistency()[0], 4), round(CM2.consistency()[0], 4)],\n",
    "        [round(CM1.false_positive_rate_difference(), 4), round(CM2.false_positive_rate_difference(), 4)],\n",
    "        [round(CM1.false_negative_rate_difference(), 4), round(CM2.false_negative_rate_difference(), 4)]]\n",
    "    )\n",
    "    df = pd.DataFrame(metrics, columns=[\"no intervention\", intervention])\n",
    "    df.index = [\"accuracy\", \"theil index\", \"consistency\", \"false positive rate difference\",\n",
    "                \"false negative rate difference\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_debiasing_algos(dataset, privileged_groups, unprivileged_groups, classifier, \n",
    "                             preprocessing_algo:preprocessing = None, inprocessing_algo:inprocessing = None, \n",
    "                             postprocessing_algo:postprocessing = None):\n",
    "    dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "    classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = classifier.predict(dataset_test.features)\n",
    "    \n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM1 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "\n",
    "    if preprocessing_algo is not None:\n",
    "        dataset_train = preprocessing_algo.fit_transform(dataset_train)\n",
    "    fair_classifier = clone(classifier)\n",
    "    fair_classifier.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    \n",
    "    results = fair_classifier.predict(dataset_test.features)\n",
    "    \n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "    \n",
    "    CM2 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    return compare_fairness_metrics_as_df(CM1, CM2, \"preprocessing\")\n",
    "        \n",
    "    '''_________________________\n",
    "    RW = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                                 privileged_groups=privileged_groups)\n",
    "\n",
    "    fair_dataset_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "    fair_RF = RandomForestClassifier(n_estimators=1100)\n",
    "    fair_RF.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "\n",
    "    results = fair_RF.predict(dataset_test.features)\n",
    "\n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "    CM2 = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    compare_fairness_metrics(CM1, CM2, side_by_side=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"78b37c0b-09d7-418a-96f4-eeb1f52508ec\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"78b37c0b-09d7-418a-96f4-eeb1f52508ec\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['personal_status', 'sex'] #ignore sex-related stuff\n",
    ")\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=1100)\n",
    "RF.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "\n",
    "results = RF.predict(dataset_test.features)\n",
    "\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "CM1 = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "\n",
    "RW = preprocessing.LFR(unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "fair_dataset_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "fair_RF = RandomForestClassifier(n_estimators=1100)\n",
    "fair_RF.fit(fair_dataset_train.features, fair_dataset_train.labels.ravel())\n",
    "\n",
    "results = fair_RF.predict(dataset_test.features)\n",
    "\n",
    "dataset_test_pred = dataset_test.copy()\n",
    "dataset_test_pred.labels = np.array([results]).transpose()\n",
    "\n",
    "CM2 = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
