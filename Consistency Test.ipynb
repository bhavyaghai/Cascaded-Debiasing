{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "import copy\n",
    "\n",
    "import aif360\n",
    "from aif360.datasets import AdultDataset, BankDataset, CompasDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms import preprocessing, inprocessing, postprocessing\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "            import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext jupyternotify\n",
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparison_algo(inprocessing_algo):\n",
    "    if isinstance(inprocessing_algo, inprocessing.PrejudiceRemover):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.GerryFairClassifier):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.MetaFairClassifier):\n",
    "        return BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "    if isinstance(inprocessing_algo, inprocessing.ExponentiatedGradientReduction):\n",
    "        return sklearn.linear_model.LogisticRegression()\n",
    "    if isinstance(inprocessing_algo, inprocessing.GridSearchReduction):\n",
    "        return sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(model):\n",
    "    if isinstance(model, sklearn.linear_model.LogisticRegression):\n",
    "        return \"Logistic Regression\"\n",
    "    if isinstance(model, sklearn.linear_model.LinearRegression):\n",
    "        return \"Linear Regression\"\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        return \"Meta Classifier\"\n",
    "    \n",
    "    if isinstance(model, preprocessing.DisparateImpactRemover):\n",
    "        return \"DIR\"\n",
    "    if isinstance(model, preprocessing.Reweighing):\n",
    "        return \"RW\"\n",
    "    \n",
    "    if isinstance(model, inprocessing.PrejudiceRemover):\n",
    "        return \"PR\"\n",
    "    if isinstance(model, inprocessing.ExponentiatedGradientReduction):\n",
    "        return \"EGR\"\n",
    "    if isinstance(model, inprocessing.GerryFairClassifier):\n",
    "        return \"GFC\"\n",
    "    if isinstance(model, inprocessing.GridSearchReduction):\n",
    "        return \"GSR\"\n",
    "    if isinstance(model, inprocessing.MetaFairClassifier):\n",
    "        return \"MFC\"\n",
    "    \n",
    "    if isinstance(model, postprocessing.EqOddsPostprocessing):\n",
    "        return \"EOP\"\n",
    "    if isinstance(model, postprocessing.CalibratedEqOddsPostprocessing):\n",
    "        return \"CEOP\"\n",
    "    if isinstance(model, postprocessing.RejectOptionClassification):\n",
    "        return \"ROC\"\n",
    "    \n",
    "    return \"Logistic Regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, classifier=None, \n",
    "                 preprocessing_algo=None, inprocessing_algo=None, postprocessing_algo=None):\n",
    "    base = sklearn.linear_model.LogisticRegression()\n",
    "    if inprocessing_algo is not None:\n",
    "        base = get_comparison_algo(inprocessing_algo)\n",
    "    '''base.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    results = base.predict(dataset_test.features)\n",
    "    if isinstance(base, sklearn.linear_model.LinearRegression):\n",
    "        results = np.rint(results)\n",
    "    dataset_test_pred = dataset_test.copy()\n",
    "    dataset_test_pred.labels = np.array([results]).transpose()'''\n",
    "    \n",
    "    dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "    dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "    \n",
    "    dataset_test_features = dataset_test.features\n",
    "    \n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = dataset_train.features#scale_orig.fit_transform(dataset_train.features)\n",
    "    y_train = dataset_train.labels.ravel()\n",
    "    model = base\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "    y_train_pred_prob = model.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "    # Prediction probs for testing data\n",
    "    X_test = dataset_test.features#scale_orig.transform(dataset_test.features)\n",
    "    y_test_pred_prob = model.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "    dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "    dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "    class_thresh = 0.5\n",
    "    y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "    y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "    y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "    dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "    y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "    y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "    y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "    dataset_test_pred.labels = y_test_pred\n",
    "    \n",
    "    dataset_test.features = dataset_test_features\n",
    "    \n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    #print(f\"Orig Consistency: {CM.consistency()}\")\n",
    "    \n",
    "    if preprocessing_algo is not None:\n",
    "        dataset_train = preprocessing_algo.fit_transform(dataset_train)\n",
    "    \n",
    "    if inprocessing_algo is not None:\n",
    "        model = inprocessing_algo\n",
    "        dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "        dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "        scale_orig = StandardScaler()\n",
    "        #X_train = scale_orig.fit_transform(dataset_train.features)\n",
    "        dataset_train.features = dataset_train.features#scale_orig.fit_transform(dataset_train.features)\n",
    "        y_train = dataset_train.labels.ravel()\n",
    "        #model = GSR\n",
    "        model.fit(dataset_train)\n",
    "\n",
    "        fav_idx = np.where(np.array([0, 1]) == dataset_train.favorable_label)[0][0]\n",
    "        y_train_pred_prob = model.predict(dataset_train).scores\n",
    "        #print(y_train_pred_prob)\n",
    "        y_train_pred_prob = y_train_pred_prob#[:,fav_idx]\n",
    "\n",
    "        # Prediction probs for testing data\n",
    "        #X_test = scale_orig.transform(dataset_test.features)\n",
    "        dataset_transf_test = dataset_test.copy(deepcopy=True)\n",
    "        dataset_transf_test.features = dataset_test.features#scale_orig.transform(dataset_test.features)\n",
    "        y_test_pred_prob = model.predict(dataset_transf_test).scores#[:,fav_idx]\n",
    "\n",
    "        dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "        dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "        class_thresh = 0.5\n",
    "        y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "        y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "        y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "        dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "        y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "        y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "        y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "        dataset_test_pred.labels = y_test_pred\n",
    "    else:\n",
    "        dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "        dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "        scale_orig = StandardScaler()\n",
    "        X_train = dataset_train.features#scale_orig.fit_transform(dataset_train.features)\n",
    "        y_train = dataset_train.labels.ravel()\n",
    "        model = base\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "        y_train_pred_prob = model.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "        # Prediction probs for testing data\n",
    "        X_test = dataset_test.features#scale_orig.transform(dataset_test.features)\n",
    "        y_test_pred_prob = model.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "        dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "        dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "        class_thresh = 0.5\n",
    "        y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "        y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "        y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "        dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "        y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "        y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "        y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "        dataset_test_pred.labels = y_test_pred\n",
    "        \n",
    "    #dataset_test.features = dataset_test_features\n",
    "    \n",
    "    if postprocessing_algo is not None:\n",
    "        dataset_test_pred = postprocessing_algo.fit_predict(dataset_test, dataset_test_pred)\n",
    "        \n",
    "    dataset_test.features = dataset_test_features\n",
    "    \n",
    "    CM = ClassificationMetric(dataset_test,\n",
    "                              dataset_test_pred,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    name = []\n",
    "    if preprocessing_algo is not None:\n",
    "        name.append(get_model_name(preprocessing_algo))\n",
    "    if inprocessing_algo is not None:\n",
    "        name.append(get_model_name(inprocessing_algo))\n",
    "    if postprocessing_algo is not None:\n",
    "        name.append(get_model_name(postprocessing_algo))\n",
    "    if len(name) == 0:\n",
    "        name.append(\"Logistic Regression\")\n",
    "    print(f\"Consistency Score for {' + '.join(name)}: {CM.consistency()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency Score for Logistic Regression: [0.89452279]\n",
      "Consistency Score for RW: [0.89452279]\n",
      "Consistency Score for DIR: [0.89452279]\n",
      "Consistency Score for EGR: [0.89452279]\n",
      "Consistency Score for RW + EGR: [0.89452279]\n",
      "Consistency Score for DIR + EGR: [0.89452279]\n",
      "Consistency Score for GSR: [0.89452279]\n",
      "Consistency Score for RW + GSR: [0.89452279]\n",
      "Consistency Score for DIR + GSR: [0.89452279]\n",
      "Consistency Score for PR: [0.89452279]\n",
      "Consistency Score for RW + PR: [0.89452279]\n",
      "Consistency Score for DIR + PR: [0.89452279]\n",
      "Consistency Score for CEOP: [0.89452279]\n",
      "Consistency Score for RW + CEOP: [0.89452279]\n",
      "Consistency Score for DIR + CEOP: [0.89452279]\n",
      "Consistency Score for EGR + CEOP: [0.89452279]\n",
      "Consistency Score for RW + EGR + CEOP: [0.89452279]\n",
      "Consistency Score for DIR + EGR + CEOP: [0.89452279]\n",
      "Consistency Score for GSR + CEOP: [0.89452279]\n",
      "Consistency Score for RW + GSR + CEOP: [0.89452279]\n",
      "Consistency Score for DIR + GSR + CEOP: [0.89452279]\n",
      "Consistency Score for PR + CEOP: [0.89452279]\n",
      "Consistency Score for RW + PR + CEOP: [0.89452279]\n",
      "Consistency Score for DIR + PR + CEOP: [0.89452279]\n",
      "Consistency Score for ROC: [0.89452279]\n",
      "Consistency Score for RW + ROC: [0.89452279]\n",
      "Consistency Score for DIR + ROC: [0.89452279]\n",
      "Consistency Score for EGR + ROC: [0.89452279]\n",
      "Consistency Score for RW + EGR + ROC: [0.89452279]\n",
      "Consistency Score for DIR + EGR + ROC: [0.89452279]\n",
      "Consistency Score for GSR + ROC: [0.89452279]\n",
      "Consistency Score for RW + GSR + ROC: [0.89452279]\n",
      "Consistency Score for DIR + GSR + ROC: [0.89452279]\n",
      "Consistency Score for PR + ROC: [0.89452279]\n",
      "Consistency Score for RW + PR + ROC: [0.89452279]\n",
      "Consistency Score for DIR + PR + ROC: [0.89452279]\n",
      "Consistency Score for EOP: [0.89452279]\n",
      "Consistency Score for RW + EOP: [0.89452279]\n",
      "Consistency Score for DIR + EOP: [0.89452279]\n",
      "Consistency Score for EGR + EOP: [0.89452279]\n",
      "Consistency Score for RW + EGR + EOP: [0.89452279]\n",
      "Consistency Score for DIR + EGR + EOP: [0.89452279]\n",
      "Consistency Score for GSR + EOP: [0.89452279]\n",
      "Consistency Score for RW + GSR + EOP: [0.89452279]\n",
      "Consistency Score for DIR + GSR + EOP: [0.89452279]\n",
      "Consistency Score for PR + EOP: [0.89452279]\n",
      "Consistency Score for RW + PR + EOP: [0.89452279]\n",
      "Consistency Score for DIR + PR + EOP: [0.89452279]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"a9df4aa6-f5e5-4272-ba22-00287e9d9ddf\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"a9df4aa6-f5e5-4272-ba22-00287e9d9ddf\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "dataset_train, dataset_test = dataset.split([0.7], shuffle = True)\n",
    "\n",
    "preprocessing_algos = [None,\n",
    "                       preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                       preprocessing.DisparateImpactRemover()]\n",
    "inprocessing_algos = [None,\n",
    "                      inprocessing.ExponentiatedGradientReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                      inprocessing.GridSearchReduction(sklearn.linear_model.LogisticRegression(), constraints=\"DemographicParity\", drop_prot_attr=False),\n",
    "                      inprocessing.PrejudiceRemover()]\n",
    "postprocessing_algos = [None,\n",
    "                        postprocessing.CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                        postprocessing.RejectOptionClassification(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups),\n",
    "                        postprocessing.EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)]\n",
    "\n",
    "for post in postprocessing_algos:\n",
    "    for inproc in inprocessing_algos:\n",
    "        for pre in preprocessing_algos:\n",
    "            analyze_algo(dataset_train, dataset_test, privileged_groups, unprivileged_groups, \n",
    "                 preprocessing_algo=copy.deepcopy(pre), \n",
    "                 inprocessing_algo=copy.deepcopy(inproc),\n",
    "                 postprocessing_algo=copy.deepcopy(post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig Consistency: [0.89452279]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Only\n",
    "\n",
    "dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "base = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "dataset_test_features = dataset_test.features\n",
    "\n",
    "scale_orig = StandardScaler()\n",
    "X_train = dataset_train.features#scale_orig.fit_transform(dataset_train.features)\n",
    "y_train = dataset_train.labels.ravel()\n",
    "model = base\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "y_train_pred_prob = model.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "# Prediction probs for testing data\n",
    "X_test = dataset_test.features#scale_orig.transform(dataset_test.features)\n",
    "y_test_pred_prob = model.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "class_thresh = 0.5\n",
    "y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "dataset_test_pred.labels = y_test_pred\n",
    "\n",
    "dataset_test.features = dataset_test_features\n",
    "\n",
    "CM = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "print(f\"Orig Consistency: {CM.consistency()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RW Consistency: [0.89452279]\n"
     ]
    }
   ],
   "source": [
    "dataset = BankDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25], #age >= 25 is privileged\n",
    "    features_to_drop=['day_of_week'] #ignore sex-related stuff\n",
    ")\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "base = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "RW = preprocessing.Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "dataset_train = RW.fit_transform(dataset_train)\n",
    "\n",
    "dataset_train_pred = dataset_train.copy(deepcopy=True)\n",
    "dataset_test_pred = dataset_test.copy(deepcopy=True)\n",
    "\n",
    "dataset_test_features = dataset_test.features\n",
    "\n",
    "scale_orig = StandardScaler()\n",
    "X_train = dataset_train.features#scale_orig.fit_transform(dataset_train.features)\n",
    "y_train = dataset_train.labels.ravel()\n",
    "model = base\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(model.classes_ == dataset_train.favorable_label)[0][0]\n",
    "y_train_pred_prob = model.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "# Prediction probs for testing data\n",
    "X_test = dataset_test.features#scale_orig.transform(dataset_test.features)\n",
    "y_test_pred_prob = model.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "dataset_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "class_thresh = 0.5\n",
    "y_train_pred = np.zeros_like(dataset_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_train_pred.unfavorable_label\n",
    "dataset_train_pred.labels = y_train_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_test_pred.unfavorable_label\n",
    "dataset_test_pred.labels = y_test_pred\n",
    "\n",
    "dataset_test.features = dataset_test_features\n",
    "\n",
    "CM = ClassificationMetric(dataset_test,\n",
    "                          dataset_test_pred,\n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "print(f\"RW Consistency: {CM.consistency()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
